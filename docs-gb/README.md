# Why Seldon Core 2

Seldon Core 2 is a source-available, Kubernetes-native framework designed to deploy and manage machine learning (ML) systems at scale. Its data-centric approach and modular architecture enable you to handle everything from simple models to complex ML applications, ensuring flexibility, standardization, observability, and cost optimization across diverse environments, including on-premise, hybrid, and multi-cloud setups.

![Seldon Core 2 key benefits](./images/seldon_core_2_intro.png)

## **Flexibility: Real-time, your way**

Core 2 offers a platform-agnostic, flexible framework for seamless deployment of different types of ML models across on-premise, cloud, and hybrid environments. Its adaptive architecture enables customizable applications, future-proofing MLOps by scaling deployments as data and applications evolve. The modular design enhances resource-efficiency, allowing dynamic scaling, component reuse, and optimized resource allocation. This ensures long-term scalability, operational efficiency, and adaptability to changing demands.

## **Standardization: Consistency across workflows**

Seldon Core 2 enforces best practices for ML deployment, ensuring consistency, reliability, and efficiency across the entire lifecycle. By automating key steps, it removes operational bottlenecks, enabling faster deployments and allowing teams to focus on high-value tasks.

With a "learn once, deploy anywhere" approach, Seldon Core 2 standardizes model deployment across on-premise, cloud, and hybrid environments, reducing risks and improving productivity. Its consistent methods build trust in both new and existing models, fostering innovation and unlocking AI’s full potential while ensuring accuracy and compliance.

Seldon Core 2 enhances collaboration between MLOps Engineers, Data Scientists, and Software Engineers through a customizable framework that promotes knowledge sharing, innovation, and seamless adoption of new data science features.

## **Enhanced Observability**

Observability in Seldon Core 2 enables real-time monitoring, analysis, and performance tracking of ML systems, covering data pipelines, models, and deployment environments. Its customizable framework combines operational and data science monitoring, ensuring teams have the key metrics needed for maintenance and decision-making.

With scalable maintenance, Seldon simplifies operational monitoring, allowing real-time ML deployments to expand across organizations while supporting complex, mission-critical use cases. A data-centric approach ensures all prediction data is auditable, maintaining explainability, compliance, and trust in AI-driven decisions.

Seldon Core 2 provides flexible metric aggregation, surfacing operational, data science, and custom metrics for different users. Whether teams need high-level overviews or deep insights, Seldon ensures full transparency. With real-time access, you can register, monitor, and audit models step by step, gaining visibility into data-driven decisions and ensuring accountable, trustworthy AI systems.

## **Optimization: Modularity to maximize resource efficiency**

Seldon Core 2 is built for scalability, efficiency, and cost-effective ML operations, enabling organizations to deploy only the necessary components while maintaining agility and high performance. Its modular architecture ensures that resources are optimized, infrastructure is consolidated, and deployments remain adaptable to evolving business needs.

**Scaling for Efficiency:** dynamic infrastructure scaling based on real-time demand, ensuring that only required resources are used. By eliminating redundancy and optimizing model deployments, you can reduce operational costs while maintaining performance.

**Consolidated Serving Infrastructure**: With multi-model serving (MMS) and overcommit capabilities, Seldon Core 2 maximizes resource utilization by intelligently allocating models across available infrastructure. This approach reduces compute overhead while ensuring reliable and efficient model inference.

**Extendability & Modular Adaptation**: Designed for flexibility, Seldon Core 2 integrates seamlessly with external modules like LLMs and Alibi, enabling organizations to extend their ML capabilities as needed. Its modular nature supports easy adaptation, ensuring compatibility with diverse AI workloads.

**Reusability for Cost Optimization:** By repurposing and reusing components across workflows, Seldon Core 2 eliminates the need to rebuild from scratch. This accelerates ML development, enhances operational efficiency, and ensures long-term AI sustainability while minimizing infrastructure costs.

By combining scalability, infrastructure consolidation, modular adaptability, and component reusability, Seldon Core 2 empowers you to lower costs, streamline workflows, and drive AI innovation—all while maintaining flexibility and high performance.
