{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Examples with Different Protocols Showing Metrics\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    " * A kubernetes cluster with kubectl configured\n",
    " * curl\n",
    " * grpcurl\n",
    " * pygmentize\n",
    " \n",
    "\n",
    "## Setup Seldon Core\n",
    "\n",
    "Install Seldon Core as described in [docs](https://docs.seldon.io/projects/seldon-core/en/latest/workflow/install.html)\n",
    "\n",
    "Then port-forward to that ingress on localhost:8003 in a separate terminal either with:\n",
    "\n",
    " * Ambassador: \n",
    " \n",
    " ```bash\n",
    " kubectl port-forward $(kubectl get pods -n seldon -l app.kubernetes.io/name=ambassador -o jsonpath='{.items[0].metadata.name}') -n seldon 8003:8080\n",
    " ```\n",
    " * Istio: \n",
    " \n",
    " ```bash\n",
    " kubectl port-forward $(kubectl get pods -l istio=ingressgateway -n istio-system -o jsonpath='{.items[0].metadata.name}') -n istio-system 8003:80\n",
    " ```\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl create namespace seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Seldon Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm install seldon-core-analytics ../../../helm-charts/seldon-core-analytics  \\\n",
    "        --set grafana_prom_admin_password=password \\\n",
    "        --set persistence.enabled=false \\\n",
    "        --namespace seldon-system \\\n",
    "        --wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Port forward to the Grafana dashboard\n",
    "\n",
    "```bash\n",
    "kubectl port-forward $(kubectl get pods -n seldon-system  -l app.kubernetes.io/name=grafana -o jsonpath='{.items[0].metadata.name}') 3000:3000 -n seldon-system\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env RESOURCES=../../../notebooks/resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seldon Protocol REST Model\n",
    "\n",
    "**Make sure your active namespace is seldon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ${RESOURCES}/model_seldon_rest.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f ${RESOURCES}/model_seldon_rest.yaml -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=rest-seldon \\\n",
    "                                 -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for i in `seq 1 60`; do \\\n",
    "   sleep 1 && curl -d '{\"data\": {\"ndarray\":[[1.0, 2.0, 5.0]]}}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/rest-seldon/api/v1.0/predictions \\\n",
    "   -H \"Content-Type: application/json\"; \\\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![seldon-rest-dashboard](seldon-rest-dashboard.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(3):\n",
    "    metric=!curl -s http://localhost:8003/seldon/seldon/rest-seldon/prometheus | grep seldon_api_executor_server_requests_seconds_count\n",
    "    if metric and len(metric)>0:    \n",
    "        print(metric[0])\n",
    "        assert(not metric[0] == \"\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Failed to get metrics for rest-seldon\")\n",
    "        time.sleep(2)\n",
    "\n",
    "for i in range(3):        \n",
    "    metric=!curl -s http://localhost:8003/seldon/seldon/rest-seldon/prometheus | grep seldon_api_executor_server_requests_seconds_summary_count\n",
    "    if metric and len(metric)>0:    \n",
    "        print(metric[0])\n",
    "        assert(not metric[0] == \"\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Failed to get metrics for rest-seldon\")\n",
    "        time.sleep(2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f ${RESOURCES}/model_seldon_rest.yaml -n seldon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seldon Protocol GRPC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ${RESOURCES}/model_seldon_grpc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f ${RESOURCES}/model_seldon_grpc.yaml -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=grpc-seldon \\\n",
    "                                 -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../../../executor/proto && for i in `seq 1 60`; do \\\n",
    " sleep 1 && grpcurl -d '{\"data\":{\"ndarray\":[[1.0,2.0]]}}' \\\n",
    "         -rpc-header seldon:grpc-seldon -rpc-header namespace:seldon \\\n",
    "         -plaintext \\\n",
    "         -proto ./prediction.proto  0.0.0.0:8003 seldon.protos.Seldon/Predict; \\\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![seldon-grpc-dashboard](seldon-grpc-dashboard.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    metric=!curl -s http://localhost:8003/seldon/seldon/grpc-seldon/prometheus | grep seldon_api_executor_server_requests_seconds_count\n",
    "    if metric and len(metric)>0:    \n",
    "        print(metric[0])\n",
    "        assert(not metric[0] == \"\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Failed to get metrics for grpc-seldon\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "for i in range(3):\n",
    "    metric=!curl -s http://localhost:8003/seldon/seldon/grpc-seldon/prometheus | grep seldon_api_executor_server_requests_seconds_summary_count\n",
    "    if metric and len(metric)>0:    \n",
    "        print(metric[0])\n",
    "        assert(not metric[0] == \"\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Failed to get metrics for grpc-seldon\")\n",
    "        time.sleep(2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f ${RESOURCES}/model_seldon_grpc.yaml -n seldon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Protocol REST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ${RESOURCES}/model_tfserving_rest.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f ${RESOURCES}/model_tfserving_rest.yaml -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=rest-tfserving \\\n",
    "                                 -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for i in `seq 1 60`; do \\\n",
    "   sleep 1 && curl -d '{\"instances\": [1.0, 2.0, 5.0]}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/rest-tfserving/v1/models/halfplustwo/:predict \\\n",
    "   -H \"Content-Type: application/json\"; \\\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    metric=!curl -s http://localhost:8003/seldon/seldon/rest-tfserving/prometheus | grep seldon_api_executor_server_requests_seconds_count\n",
    "    if metric and len(metric)>0:    \n",
    "        print(metric[0])\n",
    "        assert(not metric[0] == \"\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Failed to get metrics for rest-tfserving\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "for i in range(3):\n",
    "    metric=!curl -s http://localhost:8003/seldon/seldon/rest-tfserving/prometheus | grep seldon_api_executor_server_requests_seconds_summary_count\n",
    "    if metric and len(metric)>0:    \n",
    "        print(metric[0])\n",
    "        assert(not metric[0] == \"\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Failed to get metrics for rest-tfserving\")\n",
    "        time.sleep(2)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tfserving-rest-dashboard](tfserving-rest-dashboard.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f ${RESOURCES}/model_tfserving_rest.yaml -n seldon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Protocol GRPC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ${RESOURCES}/model_tfserving_grpc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f ${RESOURCES}/model_tfserving_grpc.yaml -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=grpc-tfserving \\\n",
    "                                 -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../../../executor/proto && for i in `seq 1 60`; do \\\n",
    " sleep 1 && grpcurl \\\n",
    "   -d '{\"model_spec\":{\"name\":\"halfplustwo\"},\"inputs\":{\"x\":{\"dtype\": 1, \"tensor_shape\": {\"dim\":[{\"size\": 3}]}, \"floatVal\" : [1.0, 2.0, 3.0]}}}' \\\n",
    "   -rpc-header seldon:grpc-tfserving -rpc-header namespace:seldon \\\n",
    "   -plaintext -proto ./prediction_service.proto \\\n",
    "   0.0.0.0:8003 tensorflow.serving.PredictionService/Predict; \\\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dashboard](tfserving-grpc-dashboard.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    metric=!curl -s http://localhost:8003/seldon/seldon/grpc-tfserving/prometheus | grep seldon_api_executor_server_requests_seconds_count\n",
    "    if metric and len(metric)>0:    \n",
    "        print(metric[0])\n",
    "        assert(not metric[0] == \"\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Failed to get metrics for grpc-tfserving\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "for i in range(3):\n",
    "    metric=!curl -s http://localhost:8003/seldon/seldon/grpc-tfserving/prometheus | grep seldon_api_executor_server_requests_seconds_summary_count\n",
    "    if metric and len(metric)>0:    \n",
    "        print(metric[0])\n",
    "        assert(not metric[0] == \"\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Failed to get metrics for grpc-tfserving\")\n",
    "        time.sleep(2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f ${RESOURCES}/model_tfserving_grpc.yaml -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm delete seldon-core-analytics -n seldon-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
