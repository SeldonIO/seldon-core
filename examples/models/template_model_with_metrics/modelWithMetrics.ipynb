{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Metrics\n",
    "\n",
    "Example testing a model with custom metrics.\n",
    "\n",
    "Metrics can be \n",
    "\n",
    "  * A ```COUNTER``` : the returned value will increment the current value\n",
    "  * A ```GAUGE``` : the returned value will overwrite the current value\n",
    "  * A ```TIMER``` : a number of millisecs. Prometheus SUM and COUNT metrics will be created.\n",
    "  \n",
    "You need to provide a list of dictionaries each with the following:\n",
    "\n",
    "  * a ```type``` : COUNTER, GAUGE, or TIMER\n",
    "  * a ```key``` : a user defined key\n",
    "  * a ```value``` : a float value\n",
    "  \n",
    "See example code below:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mModelWithMetrics\u001b[39;49;00m(\u001b[36mobject\u001b[39;49;00m):\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
      "        \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mInitialising\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mpredict\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m,X,features_names):\r\n",
      "        \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mPredict called\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m X\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mmetrics\u001b[39;49;00m():\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m [\r\n",
      "            {\u001b[33m\"\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[33m\"\u001b[39;49;00m\u001b[33mCOUNTER\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[33m\"\u001b[39;49;00m\u001b[33mkey\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[33m\"\u001b[39;49;00m\u001b[33mmycounter\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[33m\"\u001b[39;49;00m\u001b[33mvalue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[34m1\u001b[39;49;00m}, \u001b[37m# a counter which will increase by the given value\u001b[39;49;00m\r\n",
      "            {\u001b[33m\"\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[33m\"\u001b[39;49;00m\u001b[33mGAUGE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[33m\"\u001b[39;49;00m\u001b[33mkey\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[33m\"\u001b[39;49;00m\u001b[33mmygauge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[33m\"\u001b[39;49;00m\u001b[33mvalue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[34m100\u001b[39;49;00m}, \u001b[37m# a gauge which will be set to given value\u001b[39;49;00m\r\n",
      "            {\u001b[33m\"\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[33m\"\u001b[39;49;00m\u001b[33mTIMER\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[33m\"\u001b[39;49;00m\u001b[33mkey\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[33m\"\u001b[39;49;00m\u001b[33mmytimer\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[33m\"\u001b[39;49;00m\u001b[33mvalue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[34m20.2\u001b[39;49;00m}, \u001b[37m# a timer which will add sum and count metrics - assumed millisecs\u001b[39;49;00m\r\n",
      "            ]\r\n",
      "    \r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ModelWithMetrics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Installing application source...\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "!s2i build -E environment_rest . seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT model-with-metrics-rest:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d23013897d05f9b5028ddc8825eb8d2d90073e6ecbfda50d8d5e5e556f5453c9\r\n"
     ]
    }
   ],
   "source": [
    "!docker run --name \"model-with-metrics\" -d --rm -p 5000:5000 model-with-metrics-rest:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f proto/prediction*.py\r\n",
      "rm -f proto/prediction.proto\r\n",
      "rm -rf proto/__pycache__\r\n",
      "rm -f fbs/*.py\r\n",
      "rm -rf fbs/__pycache__\r\n",
      "cp ../../proto/prediction.proto ./proto\r\n",
      "python -m grpc.tools.protoc -I. --python_out=. --grpc_python_out=. ./proto/prediction.proto\r\n"
     ]
    }
   ],
   "source": [
    "!cd ../../../wrappers/testing && make build_protos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\r\n",
      "SENDING NEW REQUEST:\r\n",
      "{'meta': {}, 'data': {'names': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], 'ndarray': [[7.508, 4.0, 6.443, 2.41]]}}\r\n",
      "RECEIVED RESPONSE:\r\n",
      "{'data': {'names': ['t:0', 't:1', 't:2', 't:3'], 'ndarray': [[7.508, 4.0, 6.443, 2.41]]}, 'meta': {'metrics': [{'key': 'mycounter', 'type': 'COUNTER', 'value': 1}, {'key': 'mygauge', 'type': 'GAUGE', 'value': 100}, {'key': 'mytimer', 'type': 'TIMER', 'value': 20.2}]}}\r\n",
      "\r\n",
      "Time 0.0059931278228759766\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../../wrappers/testing/tester.py contract.json 0.0.0.0 5000 -p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-with-metrics\r\n"
     ]
    }
   ],
   "source": [
    "!docker rm model-with-metrics --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Installing application source...\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "!s2i build -E environment_grpc . seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT model-with-metrics-grpc:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4e68f0b1c988632b8811168983e21f724015c622d047d02fdeaeb8a06ed3e74d\r\n"
     ]
    }
   ],
   "source": [
    "!docker run --name \"model-with-metrics\" -d --rm -p 5000:5000 model-with-metrics-grpc:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f proto/prediction*.py\r\n",
      "rm -f proto/prediction.proto\r\n",
      "rm -rf proto/__pycache__\r\n",
      "rm -f fbs/*.py\r\n",
      "rm -rf fbs/__pycache__\r\n",
      "cp ../../proto/prediction.proto ./proto\r\n",
      "python -m grpc.tools.protoc -I. --python_out=. --grpc_python_out=. ./proto/prediction.proto\r\n"
     ]
    }
   ],
   "source": [
    "!cd ../../../wrappers/testing && make build_protos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\r\n",
      "SENDING NEW REQUEST:\r\n",
      "data {\r\n",
      "  names: \"sepal_length\"\r\n",
      "  names: \"sepal_width\"\r\n",
      "  names: \"petal_length\"\r\n",
      "  names: \"petal_width\"\r\n",
      "  ndarray {\r\n",
      "    values {\r\n",
      "      list_value {\r\n",
      "        values {\r\n",
      "          number_value: 7.428\r\n",
      "        }\r\n",
      "        values {\r\n",
      "          number_value: 3.564\r\n",
      "        }\r\n",
      "        values {\r\n",
      "          number_value: 5.525\r\n",
      "        }\r\n",
      "        values {\r\n",
      "          number_value: 1.467\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "RECEIVED RESPONSE:\r\n",
      "meta {\r\n",
      "  metrics {\r\n",
      "    key: \"mycounter\"\r\n",
      "    value: 1.0\r\n",
      "  }\r\n",
      "  metrics {\r\n",
      "    key: \"mygauge\"\r\n",
      "    type: GAUGE\r\n",
      "    value: 100.0\r\n",
      "  }\r\n",
      "  metrics {\r\n",
      "    key: \"mytimer\"\r\n",
      "    type: TIMER\r\n",
      "    value: 20.200000762939453\r\n",
      "  }\r\n",
      "}\r\n",
      "data {\r\n",
      "  names: \"t:0\"\r\n",
      "  names: \"t:1\"\r\n",
      "  names: \"t:2\"\r\n",
      "  names: \"t:3\"\r\n",
      "  ndarray {\r\n",
      "    values {\r\n",
      "      list_value {\r\n",
      "        values {\r\n",
      "          number_value: 7.428\r\n",
      "        }\r\n",
      "        values {\r\n",
      "          number_value: 3.564\r\n",
      "        }\r\n",
      "        values {\r\n",
      "          number_value: 5.525\r\n",
      "        }\r\n",
      "        values {\r\n",
      "          number_value: 1.467\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../../wrappers/testing/tester.py contract.json 0.0.0.0 5000 -p --grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-with-metrics\r\n"
     ]
    }
   ],
   "source": [
    "!docker rm model-with-metrics --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test using Minikube\n",
    "\n",
    "**Due to a [minikube/s2i issue](https://github.com/SeldonIO/seldon-core/issues/253) you will need Minikube version 0.25.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a newer version of minikube available (v0.30.0).  Download it here:\n",
      "https://github.com/kubernetes/minikube/releases/tag/v0.30.0\n",
      "\n",
      "To disable this notification, run the following:\n",
      "minikube config set WantUpdateNotification false\n",
      "Starting local Kubernetes v1.9.4 cluster...\n",
      "Starting VM...\n",
      "Getting VM IP address...\n",
      "Moving files into cluster...\n",
      "Setting up certs...\n",
      "Connecting to cluster...\n",
      "Setting up kubeconfig...\n",
      "Starting cluster components...\n",
      "Kubectl is now configured to use the cluster.\n",
      "Loading cached images from config file.\n"
     ]
    }
   ],
   "source": [
    "!minikube start --vm-driver kvm2 --memory 4096 --feature-gates=CustomResourceValidation=true --extra-config=apiserver.Authorization.Mode=RBAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusterrolebinding.rbac.authorization.k8s.io/kube-system-cluster-admin created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create clusterrolebinding kube-system-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$HELM_HOME has been configured at /home/clive/.helm.\n",
      "\n",
      "Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.\n",
      "\n",
      "Please note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy.\n",
      "To prevent this, run `helm init` with the --tiller-tls-verify flag.\n",
      "For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation\n",
      "Happy Helming!\n"
     ]
    }
   ],
   "source": [
    "!helm init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment \"tiller-deploy\" rollout to finish: 0 of 1 updated replicas are available...\n",
      "deployment \"tiller-deploy\" successfully rolled out\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deploy/tiller-deploy -n kube-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME:   seldon-core-crd\n",
      "LAST DEPLOYED: Sat Nov  3 08:25:19 2018\n",
      "NAMESPACE: default\n",
      "STATUS: DEPLOYED\n",
      "\n",
      "RESOURCES:\n",
      "==> v1/ServiceAccount\n",
      "NAME                        SECRETS  AGE\n",
      "seldon-spartakus-volunteer  1        0s\n",
      "\n",
      "==> v1beta1/ClusterRole\n",
      "NAME                        AGE\n",
      "seldon-spartakus-volunteer  0s\n",
      "\n",
      "==> v1beta1/ClusterRoleBinding\n",
      "NAME                        AGE\n",
      "seldon-spartakus-volunteer  0s\n",
      "\n",
      "==> v1/ConfigMap\n",
      "NAME                     DATA  AGE\n",
      "seldon-spartakus-config  3     1s\n",
      "\n",
      "==> v1beta1/CustomResourceDefinition\n",
      "NAME                                         AGE\n",
      "seldondeployments.machinelearning.seldon.io  0s\n",
      "\n",
      "==> v1beta1/Deployment\n",
      "NAME                        DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE\n",
      "seldon-spartakus-volunteer  1        0        0           0          0s\n",
      "\n",
      "\n",
      "NOTES:\n",
      "NOTES: TODO\n",
      "\n",
      "\n",
      "NAME:   seldon-core\n",
      "LAST DEPLOYED: Sat Nov  3 08:25:20 2018\n",
      "NAMESPACE: default\n",
      "STATUS: DEPLOYED\n",
      "\n",
      "RESOURCES:\n",
      "==> v1/ClusterRoleBinding\n",
      "NAME            AGE\n",
      "seldon-default  0s\n",
      "\n",
      "==> v1beta1/Role\n",
      "NAME          AGE\n",
      "seldon-local  0s\n",
      "\n",
      "==> v1/RoleBinding\n",
      "NAME    AGE\n",
      "seldon  0s\n",
      "\n",
      "==> v1/Service\n",
      "NAME                          TYPE       CLUSTER-IP     EXTERNAL-IP  PORT(S)                        AGE\n",
      "seldon-core-seldon-apiserver  NodePort   10.108.30.143  <none>       8080:30088/TCP,5000:31980/TCP  0s\n",
      "seldon-core-redis             ClusterIP  10.109.3.187   <none>       6379/TCP                       0s\n",
      "\n",
      "==> v1beta1/Deployment\n",
      "NAME                                DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE\n",
      "seldon-core-seldon-apiserver        1        1        1           0          0s\n",
      "seldon-core-seldon-cluster-manager  1        1        1           0          0s\n",
      "seldon-core-redis                   1        1        1           0          0s\n",
      "\n",
      "==> v1/Pod(related)\n",
      "NAME                                                 READY  STATUS             RESTARTS  AGE\n",
      "seldon-core-seldon-apiserver-5976c46469-tq2l8        0/1    ContainerCreating  0         0s\n",
      "seldon-core-seldon-cluster-manager-55db6c898c-p6mk8  0/1    ContainerCreating  0         0s\n",
      "seldon-core-redis-98c4948f7-gm5sv                    0/1    ContainerCreating  0         0s\n",
      "\n",
      "==> v1/ServiceAccount\n",
      "NAME    SECRETS  AGE\n",
      "seldon  1        0s\n",
      "\n",
      "==> v1beta1/ClusterRole\n",
      "NAME                AGE\n",
      "seldon-crd-default  0s\n",
      "\n",
      "\n",
      "NOTES:\n",
      "Thank you for installing Seldon Core.\n",
      "\n",
      "Documentation can be found at https://github.com/SeldonIO/seldon-core\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!helm install ../../../helm-charts/seldon-core-crd --name seldon-core-crd  --set usage_metrics.enabled=true\n",
    "!helm install ../../../helm-charts/seldon-core --name seldon-core "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME:   seldon-core-analytics\n",
      "LAST DEPLOYED: Sat Nov  3 08:31:02 2018\n",
      "NAMESPACE: default\n",
      "STATUS: DEPLOYED\n",
      "\n",
      "RESOURCES:\n",
      "==> v1beta1/DaemonSet\n",
      "NAME                      DESIRED  CURRENT  READY  UP-TO-DATE  AVAILABLE  NODE SELECTOR  AGE\n",
      "prometheus-node-exporter  1        1        0      1           0          <none>         1s\n",
      "\n",
      "==> v1/Secret\n",
      "NAME                 TYPE    DATA  AGE\n",
      "grafana-prom-secret  Opaque  1     1s\n",
      "\n",
      "==> v1/ServiceAccount\n",
      "NAME        SECRETS  AGE\n",
      "prometheus  1        1s\n",
      "\n",
      "==> v1beta1/ClusterRole\n",
      "NAME        AGE\n",
      "prometheus  1s\n",
      "\n",
      "==> v1beta1/ClusterRoleBinding\n",
      "NAME        AGE\n",
      "prometheus  1s\n",
      "\n",
      "==> v1beta1/Deployment\n",
      "NAME                     DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE\n",
      "alertmanager-deployment  1        1        1           0          1s\n",
      "grafana-prom-deployment  1        1        1           0          1s\n",
      "prometheus-deployment    1        1        1           0          1s\n",
      "\n",
      "==> v1/Service\n",
      "NAME                      TYPE       CLUSTER-IP     EXTERNAL-IP  PORT(S)       AGE\n",
      "alertmanager              ClusterIP  10.97.126.206  <none>       80/TCP        1s\n",
      "grafana-prom              NodePort   10.109.58.248  <none>       80:31930/TCP  1s\n",
      "prometheus-node-exporter  ClusterIP  None           <none>       9100/TCP      1s\n",
      "prometheus-seldon         ClusterIP  10.97.11.205   <none>       80/TCP        0s\n",
      "\n",
      "==> v1/ConfigMap\n",
      "NAME                       DATA  AGE\n",
      "alertmanager-server-conf   1     1s\n",
      "grafana-import-dashboards  7     1s\n",
      "prometheus-rules           4     1s\n",
      "prometheus-server-conf     1     1s\n",
      "\n",
      "==> v1/Job\n",
      "NAME                            DESIRED  SUCCESSFUL  AGE\n",
      "grafana-prom-import-dashboards  1        0           1s\n",
      "\n",
      "==> v1/Pod(related)\n",
      "NAME                                      READY  STATUS             RESTARTS  AGE\n",
      "grafana-prom-import-dashboards-4s2rl      0/1    ContainerCreating  0         1s\n",
      "alertmanager-deployment-547b86cb67-qlfq4  0/1    ContainerCreating  0         1s\n",
      "grafana-prom-deployment-7b45fb85d4-56jxs  0/1    ContainerCreating  0         1s\n",
      "prometheus-node-exporter-thzpc            0/1    ContainerCreating  0         1s\n",
      "prometheus-deployment-675fdfb9c8-rdxcs    0/1    ContainerCreating  0         1s\n",
      "\n",
      "\n",
      "NOTES:\n",
      "NOTES: TODO\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!helm install seldon-core-analytics --name seldon-core-analytics --set grafana_prom_admin_password=password --set persistence.enabled=false --repo https://storage.googleapis.com/seldon-charts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1103 08:44:32.398667   32003 build.go:50] Running S2I version \"v1.1.12\"\n",
      "I1103 08:44:32.398790   32003 util.go:58] Getting docker credentials for seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT\n",
      "I1103 08:44:32.398809   32003 util.go:74] Using  credentials for pulling seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT\n",
      "I1103 08:44:32.429416   32003 docker.go:487] Using locally available image \"seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT\"\n",
      "I1103 08:44:32.430628   32003 build.go:163] \n",
      "Builder Image:\t\t\tseldonio/seldon-core-s2i-python3:0.3-SNAPSHOT\n",
      "Source:\t\t\t\t.\n",
      "Output Image Tag:\t\tmodel-with-metrics-rest:0.1\n",
      "Environment:\t\t\tPERSISTENCE=0,MODEL_NAME=ModelWithMetrics,API_TYPE=REST,SERVICE_TYPE=MODEL\n",
      "Environment File:\t\tenvironment_rest\n",
      "Labels:\t\t\t\t\n",
      "Incremental Build:\t\tdisabled\n",
      "Remove Old Build:\t\tdisabled\n",
      "Builder Pull Policy:\t\tif-not-present\n",
      "Previous Image Pull Policy:\tif-not-present\n",
      "Quiet:\t\t\t\tdisabled\n",
      "Layered Build:\t\t\tdisabled\n",
      "Docker Endpoint:\t\ttcp://192.168.39.12:2376\n",
      "Docker Pull Config:\t\t/home/clive/.docker/config.json\n",
      "Docker Pull User:\t\tcliveseldon\n",
      "\n",
      "I1103 08:44:32.431948   32003 docker.go:487] Using locally available image \"seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT\"\n",
      "I1103 08:44:32.437483   32003 docker.go:487] Using locally available image \"seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT\"\n",
      "I1103 08:44:32.437496   32003 docker.go:718] Image sha256:da9e01bbfac1dc10c7662d401472d248b8dd4971590746c3f9f9e2b168ec414d contains io.openshift.s2i.scripts-url set to \"image:///s2i/bin\"\n",
      "I1103 08:44:32.437507   32003 scm.go:20] DownloadForSource .\n",
      "I1103 08:44:32.437533   32003 sti.go:204] Preparing to build model-with-metrics-rest:0.1\n",
      "I1103 08:44:32.437650   32003 download.go:38] Copying sources from \".\" to \"/tmp/s2i235039620/upload/src\"\n",
      "I1103 08:44:32.437723   32003 fs.go:260] F \"contract.json\" -> \"/tmp/s2i235039620/upload/src/contract.json\"\n",
      "I1103 08:44:32.437767   32003 fs.go:260] F \"deployment-rest.json\" -> \"/tmp/s2i235039620/upload/src/deployment-rest.json\"\n",
      "I1103 08:44:32.437801   32003 fs.go:260] F \"modelWithMetrics.ipynb\" -> \"/tmp/s2i235039620/upload/src/modelWithMetrics.ipynb\"\n",
      "I1103 08:44:32.437901   32003 fs.go:260] F \"environment_rest\" -> \"/tmp/s2i235039620/upload/src/environment_rest\"\n",
      "I1103 08:44:32.437933   32003 fs.go:260] F \"environment_rest~\" -> \"/tmp/s2i235039620/upload/src/environment_rest~\"\n",
      "I1103 08:44:32.437964   32003 fs.go:260] F \"ModelWithMetrics.py~\" -> \"/tmp/s2i235039620/upload/src/ModelWithMetrics.py~\"\n",
      "I1103 08:44:32.437996   32003 fs.go:260] F \"deployment-grpc.json\" -> \"/tmp/s2i235039620/upload/src/deployment-grpc.json\"\n",
      "I1103 08:44:32.438032   32003 fs.go:260] F \"deployment-rest.json~\" -> \"/tmp/s2i235039620/upload/src/deployment-rest.json~\"\n",
      "I1103 08:44:32.438228   32003 fs.go:247] D \".ipynb_checkpoints\" -> \"/tmp/s2i235039620/upload/src/.ipynb_checkpoints\"\n",
      "I1103 08:44:32.438313   32003 fs.go:260] F \".ipynb_checkpoints/modelWithMetrics-checkpoint.ipynb\" -> \"/tmp/s2i235039620/upload/src/.ipynb_checkpoints/modelWithMetrics-checkpoint.ipynb\"\n",
      "I1103 08:44:32.438477   32003 fs.go:260] F \"environment_grpc~\" -> \"/tmp/s2i235039620/upload/src/environment_grpc~\"\n",
      "I1103 08:44:32.438570   32003 fs.go:260] F \"ModelWithMetrics.py\" -> \"/tmp/s2i235039620/upload/src/ModelWithMetrics.py\"\n",
      "I1103 08:44:32.438684   32003 fs.go:260] F \"environment_grpc\" -> \"/tmp/s2i235039620/upload/src/environment_grpc\"\n",
      "I1103 08:44:32.438736   32003 fs.go:260] F \"deployment-grpc.json~\" -> \"/tmp/s2i235039620/upload/src/deployment-grpc.json~\"\n",
      "I1103 08:44:32.438808   32003 install.go:261] Using \"assemble\" installed from \"image:///s2i/bin/assemble\"\n",
      "I1103 08:44:32.438835   32003 install.go:261] Using \"run\" installed from \"image:///s2i/bin/run\"\n",
      "I1103 08:44:32.438847   32003 install.go:261] Using \"save-artifacts\" installed from \"image:///s2i/bin/save-artifacts\"\n",
      "I1103 08:44:32.438862   32003 ignore.go:64] .s2iignore file does not exist\n",
      "I1103 08:44:32.438869   32003 sti.go:213] Clean build will be performed\n",
      "I1103 08:44:32.438874   32003 sti.go:216] Performing source build from .\n",
      "I1103 08:44:32.438880   32003 sti.go:227] Running \"assemble\" in \"model-with-metrics-rest:0.1\"\n",
      "I1103 08:44:32.438884   32003 sti.go:573] Using image name seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT\n",
      "I1103 08:44:32.440264   32003 docker.go:487] Using locally available image \"seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT\"\n",
      "I1103 08:44:32.440278   32003 sti.go:453] No user environment provided (no environment file found in application sources)\n",
      "I1103 08:44:32.440304   32003 sti.go:691] starting the source uploading ...\n",
      "I1103 08:44:32.440318   32003 tar.go:217] Adding \"/tmp/s2i235039620/upload\" to tar ...\n",
      "I1103 08:44:32.440365   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/scripts as scripts\n",
      "I1103 08:44:32.442743   32003 docker.go:718] Image sha256:da9e01bbfac1dc10c7662d401472d248b8dd4971590746c3f9f9e2b168ec414d contains io.openshift.s2i.scripts-url set to \"image:///s2i/bin\"\n",
      "I1103 08:44:32.442752   32003 docker.go:793] Base directory for S2I scripts is '/s2i/bin'. Untarring destination is '/tmp'.\n",
      "I1103 08:44:32.442759   32003 docker.go:949] Setting \"/bin/sh -c tar -C /tmp -xf - && /s2i/bin/assemble\" command for container ...\n",
      "I1103 08:44:32.442837   32003 docker.go:958] Creating container with options {Name:\"s2i_seldonio_seldon_core_s2i_python3_0_3_SNAPSHOT_4f7236f8\" Config:{Hostname: Domainname: User: AttachStdin:false AttachStdout:true AttachStderr:false ExposedPorts:map[] Tty:false OpenStdin:true StdinOnce:true Env:[PERSISTENCE=0 MODEL_NAME=ModelWithMetrics API_TYPE=REST SERVICE_TYPE=MODEL] Cmd:[/bin/sh -c tar -C /tmp -xf - && /s2i/bin/assemble] Healthcheck:<nil> ArgsEscaped:false Image:seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT Volumes:map[] WorkingDir: Entrypoint:[] NetworkDisabled:false MacAddress: OnBuild:[] Labels:map[] StopSignal: StopTimeout:<nil> Shell:[]} HostConfig:&{Binds:[] ContainerIDFile: LogConfig:{Type: Config:map[]} NetworkMode: PortBindings:map[] RestartPolicy:{Name: MaximumRetryCount:0} AutoRemove:false VolumeDriver: VolumesFrom:[] CapAdd:[] CapDrop:[] DNS:[] DNSOptions:[] DNSSearch:[] ExtraHosts:[] GroupAdd:[] IpcMode: Cgroup: Links:[] OomScoreAdj:0 PidMode: Privileged:false PublishAllPorts:false ReadonlyRootfs:false SecurityOpt:[] StorageOpt:map[] Tmpfs:map[] UTSMode: UsernsMode: ShmSize:67108864 Sysctls:map[] Runtime: ConsoleSize:[0 0] Isolation: Resources:{CPUShares:0 Memory:0 NanoCPUs:0 CgroupParent: BlkioWeight:0 BlkioWeightDevice:[] BlkioDeviceReadBps:[] BlkioDeviceWriteBps:[] BlkioDeviceReadIOps:[] BlkioDeviceWriteIOps:[] CPUPeriod:0 CPUQuota:0 CPURealtimePeriod:0 CPURealtimeRuntime:0 CpusetCpus: CpusetMems: Devices:[] DeviceCgroupRules:[] DiskQuota:0 KernelMemory:0 MemoryReservation:0 MemorySwap:0 MemorySwappiness:<nil> OomKillDisable:<nil> PidsLimit:0 Ulimits:[] CPUCount:0 CPUPercent:0 IOMaximumIOps:0 IOMaximumBandwidth:0} Mounts:[] Init:<nil>}} ...\n",
      "I1103 08:44:32.478500   32003 docker.go:990] Attaching to container \"4331b83d9b680f4b1ee67ed31a2d94c7fe3ee14c723dcd34a03a7eaee3054e87\" ...\n",
      "I1103 08:44:32.485787   32003 docker.go:1001] Starting container \"4331b83d9b680f4b1ee67ed31a2d94c7fe3ee14c723dcd34a03a7eaee3054e87\" ...\n",
      "I1103 08:44:32.657935   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src as src\n",
      "I1103 08:44:32.658128   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/.ipynb_checkpoints as src/.ipynb_checkpoints\n",
      "I1103 08:44:32.658273   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/.ipynb_checkpoints/modelWithMetrics-checkpoint.ipynb as src/.ipynb_checkpoints/modelWithMetrics-checkpoint.ipynb\n",
      "I1103 08:44:32.658622   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/ModelWithMetrics.py as src/ModelWithMetrics.py\n",
      "I1103 08:44:32.658727   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/ModelWithMetrics.py~ as src/ModelWithMetrics.py~\n",
      "I1103 08:44:32.658800   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/contract.json as src/contract.json\n",
      "I1103 08:44:32.658954   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/deployment-grpc.json as src/deployment-grpc.json\n",
      "I1103 08:44:32.659076   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/deployment-grpc.json~ as src/deployment-grpc.json~\n",
      "I1103 08:44:32.659194   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/deployment-rest.json as src/deployment-rest.json\n",
      "I1103 08:44:32.659308   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/deployment-rest.json~ as src/deployment-rest.json~\n",
      "I1103 08:44:32.659401   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/environment_grpc as src/environment_grpc\n",
      "I1103 08:44:32.659468   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/environment_grpc~ as src/environment_grpc~\n",
      "I1103 08:44:32.659582   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/environment_rest as src/environment_rest\n",
      "I1103 08:44:32.659682   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/environment_rest~ as src/environment_rest~\n",
      "I1103 08:44:32.659782   32003 tar.go:312] Adding to tar: /tmp/s2i235039620/upload/src/modelWithMetrics.ipynb as src/modelWithMetrics.ipynb\n",
      "I1103 08:44:32.674667   32003 sti.go:699] ---> Installing application source...\n",
      "I1103 08:44:32.691908   32003 docker.go:1032] Waiting for container \"4331b83d9b680f4b1ee67ed31a2d94c7fe3ee14c723dcd34a03a7eaee3054e87\" to stop ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1103 08:44:32.760107   32003 docker.go:1057] Invoking PostExecute function\n",
      "I1103 08:44:32.760121   32003 postexecutorstep.go:68] Skipping step: store previous image\n",
      "I1103 08:44:32.760124   32003 postexecutorstep.go:117] Executing step: commit image\n",
      "I1103 08:44:32.761864   32003 postexecutorstep.go:522] Checking for new Labels to apply... \n",
      "I1103 08:44:32.761878   32003 postexecutorstep.go:530] Creating the download path '/tmp/s2i235039620/metadata'\n",
      "I1103 08:44:32.761941   32003 postexecutorstep.go:464] Downloading file \"/tmp/.s2i/image_metadata.json\"\n",
      "I1103 08:44:32.790762   32003 postexecutorstep.go:538] unable to download and extract 'image_metadata.json' ... continuing\n",
      "I1103 08:44:32.793620   32003 docker.go:1091] Committing container with dockerOpts: {Reference:model-with-metrics-rest:0.1 Comment: Author: Changes:[] Pause:false Config:0xc4203baf00}, config: {Hostname: Domainname: User: AttachStdin:false AttachStdout:false AttachStderr:false ExposedPorts:map[] Tty:false OpenStdin:false StdinOnce:false Env:[PERSISTENCE=0 MODEL_NAME=ModelWithMetrics API_TYPE=REST SERVICE_TYPE=MODEL] Cmd:[/s2i/bin/run] Healthcheck:<nil> ArgsEscaped:false Image: Volumes:map[] WorkingDir: Entrypoint:[] NetworkDisabled:false MacAddress: OnBuild:[] Labels:map[io.openshift.s2i.build.source-location:. io.openshift.s2i.scripts-url:image:///s2i/bin io.k8s.display-name:model-with-metrics-rest:0.1 io.openshift.s2i.build.image:seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT] StopSignal: StopTimeout:<nil> Shell:[]}\n",
      "I1103 08:44:32.860274   32003 postexecutorstep.go:392] Executing step: report success\n",
      "I1103 08:44:32.860286   32003 postexecutorstep.go:397] Successfully built model-with-metrics-rest:0.1\n",
      "I1103 08:44:32.860291   32003 postexecutorstep.go:93] Skipping step: remove previous image\n",
      "I1103 08:44:32.860334   32003 docker.go:968] Removing container \"4331b83d9b680f4b1ee67ed31a2d94c7fe3ee14c723dcd34a03a7eaee3054e87\" ...\n",
      "I1103 08:44:32.871253   32003 docker.go:978] Removed container \"4331b83d9b680f4b1ee67ed31a2d94c7fe3ee14c723dcd34a03a7eaee3054e87\"\n",
      "I1103 08:44:32.871376   32003 cleanup.go:33] Removing temporary directory /tmp/s2i235039620\n",
      "I1103 08:44:32.871384   32003 fs.go:302] Removing directory '/tmp/s2i235039620'\n",
      "I1103 08:44:32.871717   32003 build.go:175] Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "!eval $(minikube docker-env) && s2i build -E environment_rest . seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT model-with-metrics-rest:0.1 --loglevel 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/mymodel created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f deployment-rest.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until ready (replicas == replicasAvailable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map[predictorStatus:[map[name:mymodel-mymodel-svc-orch replicas:1 replicasAvailable:1] map[replicas:1 replicasAvailable:1 name:mymodel-mymodel-complex-model-0]] state:Available]"
     ]
    }
   ],
   "source": [
    "!kubectl get seldondeployments mymodel -o jsonpath='{.status}' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f proto/prediction*.py\r\n",
      "rm -f proto/prediction.proto\r\n",
      "rm -rf proto/__pycache__\r\n",
      "mkdir -p ./proto\r\n",
      "touch ./proto/__init__.py\r\n",
      "cp ../../proto/prediction.proto ./proto\r\n",
      "python -m grpc.tools.protoc -I. --python_out=. --grpc_python_out=. ./proto/prediction.proto\r\n"
     ]
    }
   ],
   "source": [
    "!cd ../../../util/api_tester && make build_protos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "SENDING NEW REQUEST:\n",
      "{'meta': {}, 'data': {'names': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], 'ndarray': [[5.314392890434304, 2.0870503600642127, 7.4093196094849265, 2.808545702671992]]}}\n",
      "Getting token from http://192.168.39.12:30088/oauth/token\n",
      "{\"access_token\":\"07b7e438-8d7e-48b6-82d2-9d310f515757\",\"token_type\":\"bearer\",\"expires_in\":42150,\"scope\":\"read write\"}\n",
      "RECEIVED RESPONSE:\n",
      "{'meta': {'puid': 's5evocddmdohugpqqv5iddc7po', 'tags': {}, 'routing': {}, 'requestPath': {'complex-model': 'model-with-metrics-rest:0.1'}, 'metrics': [{'key': 'mycounter', 'type': 'COUNTER', 'value': 1.0}, {'key': 'mygauge', 'type': 'GAUGE', 'value': 100.0}, {'key': 'mytimer', 'type': 'TIMER', 'value': 20.2}]}, 'data': {'names': ['t:0', 't:1', 't:2', 't:3'], 'ndarray': [[5.314392890434304, 2.0870503600642127, 7.4093196094849265, 2.808545702671992]]}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../../../util/api_tester/api-tester.py contract.json \\\n",
    "    `minikube ip` `kubectl get svc -l app=seldon-apiserver-container-app -o jsonpath='{.items[0].spec.ports[0].nodePort}'` \\\n",
    "    --oauth-key oauth-key --oauth-secret oauth-secret -p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"mymodel\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f deployment-rest.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Installing application source...\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "!eval $(minikube docker-env) && s2i build -E environment_grpc . seldonio/seldon-core-s2i-python3:0.3-SNAPSHOT model-with-metrics-grpc:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/mymodel created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f deployment-grpc.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until ready (replicas == replicasAvailable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map[predictorStatus:[map[replicas:1 replicasAvailable:1 name:mymodel-mymodel-svc-orch] map[name:mymodel-mymodel-complex-model-0 replicas:1 replicasAvailable:1]] state:Available]"
     ]
    }
   ],
   "source": [
    "!kubectl get seldondeployments mymodel -o jsonpath='{.status}' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f proto/prediction*.py\r\n",
      "rm -f proto/prediction.proto\r\n",
      "rm -rf proto/__pycache__\r\n",
      "mkdir -p ./proto\r\n",
      "touch ./proto/__init__.py\r\n",
      "cp ../../proto/prediction.proto ./proto\r\n",
      "python -m grpc.tools.protoc -I. --python_out=. --grpc_python_out=. ./proto/prediction.proto\r\n"
     ]
    }
   ],
   "source": [
    "!cd ../../../util/api_tester && make build_protos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "SENDING NEW REQUEST:\n",
      "data {\n",
      "  names: \"sepal_length\"\n",
      "  names: \"sepal_width\"\n",
      "  names: \"petal_length\"\n",
      "  names: \"petal_width\"\n",
      "  ndarray {\n",
      "    values {\n",
      "      list_value {\n",
      "        values {\n",
      "          number_value: 7.294562576598512\n",
      "        }\n",
      "        values {\n",
      "          number_value: 3.6624031290151073\n",
      "        }\n",
      "        values {\n",
      "          number_value: 2.755651138726249\n",
      "        }\n",
      "        values {\n",
      "          number_value: 1.2337746487942007\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Getting token from http://192.168.39.12:30088/oauth/token\n",
      "{\"access_token\":\"07b7e438-8d7e-48b6-82d2-9d310f515757\",\"token_type\":\"bearer\",\"expires_in\":40402,\"scope\":\"read write\"}\n",
      "RECEIVED RESPONSE:\n",
      "meta {\n",
      "  puid: \"if7btsi0i34p44tjfaj6adkst\"\n",
      "  requestPath {\n",
      "    key: \"complex-model\"\n",
      "    value: \"model-with-metrics-grpc:0.1\"\n",
      "  }\n",
      "  metrics {\n",
      "    key: \"mycounter\"\n",
      "    value: 1.0\n",
      "  }\n",
      "  metrics {\n",
      "    key: \"mygauge\"\n",
      "    type: GAUGE\n",
      "    value: 100.0\n",
      "  }\n",
      "  metrics {\n",
      "    key: \"mytimer\"\n",
      "    type: TIMER\n",
      "    value: 20.200000762939453\n",
      "  }\n",
      "}\n",
      "data {\n",
      "  names: \"t:0\"\n",
      "  names: \"t:1\"\n",
      "  names: \"t:2\"\n",
      "  names: \"t:3\"\n",
      "  ndarray {\n",
      "    values {\n",
      "      list_value {\n",
      "        values {\n",
      "          number_value: 7.294562576598512\n",
      "        }\n",
      "        values {\n",
      "          number_value: 3.6624031290151073\n",
      "        }\n",
      "        values {\n",
      "          number_value: 2.755651138726249\n",
      "        }\n",
      "        values {\n",
      "          number_value: 1.2337746487942007\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../../../util/api_tester/api-tester.py contract.json \\\n",
    "    `minikube ip` `kubectl get svc -l app=seldon-apiserver-container-app -o jsonpath='{.items[0].spec.ports[1].nodePort}'` \\\n",
    "    --oauth-key oauth-key --oauth-secret oauth-secret -p --grpc --oauth-port `kubectl get svc -l app=seldon-apiserver-container-app -o jsonpath='{.items[0].spec.ports[0].nodePort}'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "SENDING NEW REQUEST:\n",
      "request {\n",
      "  data {\n",
      "    names: \"sepal_length\"\n",
      "    names: \"sepal_width\"\n",
      "    names: \"petal_length\"\n",
      "    names: \"petal_width\"\n",
      "    ndarray {\n",
      "      values {\n",
      "        list_value {\n",
      "          values {\n",
      "            number_value: 4.892674496650631\n",
      "          }\n",
      "          values {\n",
      "            number_value: 4.742377470286767\n",
      "          }\n",
      "          values {\n",
      "            number_value: 2.851798122512135\n",
      "          }\n",
      "          values {\n",
      "            number_value: 0.004773596258239476\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "response {\n",
      "  data {\n",
      "    names: \"class1\"\n",
      "    names: \"class2\"\n",
      "    names: \"class3\"\n",
      "    ndarray {\n",
      "      values {\n",
      "        list_value {\n",
      "          values {\n",
      "            number_value: 0.8873412759534708\n",
      "          }\n",
      "          values {\n",
      "            number_value: 0.6945005393322701\n",
      "          }\n",
      "          values {\n",
      "            number_value: 0.18687912951259333\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "reward: 1.0\n",
      "\n",
      "Getting token from http://192.168.39.88:30552/oauth/token\n",
      "{\"access_token\":\"83061770-7057-4e82-aa6d-ea310e9749b3\",\"token_type\":\"bearer\",\"expires_in\":42539,\"scope\":\"read write\"}\n",
      "RECEIVED RESPONSE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../../../util/api_tester/api-tester.py contract.json \\\n",
    "    `minikube ip` `kubectl get svc -l app=seldon-apiserver-container-app -o jsonpath='{.items[0].spec.ports[1].nodePort}'` \\\n",
    "    --oauth-key oauth-key --oauth-secret oauth-secret -p --endpoint send-feedback --grpc --oauth-port `kubectl get svc -l app=seldon-apiserver-container-app -o jsonpath='{.items[0].spec.ports[0].nodePort}'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"mymodel\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f deployment-grpc.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting local Kubernetes cluster...\n",
      "Machine deleted.\n"
     ]
    }
   ],
   "source": [
    "!minikube delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
