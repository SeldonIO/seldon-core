{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoscaling Seldon Deployments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    " \n",
    "- The cluster should have `metric-server` running in the `kube-system` namespace\n",
    "- For Kind install `../../testing/scripts/metrics.yaml` See https://github.com/kubernetes-sigs/kind/issues/398\n",
    "- For Minikube run:\n",
    "    \n",
    "    ```\n",
    "    minikube addons enable metrics-server\n",
    "    ```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Seldon Core\n",
    "\n",
    "Use the setup notebook to [Setup Cluster](https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html#Setup-Cluster) with [Ambassador Ingress](https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html#Ambassador) and [Install Seldon Core](https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html#Install-Seldon-Core). Instructions [also online](https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): namespaces \"seldon\" already exists\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"kind-kind\" modified.\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model with autoscaler\n",
    "\n",
    "To create a model with an HorizontalPodAutoscaler there are three steps:\n",
    "\n",
    "\n",
    "  1. Ensure you have a resource request for the metric you want to scale on if it is a standard metric such as cpu or memory, e.g.:\n",
    "  \n",
    "```\n",
    "          resources:\n",
    "            requests:\n",
    "              cpu: '0.5'\n",
    "     \n",
    "```\n",
    "     \n",
    "  1. Add an HPA Spec referring to this Deployment, e.g.:\n",
    "  \n",
    "```\n",
    "    - hpaSpec:\n",
    "        maxReplicas: 3\n",
    "        metrics:\n",
    "        - resource:\n",
    "            name: cpu\n",
    "            targetAverageUtilization: 10\n",
    "          type: Resource\n",
    "        minReplicas: 1\n",
    "\n",
    "```\n",
    "\n",
    "The full SeldonDeployment spec is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34;01mapiVersion\u001b[39;49;00m: machinelearning.seldon.io/v1\r\n",
      "\u001b[34;01mkind\u001b[39;49;00m: SeldonDeployment\r\n",
      "\u001b[34;01mmetadata\u001b[39;49;00m:\r\n",
      "  \u001b[34;01mname\u001b[39;49;00m: seldon-model\r\n",
      "\u001b[34;01mspec\u001b[39;49;00m:\r\n",
      "  \u001b[34;01mname\u001b[39;49;00m: test-deployment\r\n",
      "  \u001b[34;01mpredictors\u001b[39;49;00m:\r\n",
      "  - \u001b[34;01mcomponentSpecs\u001b[39;49;00m:\r\n",
      "    - \u001b[34;01mhpaSpec\u001b[39;49;00m:\r\n",
      "        \u001b[34;01mmaxReplicas\u001b[39;49;00m: 3\r\n",
      "        \u001b[34;01mmetrics\u001b[39;49;00m:\r\n",
      "        - \u001b[34;01mresource\u001b[39;49;00m:\r\n",
      "            \u001b[34;01mname\u001b[39;49;00m: cpu\r\n",
      "            \u001b[34;01mtargetAverageUtilization\u001b[39;49;00m: 10\r\n",
      "          \u001b[34;01mtype\u001b[39;49;00m: Resource\r\n",
      "        \u001b[34;01mminReplicas\u001b[39;49;00m: 1\r\n",
      "      \u001b[34;01mspec\u001b[39;49;00m:\r\n",
      "        \u001b[34;01mcontainers\u001b[39;49;00m:\r\n",
      "        - \u001b[34;01mimage\u001b[39;49;00m: seldonio/mock_classifier:1.5.0-dev\r\n",
      "          \u001b[34;01mimagePullPolicy\u001b[39;49;00m: IfNotPresent\r\n",
      "          \u001b[34;01mname\u001b[39;49;00m: classifier\r\n",
      "          \u001b[34;01mresources\u001b[39;49;00m:\r\n",
      "            \u001b[34;01mrequests\u001b[39;49;00m:\r\n",
      "              \u001b[34;01mcpu\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m0.5\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "        \u001b[34;01mterminationGracePeriodSeconds\u001b[39;49;00m: 1\r\n",
      "    \u001b[34;01mgraph\u001b[39;49;00m:\r\n",
      "      \u001b[34;01mchildren\u001b[39;49;00m: []\r\n",
      "      \u001b[34;01mname\u001b[39;49;00m: classifier\r\n",
      "      \u001b[34;01mtype\u001b[39;49;00m: MODEL\r\n",
      "    \u001b[34;01mname\u001b[39;49;00m: example\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize model_with_hpa.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/seldon-model created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f model_with_hpa.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment \"seldon-model-example-0-classifier\" rollout to finish: 0 of 1 updated replicas are available...\n",
      "deployment \"seldon-model-example-0-classifier\" successfully rolled out\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=seldon-model -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Load\n",
    "\n",
    "We label some nodes for the loadtester. We attempt the first two as for Kind the first node shown will be the master."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'role' already has a value (locust), and --overwrite is false\n",
      "error: 'role' already has a value (locust), and --overwrite is false\n"
     ]
    }
   ],
   "source": [
    "!kubectl label nodes $(kubectl get nodes -o jsonpath='{.items[0].metadata.name}') role=locust\n",
    "!kubectl label nodes $(kubectl get nodes -o jsonpath='{.items[1].metadata.name}') role=locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: loadtester\r\n",
      "LAST DEPLOYED: Sun Nov  1 13:13:47 2020\r\n",
      "NAMESPACE: seldon\r\n",
      "STATUS: deployed\r\n",
      "REVISION: 1\r\n",
      "TEST SUITE: None\r\n"
     ]
    }
   ],
   "source": [
    "!helm install loadtester ../../../helm-charts/seldon-core-loadtesting  \\\n",
    "    --set locust.host=http://seldon-model-example:8000 \\\n",
    "    --set oauth.enabled=false \\\n",
    "    --set locust.hatchRate=1 \\\n",
    "    --set locust.clients=1 \\\n",
    "    --set loadtest.sendFeedback=0 \\\n",
    "    --set locust.minWait=0 \\\n",
    "    --set locust.maxWait=0 \\\n",
    "    --set replicaCount=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few mins you should see the deployment `my-dep` scaled to 3 deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "def getNumberPods():\n",
    "    dp = !kubectl get deployment seldon-model-example-0-classifier -o json\n",
    "    dp = json.loads(\"\".join(dp))\n",
    "    return dp[\"status\"][\"replicas\"]\n",
    "\n",
    "\n",
    "scaled = False\n",
    "for i in range(60):\n",
    "    pods = getNumberPods()\n",
    "    print(pods)\n",
    "    if pods > 1:\n",
    "        scaled = True\n",
    "        break\n",
    "    time.sleep(5)\n",
    "assert scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get pods,deployments,hpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Load\n",
    "After 5-10 mins you should see the deployments replicas decrease to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release \"loadtester\" uninstalled\r\n"
     ]
    }
   ],
   "source": [
    "!helm delete loadtester -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                     READY   STATUS    RESTARTS   AGE\r\n",
      "pod/ambassador-6747c68887-2rddl                          1/1     Running   0          22h\r\n",
      "pod/jaeger-5cb557b89d-khfb8                              1/1     Running   0          22h\r\n",
      "pod/jaeger-operator-67777ffc99-m25fp                     1/1     Running   0          22h\r\n",
      "pod/locust-master-1-6sbss                                1/1     Running   0          125m\r\n",
      "pod/locust-slave-1-nlwgv                                 1/1     Running   0          125m\r\n",
      "pod/seldon-model-example-0-classifier-7cf4bd7485-fvn7f   2/2     Running   0          126m\r\n",
      "pod/seldon-model-example-0-classifier-7cf4bd7485-jlsjg   2/2     Running   0          124m\r\n",
      "pod/seldon-model-example-0-classifier-7cf4bd7485-p9j4w   0/2     Pending   0          124m\r\n",
      "\r\n",
      "NAME                                                READY   UP-TO-DATE   AVAILABLE   AGE\r\n",
      "deployment.apps/ambassador                          1/1     1            1           22h\r\n",
      "deployment.apps/jaeger                              1/1     1            1           22h\r\n",
      "deployment.apps/jaeger-operator                     1/1     1            1           22h\r\n",
      "deployment.apps/seldon-model-example-0-classifier   2/3     3            2           126m\r\n",
      "\r\n",
      "NAME                                                                    REFERENCE                                      TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\r\n",
      "horizontalpodautoscaler.autoscaling/seldon-model-example-0-classifier   Deployment/seldon-model-example-0-classifier   29%/10%   1         3         3          126m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods,deployments,hpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"seldon-model\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f model_with_hpa.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
