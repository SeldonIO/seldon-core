{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow Pre-packaged Model Server AB Test Deployment \n",
    "In this example we will build two models with MLFlow and we will deploy them as an A/B test deployment.\n",
    "\n",
    "The reason this is powerful is because it allows you to deploy a new model next to the old one, distributing a percentage of traffic.\n",
    "\n",
    "These deployment strategies are quite simple using Seldon, and can be extended to shadow deployments, multi-armed-bandits, etc.\n",
    "\n",
    "\n",
    "## Tutorial Overview\n",
    "\n",
    "This tutorial will break down in the following sections:\n",
    "\n",
    "1) Train the MLFlow elastic net wine example\n",
    "\n",
    "2) Deploy your trained model leveraging our pre-packaged MLFlow model server\n",
    "\n",
    "3) Test the deployed MLFlow model by sending requests\n",
    "\n",
    "4) Deploy your second model as an A/B test\n",
    "\n",
    "5) Visualise and monitor the performance of your models using Seldon Analytics\n",
    "\n",
    "## Dependencies:\n",
    "\n",
    "For this example to work you must be running Seldon 0.3.2 or above - you can follow our [getting started guide for this](https://docs.seldon.io/projects/seldon-core/en/latest/workflow/install.html).\n",
    "\n",
    "In regards to other dependencies, make sure you have installed:\n",
    "\n",
    "* Helm v2.13.1+\n",
    "* kubectl v1.14+\n",
    "* Python 3.6+\n",
    "* MLFlow 1.1.0\n",
    "\n",
    "#### Let's get started! ðŸš€ðŸ”¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Train the first MLFlow Elastic Net Wine example\n",
    "We will use the elastic net wine example from MLFlow v1.1.0 for this example. First we'll import all the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings, sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the wine dataset which is also in this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"wine-quality.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will define all the functions we will use to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "def run_train_model_iteration(data, seed=40):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe and returns  \n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    train, test = train_test_split(data)\n",
    "    train_x = train.drop([\"quality\"], axis=1)\n",
    "    test_x = test.drop([\"quality\"], axis=1)\n",
    "    train_y = train[[\"quality\"]]\n",
    "    test_y = test[[\"quality\"]]\n",
    "\n",
    "    alpha = 0.5\n",
    "    l1_ratio = 0.5\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "        \n",
    "        # We create a store of the model \n",
    "        mlflow.sklearn.log_model(lr, \"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a first trained model, which the function above creates an MLFlow \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\n",
      "  RMSE: 0.8222428497595403\n",
      "  MAE: 0.6278761410160693\n",
      "  R2: 0.12678721972772622\n"
     ]
    }
   ],
   "source": [
    "run_train_model_iteration(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these iterations will create a new run which can be visualised through the MLFlow dashboard as per the screenshot below.\n",
    "\n",
    "![](images/mlflow-dashboard.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these models can actually be able to found on the `mlruns` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "012c5eaa115a4f43b5e4b74cb63d5c56  meta.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!ls mlruns/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside of the folders with the hash names is where we can find the artefacts of our model, which we'll be using to deploy with Seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlruns/0/012c5eaa115a4f43b5e4b74cb63d5c56/artifacts/\n"
     ]
    }
   ],
   "source": [
    "print(\"mlruns/0/\"+next(os.walk(\"mlruns/0\"))[1][0]+\"/artifacts/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should upload newly trained model into a public Google Bucket or S3 bucket. \n",
    "\n",
    "We have already done this to make it simpler, which you will be able to find at `gs://seldon-models/mlflow/elasticnet_wine`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Deploy your model using the Pre-packaged Moldel Server for MLFlow\n",
    "Once you have a Kubernetes Cluster running with [Seldon](https://docs.seldon.io/projects/seldon-core/en/latest/workflow/install.html) and [Ambassador](https://docs.seldon.io/projects/seldon-core/en/latest/workflow/install.html#install-ambassador) running we can deploy our trained MLFlow model.\n",
    "\n",
    "For this we have to create a Seldon definition of the model server definition, which we will break down further below.\n",
    "\n",
    "We will be using the model we updated to our google bucket (gs://seldon-models/mlflow/elasticnet_wine), but you can use your model if you uploaded it to a public bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mlflow-model-server-seldon-config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile mlflow-model-server-seldon-config.yaml\n",
    "---\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: mlflow-deployment\n",
    "spec:\n",
    "  name: mlflow-deployment\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: MLFLOW_SERVER\n",
    "      modelUri: gs://seldon-models/mlflow/elasticnet_wine\n",
    "      name: wines-classifier\n",
    "    name: mlflow-deployment-dag\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we write our configuration file, we are able to deploy it to our cluster by running it with our command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/mlflow-deployment created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f mlflow-model-server-seldon-config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it's created we just wait until it's deployed. \n",
    "\n",
    "It will basically download the image for the pre-packaged MLFlow model server, and initialise it with the model we specified above.\n",
    "\n",
    "You can check the status of the deployment with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment \"mlflow-deployment-mlflow-deployment-dag\" successfully rolled out\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deployment.apps/mlflow-deployment-mlflow-deployment-dag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it's deployed, we should see a \"succcessfully rolled out\" message above. We can now test it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Test the deployed MLFlow model by sending requests\n",
    "Now that our model is deployed in Kubernetes, we are able to send any requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first need the URL that is currently available through Ambassador. \n",
    "\n",
    "If you are running this locally, you should be able to reach it through localhost, in this case we can use port 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ambassador                                                  LoadBalancer   10.100.227.53   localhost     80:31215/TCP,443:31622/TCP   16d\r\n",
      "ambassador-admins                                           ClusterIP      10.101.19.26    <none>        8877/TCP                     16d\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get svc | grep ambassador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will select the first datapoint in our dataset to send to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 0.27, 0.36, 20.7, 0.045, 45.0, 170.0, 1.001, 3.0, 0.45, 8.8]\n"
     ]
    }
   ],
   "source": [
    "x_0 = data.drop([\"quality\"], axis=1).values[:1]\n",
    "print(list(x_0[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try sending a request first using curl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"meta\": {\n",
      "    \"puid\": \"4gapbfom6aa1nb6bm71jcsdo5q\",\n",
      "    \"tags\": {\n",
      "    },\n",
      "    \"routing\": {\n",
      "    },\n",
      "    \"requestPath\": {\n",
      "      \"wines-classifier\": \"\"\n",
      "    },\n",
      "    \"metrics\": []\n",
      "  },\n",
      "  \"data\": {\n",
      "    \"names\": [],\n",
      "    \"ndarray\": [5.655099099229193]\n",
      "  }\n",
      "}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   354  100   250  100   104  12500   5200 --:--:-- --:--:-- --:--:-- 17700\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST -H 'Content-Type: application/json' \\\n",
    "    -d \"{'data': {'names': [], 'ndarray': [[7.0, 0.27, 0.36, 20.7, 0.045, 45.0, 170.0, 1.001, 3.0, 0.45, 8.8]]}}\" \\\n",
    "    http://localhost:80/seldon/default/mlflow-deployment/api/v0.1/predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also send the request by using our python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta {\n",
      "  puid: \"kt99thn77rajhquoq50jb49hmh\"\n",
      "  requestPath {\n",
      "    key: \"wines-classifier\"\n",
      "  }\n",
      "}\n",
      "data {\n",
      "  ndarray {\n",
      "    values {\n",
      "      number_value: 5.655099099229193\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "import math\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "HOST = \"localhost\" # Add the URL you found above\n",
    "port = \"80\" # Make sure you use the port above\n",
    "batch = x_0\n",
    "payload_type = \"ndarray\"\n",
    "\n",
    "sc = SeldonClient(\n",
    "    gateway=\"ambassador\", \n",
    "    gateway_endpoint=HOST + \":\" + port,\n",
    "    namespace=\"default\")\n",
    "\n",
    "client_prediction = sc.predict(\n",
    "    data=batch, \n",
    "    deployment_name=\"mlflow-deployment\",\n",
    "    names=[],\n",
    "    payload_type=payload_type)\n",
    "\n",
    "print(client_prediction.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Deploy your second model as an A/B test\n",
    "Now that we have a model in production, it's possible to deploy a second model as an A/B test.\n",
    "\n",
    "By leveraging this, we will be redirecting 20% of the traffic to the new model.\n",
    "\n",
    "This can be done by simply adding a `traffic` attribute as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ab-test-mlflow-model-server-seldon-config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ab-test-mlflow-model-server-seldon-config.yaml\n",
    "---\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: mlflow-deployment\n",
    "spec:\n",
    "  name: mlflow-deployment\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: MLFLOW_SERVER\n",
    "      modelUri: gs://seldon-models/mlflow/elasticnet_wine\n",
    "      name: wines-classifier\n",
    "    name: a-mlflow-deployment-dag\n",
    "    replicas: 1\n",
    "    traffic: 20\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: MLFLOW_SERVER\n",
    "      modelUri: gs://seldon-models/mlflow/elasticnet_wine\n",
    "      name: wines-classifier\n",
    "    name: b-mlflow-deployment-dag\n",
    "    replicas: 1\n",
    "    traffic: 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similar to the model above, we only need to run the command to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/mlflow-deployment configured\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f ab-test-mlflow-model-server-seldon-config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the models have been deployed and are running with the following command.\n",
    "\n",
    "We should now see the \"a-\" model and the \"b-\" models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                         READY   STATUS    RESTARTS   AGE\r\n",
      "ambassador-6657ccd4f6-4z6xh                                  1/1     Running   11         16d\r\n",
      "ambassador-6657ccd4f6-5mc46                                  1/1     Running   11         16d\r\n",
      "ambassador-6657ccd4f6-qqfgn                                  1/1     Running   13         16d\r\n",
      "mlflow-deployment-a-mlflow-deployment-dag-68d4c9fcf5-crd9q   2/2     Running   0          2m25s\r\n",
      "mlflow-deployment-b-mlflow-deployment-dag-8cdcccbfc-rhc4p    2/2     Running   0          2m25s\r\n",
      "seldon-controller-manager-0                         1/1     Running   0          110m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Visualise and monitor the performance of your models using Seldon Analytics\n",
    "This section is optional, but by following the instructions you will be able to visualise the performance of both models as per the chart below.\n",
    "\n",
    "In order for this example to work you need to install and run the [Grafana Analytics package for Seldon Core](https://docs.seldon.io/projects/seldon-core/en/latest/analytics/analytics.html#helm-analytics-chart).\n",
    "\n",
    "For this we can access the URL with the command below, it will request an admin and password which by default are set to the following:\n",
    "* Username: admin\n",
    "* Password: admin\n",
    "\n",
    "You can access the grafana dashboard through the port provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31212"
     ]
    }
   ],
   "source": [
    "!kubectl get svc grafana-prom -o jsonpath='{.spec.ports[0].nodePort}'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now that we can access grafana, you have to go to the prediction analytics dashboard, where you'll be able to see metrics.\n",
    "\n",
    "Now we can run the following `while True` loop to start sending some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    client_prediction = sc.predict(\n",
    "        data=batch, \n",
    "        deployment_name=\"mlflow-deployment\",\n",
    "        names=[],\n",
    "        payload_type=payload_type)\n",
    "\n",
    "print(client_prediction.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be able to see the metrics reflected as per the chart below.\n",
    "\n",
    "In the chart you can visualise on the bottom lef the requests per second, which shows the different traffic breakdown we specified.\n",
    "\n",
    "You are able to add your own custom metrics, and try out other more complex deployments by following further guides at https://docs.seldon.io/projects/seldon-core/en/latest/workflow/README.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/grafana-mlflow.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
