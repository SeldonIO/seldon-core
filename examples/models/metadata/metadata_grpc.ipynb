{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Examples for Model with Metadata\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    " * A kubernetes cluster with kubectl configured\n",
    " * curl\n",
    " * grpcurl\n",
    " * pygmentize\n",
    " \n",
    "\n",
    "## Setup Seldon Core\n",
    "\n",
    "Use the setup notebook to [Setup Cluster](seldon_core_setup.ipynb) to setup Seldon Core with an ingress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): namespaces \"seldon\" already exists\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"kind-seldon\" modified.\n"
     ]
    }
   ],
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Directly define in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models/init-metadata/Model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile models/init-metadata/Model.py\n",
    "\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def predict(self, features, names=[], meta=[]):\n",
    "        logging.info(f\"model features: {features}\")\n",
    "        logging.info(f\"model names: {names}\")\n",
    "        logging.info(f\"model meta: {meta}\")\n",
    "        return features\n",
    "\n",
    "    def init_metadata(self):\n",
    "        logging.info(\"metadata method  called\")\n",
    "\n",
    "        meta = {\n",
    "            \"name\": \"my-model-name\",\n",
    "            \"versions\": [\"my-model-version-01\"],\n",
    "            \"platform\": \"seldon\",\n",
    "            \"inputs\": [{\"name\": \"input\", \"datatype\": \"BYTES\", \"shape\": [1, 5]}],\n",
    "            \"outputs\": [{\"name\": \"output\", \"datatype\": \"BYTES\", \"shape\": [1]}],\n",
    "        }\n",
    "\n",
    "        return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model-metadata/init-metadata-grpc.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile model-metadata/init-metadata-grpc.yaml\n",
    "\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: seldon-model\n",
    "spec:\n",
    "  name: test-deployment\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - image: seldonio/model-with-metadata:0.3\n",
    "          name: my-model\n",
    "          env:\n",
    "          - name: API_TYPE\n",
    "            value: GRPC            \n",
    "          - name: SELDON_LOG_LEVEL\n",
    "            value: DEBUG\n",
    "    graph:\n",
    "      children: []\n",
    "      name: my-model\n",
    "      type: MODEL\n",
    "    name: example\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/seldon-model configured\n",
      "Waiting for deployment \"seldon-model-example-0-my-model\" rollout to finish: 0 of 1 updated replicas are available...\n",
      "deployment \"seldon-model-example-0-my-model\" successfully rolled out\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "kubectl apply -f model-metadata/init-metadata-grpc.yaml\n",
    "\n",
    "dep_name=$(kubectl get deploy -l seldon-deployment-id=seldon-model -o jsonpath='{.items[0].metadata.name}')\n",
    "kubectl rollout status deploy/${dep_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"my-model-name\",\n",
      "  \"versions\": [\n",
      "    \"my-model-version-01\"\n",
      "  ],\n",
      "  \"platform\": \"seldon\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"input\",\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"shape\": [\n",
      "        \"1\",\n",
      "        \"5\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"name\": \"output\",\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"shape\": [\n",
      "        \"1\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../../../executor/proto && grpcurl \\\n",
    "    -d '{\"name\": \"my-model\"}' \\\n",
    "    -rpc-header seldon:seldon-model -rpc-header namespace:seldon \\\n",
    "    -plaintext -proto ./prediction.proto  0.0.0.0:8003 seldon.protos.Seldon/Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"example\",\n",
      "  \"models\": {\n",
      "    \"my-model\": {\n",
      "      \"name\": \"my-model-name\",\n",
      "      \"versions\": [\n",
      "        \"my-model-version-01\"\n",
      "      ],\n",
      "      \"platform\": \"seldon\",\n",
      "      \"inputs\": [\n",
      "        {\n",
      "          \"name\": \"input\",\n",
      "          \"datatype\": \"BYTES\",\n",
      "          \"shape\": [\n",
      "            \"1\",\n",
      "            \"5\"\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"outputs\": [\n",
      "        {\n",
      "          \"name\": \"output\",\n",
      "          \"datatype\": \"BYTES\",\n",
      "          \"shape\": [\n",
      "            \"1\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"input\",\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"shape\": [\n",
      "        \"1\",\n",
      "        \"5\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"name\": \"output\",\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"shape\": [\n",
      "        \"1\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../../../executor/proto && grpcurl \\\n",
    "    -rpc-header seldon:seldon-model -rpc-header namespace:seldon \\\n",
    "    -plaintext -proto ./prediction.proto  0.0.0.0:8003 seldon.protos.Seldon/GraphMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): error when deleting \"model-metadata/init-metadata.yaml\": seldondeployments.machinelearning.seldon.io \"seldon-model\" not found\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f model-metadata/init-metadata.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Via environmental variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model-metadata/environ-metadata-grpc.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile model-metadata/environ-metadata-grpc.yaml\n",
    "\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: seldon-model\n",
    "spec:\n",
    "  name: test-deployment\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - image: seldonio/metadata-generic-node:0.3\n",
    "          name: my-model\n",
    "          env:\n",
    "          - name: API_TYPE\n",
    "            value: GRPC                \n",
    "          - name: SELDON_LOG_LEVEL\n",
    "            value: DEBUG               \n",
    "          - name: MODEL_METADATA\n",
    "            value: |\n",
    "              ---\n",
    "              name: my-model-name\n",
    "              versions: [ my-model-version-01 ]\n",
    "              platform: seldon\n",
    "              inputs:\n",
    "              - datatype: BYTES\n",
    "                name: input\n",
    "                shape: [ 1, 4 ]\n",
    "              outputs:\n",
    "              - datatype: BYTES\n",
    "                name: output\n",
    "                shape: [ 3 ]\n",
    "    graph:\n",
    "      children: []\n",
    "      name: my-model\n",
    "      type: MODEL\n",
    "    name: example\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/seldon-model configured\n",
      "Waiting for deployment \"seldon-model-example-0-my-model\" rollout to finish: 1 old replicas are pending termination...\n",
      "Waiting for deployment \"seldon-model-example-0-my-model\" rollout to finish: 1 old replicas are pending termination...\n",
      "deployment \"seldon-model-example-0-my-model\" successfully rolled out\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "kubectl apply -f model-metadata/environ-metadata-grpc.yaml\n",
    "\n",
    "dep_name=$(kubectl get deploy -l seldon-deployment-id=seldon-model -o jsonpath='{.items[0].metadata.name}')\n",
    "kubectl rollout status deploy/${dep_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"my-model-name\",\n",
      "  \"versions\": [\n",
      "    \"my-model-version-01\"\n",
      "  ],\n",
      "  \"platform\": \"seldon\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"input\",\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"shape\": [\n",
      "        \"1\",\n",
      "        \"4\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"name\": \"output\",\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"shape\": [\n",
      "        \"3\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../../../executor/proto && grpcurl \\\n",
    "    -d '{\"name\": \"my-model\"}' \\\n",
    "    -rpc-header seldon:seldon-model -rpc-header namespace:seldon \\\n",
    "    -plaintext -proto ./prediction.proto  0.0.0.0:8003 seldon.protos.Seldon/Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"example\",\n",
      "  \"models\": {\n",
      "    \"my-model\": {\n",
      "      \"name\": \"my-model-name\",\n",
      "      \"versions\": [\n",
      "        \"my-model-version-01\"\n",
      "      ],\n",
      "      \"platform\": \"seldon\",\n",
      "      \"inputs\": [\n",
      "        {\n",
      "          \"name\": \"input\",\n",
      "          \"datatype\": \"BYTES\",\n",
      "          \"shape\": [\n",
      "            \"1\",\n",
      "            \"4\"\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"outputs\": [\n",
      "        {\n",
      "          \"name\": \"output\",\n",
      "          \"datatype\": \"BYTES\",\n",
      "          \"shape\": [\n",
      "            \"3\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"input\",\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"shape\": [\n",
      "        \"1\",\n",
      "        \"4\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"name\": \"output\",\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"shape\": [\n",
      "        \"3\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../../../executor/proto && grpcurl \\\n",
    "    -rpc-header seldon:seldon-model -rpc-header namespace:seldon \\\n",
    "    -plaintext -proto ./prediction.proto  0.0.0.0:8003 seldon.protos.Seldon/GraphMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"seldon-model\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f model-metadata/environ-metadata.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Via environmental variable (V1 format)\n",
    "\n",
    "This illustrates how to use v1 format to define metadata.\n",
    "\n",
    "This example uses environmental variable but this would also be valid for `init_metadata` approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model-metadata/environ-metadata-v1-grpc.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile model-metadata/environ-metadata-v1-grpc.yaml\n",
    "\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: seldon-model\n",
    "spec:\n",
    "  name: test-deployment\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - image: seldonio/metadata-generic-node:0.3\n",
    "          name: my-model\n",
    "          env:\n",
    "          - name: API_TYPE\n",
    "            value: GRPC              \n",
    "          - name: SELDON_LOG_LEVEL\n",
    "            value: DEBUG\n",
    "          - name: MODEL_METADATA\n",
    "            value: |\n",
    "              ---\n",
    "              name: my-model-name\n",
    "              versions: [ my-model-version-01 ]\n",
    "              platform: seldon\n",
    "              inputs:\n",
    "              - messagetype: array\n",
    "                shape: [ 2, 2 ]\n",
    "              outputs:\n",
    "              - messagetype: array\n",
    "                shape: [ 1 ]\n",
    "    graph:\n",
    "      children: []\n",
    "      endpoint:\n",
    "        type: REST\n",
    "      name: my-model\n",
    "      type: MODEL\n",
    "    name: example\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/seldon-model configured\n",
      "Waiting for deployment \"seldon-model-example-0-my-model\" rollout to finish: 1 old replicas are pending termination...\n",
      "Waiting for deployment \"seldon-model-example-0-my-model\" rollout to finish: 1 old replicas are pending termination...\n",
      "deployment \"seldon-model-example-0-my-model\" successfully rolled out\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "kubectl apply -f model-metadata/environ-metadata-v1-grpc.yaml\n",
    "\n",
    "dep_name=$(kubectl get deploy -l seldon-deployment-id=seldon-model -o jsonpath='{.items[0].metadata.name}')\n",
    "kubectl rollout status deploy/${dep_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"my-model-name\",\n",
      "  \"versions\": [\n",
      "    \"my-model-version-01\"\n",
      "  ],\n",
      "  \"platform\": \"seldon\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"shape\": [\n",
      "        \"2\",\n",
      "        \"2\"\n",
      "      ],\n",
      "      \"messagetype\": \"array\"\n",
      "    }\n",
      "  ],\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"shape\": [\n",
      "        \"1\"\n",
      "      ],\n",
      "      \"messagetype\": \"array\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../../../executor/proto && grpcurl \\\n",
    "    -d '{\"name\": \"my-model\"}' \\\n",
    "    -rpc-header seldon:seldon-model -rpc-header namespace:seldon \\\n",
    "    -plaintext -proto ./prediction.proto  0.0.0.0:8003 seldon.protos.Seldon/Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"example\",\n",
      "  \"models\": {\n",
      "    \"my-model\": {\n",
      "      \"name\": \"my-model-name\",\n",
      "      \"versions\": [\n",
      "        \"my-model-version-01\"\n",
      "      ],\n",
      "      \"platform\": \"seldon\",\n",
      "      \"inputs\": [\n",
      "        {\n",
      "          \"shape\": [\n",
      "            \"2\",\n",
      "            \"2\"\n",
      "          ],\n",
      "          \"messagetype\": \"array\"\n",
      "        }\n",
      "      ],\n",
      "      \"outputs\": [\n",
      "        {\n",
      "          \"shape\": [\n",
      "            \"1\"\n",
      "          ],\n",
      "          \"messagetype\": \"array\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"shape\": [\n",
      "        \"2\",\n",
      "        \"2\"\n",
      "      ],\n",
      "      \"messagetype\": \"array\"\n",
      "    }\n",
      "  ],\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"shape\": [\n",
      "        \"1\"\n",
      "      ],\n",
      "      \"messagetype\": \"array\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../../../executor/proto && grpcurl \\\n",
    "    -rpc-header seldon:seldon-model -rpc-header namespace:seldon \\\n",
    "    -plaintext -proto ./prediction.proto  0.0.0.0:8003 seldon.protos.Seldon/GraphMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"seldon-model\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f model-metadata/environ-metadata.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
