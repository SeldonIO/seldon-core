{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVINO example with Squeezenet Model\n",
    "\n",
    "This notebook illustrates how you can serve [OpenVINO](https://software.intel.com/en-us/openvino-toolkit) optimized models for Imagenet with Seldon Core.\n",
    "\n",
    "<img src=\"dog.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    " * Seldon-core (```pip install seldon-core```)\n",
    " * Numpy\n",
    " * Keras\n",
    " * Matplotlib\n",
    " * Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Squeezenet Model\n",
    "\n",
    "We will download a pre-trained and optimized model for OpenVINO CPU into a local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models/squeezenet/1 && \\\n",
    "    wget -O models/squeezenet/1/squeezenet1.1.xml https://s3-eu-west-1.amazonaws.com/seldon-public/openvino-squeeznet-model/squeezenet1.1.xml && \\\n",
    "    wget -O models/squeezenet/1/squeezenet1.1.mapping https://s3-eu-west-1.amazonaws.com/seldon-public/openvino-squeeznet-model/squeezenet1.1.mapping && \\\n",
    "    wget -O models/squeezenet/1/squeezenet1.1.bin https://s3-eu-west-1.amazonaws.com/seldon-public/openvino-squeeznet-model/squeezenet1.1.bin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Seldon Core on Minikube\n",
    "\n",
    "**The example below assumes Minikube 0.30.0 installed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!minikube start --memory 4096 --disk-size 20g --extra-config=apiserver.authorization-mode=RBAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl create namespace seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl create clusterrolebinding kube-system-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/tiller-deploy -n kube-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm install ../../../helm-charts/seldon-core-crd --name seldon-core-crd  --set usage_metrics.enabled=true\n",
    "!helm install ../../../helm-charts/seldon-core --name seldon-core --set ambassador.enabled=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mount local folder onto minikube for HostPath\n",
    "Run in the current folder:\n",
    "```\n",
    "minikube mount ./models:/opt/ml\n",
    "```\n",
    "\n",
    "This will allow the model folder containing the Squeezenet model to be accessed. For production deployments you would use a NFS volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Combiner Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!eval $(minikube docker-env) && cd resources/combiner && s2i build -E environment_grpc . seldonio/seldon-core-s2i-python36:0.4 seldonio/imagenet_combiner:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!eval $(minikube docker-env) && cd resources/transformer && s2i build -E environment_grpc . seldonio/seldon-core-s2i-python36:0.4 seldonio/imagenet_transformer:0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Seldon Intel OpenVINO Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../notebooks\")\n",
    "from visualizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_graph(\"seldon_openvino_ensemble.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize seldon_openvino_ensemble.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f pvc.json\n",
    "!kubectl apply -f seldon_openvino_ensemble.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serve Requests\n",
    "\n",
    "**Ensure you port forward ambassador:**\n",
    "\n",
    "```\n",
    "kubectl port-forward $(kubectl get pods -n seldon -l service=ambassador -o jsonpath='{.items[0].metadata.name}') -n seldon 8003:8080\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from seldon_core.proto import prediction_pb2\n",
    "from seldon_core.proto import prediction_pb2_grpc\n",
    "import grpc\n",
    "\n",
    "def grpc_request_ambassador(deploymentName,namespace,endpoint=\"localhost:8004\",data=None):\n",
    "    datadef = prediction_pb2.DefaultData(\n",
    "                names = 'x',\n",
    "                tftensor = tf.make_tensor_proto(data)\n",
    "            )\n",
    "    request = prediction_pb2.SeldonMessage(data = datadef)\n",
    "    channel = grpc.insecure_channel(endpoint)\n",
    "    stub = prediction_pb2_grpc.SeldonStub(channel)\n",
    "    if namespace is None:\n",
    "        metadata = [('seldon',deploymentName)]\n",
    "    else:\n",
    "        metadata = [('seldon',deploymentName),('namespace',namespace)]\n",
    "    response = stub.Predict(request=request,metadata=metadata)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "import sys\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "API_AMBASSADOR=\"localhost:8003\"\n",
    "\n",
    "def getImage(path):\n",
    "    img = image.load_img(path, target_size=(227, 227))\n",
    "    x = image.img_to_array(img)\n",
    "    plt.imshow(x/255.)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "def getImageRaw(path):\n",
    "    img = image.load_img(path, target_size=(227, 227))\n",
    "    x = image.img_to_array(img)\n",
    "    plt.imshow(x/255.)\n",
    "    return x\n",
    "\n",
    "#X = getImage(\"car.png\")\n",
    "#X = X.transpose((0,3,1,2))\n",
    "\n",
    "#X = getImageRaw(\"car.png\")\n",
    "X = getImageRaw(\"dog.jpeg\")\n",
    "print(X.shape)\n",
    "start_time = datetime.datetime.now()\n",
    "response = grpc_request_ambassador(\"openvino-model\",\"seldon\",API_AMBASSADOR,data=X)\n",
    "end_time = datetime.datetime.now()\n",
    "duration = (end_time - start_time).total_seconds() * 1000\n",
    "print(duration)\n",
    "\n",
    "print(response.strData)\n",
    "\n",
    "#result = tf.make_ndarray(response.data.tftensor)   \n",
    "#result = result.reshape(1,1000)\n",
    "\n",
    "#with open('imagenet_classes.json') as f:\n",
    "#    cnames = eval(f.read())\n",
    "#\n",
    "#    single_result = result[[0],...]\n",
    "#    ma = np.argmax(single_result)\n",
    "#    print(\"\\t\",0, cnames[ma])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = []\n",
    "for i in range(100):\n",
    "    start_time = datetime.datetime.now()\n",
    "    response = grpc_request_ambassador(\"openvino-model\",\"seldon\",API_AMBASSADOR,data=X)\n",
    "    end_time = datetime.datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds() * 1000\n",
    "    durations.append(duration)\n",
    "print(sum(durations) / float(len(durations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
