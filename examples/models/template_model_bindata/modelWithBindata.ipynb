{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Binary Data\n",
    "\n",
    "Example testing a model which uses binary data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../../../proto/prediction.proto ./proto\n",
    "!cp -r ../../../proto/tensorflow/tensorflow .\n",
    "!python -m grpc.tools.protoc -I. --python_out=. --grpc_python_out=. ./proto/prediction.proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import base64\n",
    "from proto import prediction_pb2\n",
    "from proto import prediction_pb2_grpc\n",
    "import grpc\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def get_payload():\n",
    "    array_2d = np.arange(9).reshape(3, 3)\n",
    "    print(array_2d)\n",
    "    bdata = pickle.dumps(array_2d)\n",
    "    return bdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rest_request_ambassador(deploymentName,namespace,request,endpoint=\"localhost:8003\"):\n",
    "    response = requests.post(\n",
    "                \"http://\"+endpoint+\"/seldon/\"+namespace+\"/\"+deploymentName+\"/api/v0.1/predictions\",\n",
    "                json=request)\n",
    "    print(response.status_code)\n",
    "    print(response.text)\n",
    "    return response.json()\n",
    "\n",
    "def grpc_request_ambassador(deploymentName,namespace,data,endpoint=\"localhost:8004\"):\n",
    "    request = prediction_pb2.SeldonMessage(binData = data)\n",
    "    channel = grpc.insecure_channel(endpoint)\n",
    "    stub = prediction_pb2_grpc.SeldonStub(channel)\n",
    "    metadata = [('seldon',deploymentName),('namespace',namespace)]\n",
    "    response = stub.Predict(request=request,metadata=metadata)\n",
    "    return response\n",
    "\n",
    "def rest_request_docker(request,endpoint=\"localhost:5000\"):\n",
    "    response = requests.post(\n",
    "                \"http://\"+endpoint+\"/predict\",\n",
    "                 data={\"json\":json.dumps(request),\"isDefault\":True})\n",
    "    print(response.text)\n",
    "    return response.json()\n",
    "\n",
    "def grpc_request_docker(data,endpoint=\"localhost:5000\"):\n",
    "    request = prediction_pb2.SeldonMessage(binData = data)\n",
    "    channel = grpc.insecure_channel(endpoint)\n",
    "    stub = prediction_pb2_grpc.ModelStub(channel)\n",
    "    response = stub.Predict(request=request)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Installing application source...\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "!s2i build -E environment_rest . seldonio/seldon-core-s2i-python36:0.16 model-with-bindata-rest:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1af22a1967d507a92e773ad7ee5d195a5a8197fed4e7b4ac7a2fe7995da045e6\r\n"
     ]
    }
   ],
   "source": [
    "!docker run --name \"model-with-bindata\" -d --rm -p 5000:5000 model-with-bindata-rest:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "{\"binData\":\"gANjbnVtcHkuY29yZS5tdWx0aWFycmF5Cl9yZWNvbnN0cnVjdApxAGNudW1weQpuZGFycmF5CnEBSwCFcQJDAWJxA4dxBFJxBShLAUsDSwOGcQZjbnVtcHkKZHR5cGUKcQdYAgAAAGk4cQhLAEsBh3EJUnEKKEsDWAEAAAA8cQtOTk5K/////0r/////SwB0cQxiiUNIAAAAAAAAAAABAAAAAAAAAAIAAAAAAAAAAwAAAAAAAAAEAAAAAAAAAAUAAAAAAAAABgAAAAAAAAAHAAAAAAAAAAgAAAAAAAAAcQ10cQ5iLg==\",\"meta\":{\"metrics\":[{\"key\":\"mycounter\",\"value\":1.0},{\"key\":\"mygauge\",\"type\":\"GAUGE\",\"value\":100.0},{\"key\":\"mytimer\",\"type\":\"TIMER\",\"value\":20.200000762939453}]}}\n",
      "\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "bdata = get_payload()\n",
    "bdata_base64 = base64.b64encode(bdata).decode('utf-8')\n",
    "payload = {\"meta\":{},\"binData\":bdata_base64}\n",
    "response = rest_request_docker(payload)\n",
    "bdata2 = base64.b64decode(response[\"binData\"])\n",
    "arr_resp = pickle.loads(bdata2)\n",
    "print(arr_resp)\n",
    "print(arr_resp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-with-bindata\r\n"
     ]
    }
   ],
   "source": [
    "!docker rm model-with-bindata --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Installing application source...\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "!s2i build -E environment_grpc . seldonio/seldon-core-s2i-python36:0.16 model-with-bindata-grpc:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "046eb6370f931c9fc7f41066d43d2dbb7d6a7da3372cf59b85c8cc936d73a5bd\r\n"
     ]
    }
   ],
   "source": [
    "!docker run --name \"model-with-bindata\" -d --rm -p 5000:5000 model-with-bindata-grpc:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "payload = get_payload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "bdata = get_payload()\n",
    "resp = grpc_request_docker(bdata)\n",
    "bdata2 = resp.binData\n",
    "arr_resp = pickle.loads(bdata2)\n",
    "print(arr_resp)\n",
    "print(arr_resp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-with-bindata\r\n"
     ]
    }
   ],
   "source": [
    "!docker rm model-with-bindata --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test using Minikube\n",
    "\n",
    "**Due to a [minikube/s2i issue](https://github.com/SeldonIO/seldon-core/issues/253) you will need [s2i >= 1.1.13](https://github.com/openshift/source-to-image/releases/tag/v1.1.13)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😄  minikube v1.0.0 on linux (amd64)\n",
      "🤹  Downloading Kubernetes v1.14.0 images in the background ...\n",
      "💡  Tip: Use 'minikube start -p <name>' to create a new cluster, or 'minikube delete' to delete this one.\n",
      "🏃  Re-using the currently running kvm2 VM for \"minikube\" ...\n",
      "⌛  Waiting for SSH access ...\n",
      "📶  \"minikube\" IP address is 192.168.39.225\n",
      "🐳  Configuring Docker as the container runtime ...\n"
     ]
    }
   ],
   "source": [
    "!minikube start --vm-driver kvm2 --memory 4096 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Seldon Core\n",
    "\n",
    "Use the setup notebook to [Setup Cluster](../../seldon_core_setup.ipynb#Setup-Cluster) with [Ambassador Ingress](../../seldon_core_setup.ipynb#Ambassador) and [Install Seldon Core](../../seldon_core_setup.ipynb#Install-Seldon-Core). Instructions [also online](./seldon_core_setup.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Installing application source...\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "!eval $(minikube docker-env) && s2i build -E environment_rest . seldonio/seldon-core-s2i-python36:0.16 model-with-bindata-rest:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/mymodel created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f deployment-rest.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment \"mymodel-mymodel-b0e3779\" successfully rolled out\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deploy/mymodel-mymodel-b0e3779"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "minikube_ip = !minikube ip\n",
    "minikube_port = !kubectl get svc -l app.kubernetes.io/name=ambassador -o jsonpath='{.items[0].spec.ports[0].nodePort}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "200\n",
      "{\n",
      "  \"meta\": {\n",
      "    \"puid\": \"ocvn7n6p5654vvj2epvrmfd7mg\",\n",
      "    \"tags\": {\n",
      "    },\n",
      "    \"routing\": {\n",
      "    },\n",
      "    \"requestPath\": {\n",
      "      \"complex-model\": \"model-with-bindata-rest:0.1\"\n",
      "    },\n",
      "    \"metrics\": [{\n",
      "      \"key\": \"mycounter\",\n",
      "      \"type\": \"COUNTER\",\n",
      "      \"value\": 1.0,\n",
      "      \"tags\": {\n",
      "      }\n",
      "    }, {\n",
      "      \"key\": \"mygauge\",\n",
      "      \"type\": \"GAUGE\",\n",
      "      \"value\": 100.0,\n",
      "      \"tags\": {\n",
      "      }\n",
      "    }, {\n",
      "      \"key\": \"mytimer\",\n",
      "      \"type\": \"TIMER\",\n",
      "      \"value\": 20.2,\n",
      "      \"tags\": {\n",
      "      }\n",
      "    }]\n",
      "  },\n",
      "  \"binData\": \"gANjbnVtcHkuY29yZS5tdWx0aWFycmF5Cl9yZWNvbnN0cnVjdApxAGNudW1weQpuZGFycmF5CnEBSwCFcQJDAWJxA4dxBFJxBShLAUsDSwOGcQZjbnVtcHkKZHR5cGUKcQdYAgAAAGk4cQhLAEsBh3EJUnEKKEsDWAEAAAA8cQtOTk5K/////0r/////SwB0cQxiiUNIAAAAAAAAAAABAAAAAAAAAAIAAAAAAAAAAwAAAAAAAAAEAAAAAAAAAAUAAAAAAAAABgAAAAAAAAAHAAAAAAAAAAgAAAAAAAAAcQ10cQ5iLg==\"\n",
      "}\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "bdata = get_payload()\n",
    "bdata_base64 = base64.b64encode(bdata).decode('utf-8')\n",
    "payload = {\"meta\":{},\"binData\":bdata_base64}\n",
    "response = rest_request_ambassador(\"mymodel\",\"default\",payload,minikube_ip[0]+\":\"+minikube_port[0])\n",
    "bdata2 = base64.b64decode(response[\"binData\"])\n",
    "arr_resp = pickle.loads(bdata2)\n",
    "print(arr_resp)\n",
    "print(arr_resp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"mymodel\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f deployment-rest.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Installing application source...\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "!eval $(minikube docker-env) && s2i build -E environment_grpc . seldonio/seldon-core-s2i-python36:0.16 model-with-bindata-grpc:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/mymodel created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f deployment-grpc.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until ready (replicas == replicasAvailable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment \"mymodel-mymodel-a9ecaa4\" successfully rolled out\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deploy/mymodel-mymodel-a9ecaa4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "bdata = get_payload()\n",
    "response = grpc_request_ambassador(\"mymodel\",\"default\",bdata,minikube_ip[0]+\":\"+minikube_port[0])\n",
    "bdata2 = response.binData\n",
    "arr_resp = pickle.loads(bdata2)\n",
    "print(arr_resp)\n",
    "print(arr_resp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"mymodel\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f deployment-grpc.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!minikube delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
