{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seldon Core Basic Statistical Metrics with Feedback Reward\n",
    "\n",
    "In this notebook we will show how it is possible to leverage the existing \"Feedback Reward\" capabilities of Seldon Core to enable stateful metrics for real time statistical monitoring of production Seldon Core models.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    \n",
    "<td width=\"50%\">\n",
    "<img src=\"images/realtime-accuracy.jpg\" width=\"100%\">\n",
    "</td>\n",
    "    \n",
    "<td width=\"50%\">\n",
    "<img src=\"images/model-perf-comp.jpg\" width=\"100%\">\n",
    "</td>\n",
    "    \n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "To go ahead with the notebook, you will need to install the following components based on the documentation:\n",
    "* Install [Seldon Core](https://docs.seldon.io/projects/seldon-core/en/latest/workflow/install.html)\n",
    "* Install [Seldon Core Analytics](https://docs.seldon.io/projects/seldon-core/en/latest/analytics/analytics.html)\n",
    "* Configure Seldon with an ingress (such as [istio](https://docs.seldon.io/projects/seldon-core/en/latest/ingress/istio.html) or ambassador)\n",
    "\n",
    "In this tutorial we will:\n",
    "1. Train a set of python models to compare\n",
    "2. Write a language wrapper with custom metrics\n",
    "3. Deploy model and send predictions and feedback\n",
    "4. Visualise accuracy metrics on grafana dashboard\n",
    "5. Deploy second model and visualise performance in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib==0.14.1\n",
    "scikit-learn==0.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a simple breast cancer classifier\n",
    "\n",
    "We will train two models, one with a perceptron and one with a logisticRegresson model, so we can compare the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model in binary-lr.joblib\n",
      "Saving model in binary-percept.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "parameters = [\n",
    "    {\"clf\": LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\"), \"name\": \"binary-lr.joblib\"},\n",
    "    {\"clf\": Perceptron(n_iter=40, eta0=0.1, random_state=0), \"name\": \"binary-percept.joblib\"},\n",
    "]\n",
    "\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9)\n",
    "\n",
    "for param in parameters:\n",
    "    clf = param[\"clf\"]\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Saving model in {param['name']}\")\n",
    "    joblib.dump(clf, param['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.ipynb  binary-lr.joblib\tbinary-percept.joblib  requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a Seldon Language Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MetricsModel.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MetricsModel.py\n",
    "\n",
    "import joblib\n",
    "\n",
    "class Score:\n",
    "    def __init__(self, TP, FP, TN, FN):\n",
    "        self.TP = TP\n",
    "        self.FP = FP\n",
    "        self.TN = TN\n",
    "        self.FN = FN\n",
    "\n",
    "class MetricsModel:\n",
    "    def __init__(self, model_name=\"binary-lr.joblib\"):\n",
    "        self.scores = Score(0, 0, 0, 0)\n",
    "        self.model = joblib.load(model_name)\n",
    "        self.model_name = model_name.split()[0]\n",
    "\n",
    "    def predict(self, X, features_names=None, meta=None):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def send_feedback(self, features, feature_names, reward, truth, routing=\"\"):\n",
    "        predicted = self.predict(features)\n",
    "        print(f\"Predicted: {predicted[0]}, Truth: {truth[0]}\")\n",
    "        if int(truth[0]) == 1:\n",
    "            if int(predicted[0]) == int(truth[0]):\n",
    "                self.scores.TP += 1\n",
    "            else:\n",
    "                self.scores.FN += 1\n",
    "        else:\n",
    "            if int(predicted[0]) == int(truth[0]):\n",
    "                self.scores.TN += 1\n",
    "            else:\n",
    "                self.scores.FP += 1\n",
    "        return []  # Ignore return statement as its not used\n",
    "\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            {\"type\": \"GAUGE\", \"key\": f\"true_pos\", \"value\": self.scores.TP},\n",
    "            {\"type\": \"GAUGE\", \"key\": f\"true_neg\", \"value\": self.scores.FN},\n",
    "            {\"type\": \"GAUGE\", \"key\": f\"false_pos\", \"value\": self.scores.TN},\n",
    "            {\"type\": \"GAUGE\", \"key\": f\"false_neg\", \"value\": self.scores.FP},\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Containerise model\n",
    "\n",
    "Now we can containerise our model using the seldon utilities, we will be able to leverage the `requirements.txt` above to install all dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Installing application source...\n",
      "---> Installing dependencies ...\n",
      "Looking in links: /whl\n",
      "Collecting joblib==0.14.1 (from -r requirements.txt (line 1))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "Collecting scikit-learn==0.20.3 (from -r requirements.txt (line 2))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/aa/cc/a84e1748a2a70d0f3e081f56cefc634f3b57013b16faa6926d3a6f0598df/scikit_learn-0.20.3-cp37-cp37m-manylinux1_x86_64.whl (5.4MB)\n",
      "Collecting scipy>=0.13.3 (from scikit-learn==0.20.3->-r requirements.txt (line 2))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/65/f9/f7a7e5009711579c72da2725174825e5056741bf4001815d097eef1b2e17/scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9MB)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.20.3->-r requirements.txt (line 2)) (1.19.1)\n",
      "Installing collected packages: joblib, scipy, scikit-learn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.20.3 scipy-1.5.2\n",
      "Collecting pip-licenses\n",
      "Downloading https://files.pythonhosted.org/packages/c5/50/6c4b4e69a0c43bd9f03a30579695093062ba72da4e3e4026cd2144dbcc71/pip_licenses-2.3.0-py3-none-any.whl\n",
      "Collecting PTable (from pip-licenses)\n",
      "Downloading https://files.pythonhosted.org/packages/ab/b3/b54301811173ca94119eb474634f120a49cd370f257d1aae5a4abaf12729/PTable-0.9.2.tar.gz\n",
      "Building wheels for collected packages: PTable\n",
      "Building wheel for PTable (setup.py): started\n",
      "Building wheel for PTable (setup.py): finished with status 'done'\n",
      "Created wheel for PTable: filename=PTable-0.9.2-cp37-none-any.whl size=22906 sha256=bbdf078ec2fc20eee868dc4a4e9daa49e418a4f6fefa09315d53d8bb370cd6a3\n",
      "Stored in directory: /root/.cache/pip/wheels/22/cc/2e/55980bfe86393df3e9896146a01f6802978d09d7ebcba5ea56\n",
      "Successfully built PTable\n",
      "Installing collected packages: PTable, pip-licenses\n",
      "Successfully installed PTable-0.9.2 pip-licenses-2.3.0\n",
      "created path: ./licenses/license_info.csv\n",
      "created path: ./licenses/license.txt\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "!s2i build . seldonio/seldon-core-s2i-python37:1.5.0-dev metrics_model:0.1 \\\n",
    "        --env MODEL_NAME=\"MetricsModel\" --env API_TYPE=REST --env SERVICE_TYPE=MODEL --env PERSISTENCE=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy model\n",
    "\n",
    "Now that we've containerised our model, we can deploy it using Seldon, so we get a microservice for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/metrics-model created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl apply -n seldon -f - <<END\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: metrics-model\n",
    "spec:\n",
    "  name: metrics-model\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - image: metrics_model:0.1\n",
    "          imagePullPolicy: IfNotPresent\n",
    "          name: binary-percept\n",
    "    graph:\n",
    "      children: []\n",
    "      endpoint:\n",
    "        type: REST\n",
    "      parameters:\n",
    "      - name: model_name\n",
    "        type: STRING\n",
    "        value: binary-percept.joblib\n",
    "      name: binary-percept\n",
    "      type: MODEL\n",
    "    name: default\n",
    "    replicas: 1\n",
    "END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test with some of the test data, by sending the first available param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data point to predict: [[1.447e+01 2.499e+01 9.581e+01 6.564e+02 8.837e-02 1.230e-01 1.009e-01\n",
      "  3.890e-02 1.872e-01 6.341e-02 2.542e-01 1.079e+00 2.615e+00 2.311e+01\n",
      "  7.138e-03 4.653e-02 3.829e-02 1.162e-02 2.068e-02 6.111e-03 1.622e+01\n",
      "  3.173e+01 1.135e+02 8.089e+02 1.340e-01 4.202e-01 4.040e-01 1.205e-01\n",
      "  3.187e-01 1.023e-01]]\n",
      "\n",
      "Expected class: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data point to predict: {X_test[[101]]}\\n\")\n",
    "print(f\"Expected class: {y_test[101]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our python client to send the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "\n",
    "sc = SeldonClient(namespace=\"seldon\", gateway_endpoint=\"localhost:80\", deployment_name=\"metrics-model\", payload_type=\"ndarray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response: {'data': {'names': [], 'ndarray': [1]}, 'meta': {'metrics': [{'key': 'true_pos', 'type': 'GAUGE', 'value': 0}, {'key': 'true_neg', 'type': 'GAUGE', 'value': 0}, {'key': 'false_pos', 'type': 'GAUGE', 'value': 0}, {'key': 'false_neg', 'type': 'GAUGE', 'value': 0}]}}\n",
      "\n",
      "Predicted Class: [1]\n",
      "Expected class: 1\n"
     ]
    }
   ],
   "source": [
    "y_res = sc.predict(data=X[[101]])\n",
    "\n",
    "print(f\"Raw Response: {y_res.response}\\n\")\n",
    "print(f\"Predicted Class: {y_res.response['data']['ndarray']}\")\n",
    "print(f\"Expected class: {y_test[101]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sending Feedback\n",
    "\n",
    "Whilst the predict requests go through the predict function, the feedback requests go through the send_feedback function.\n",
    "\n",
    "In order to send feedback, we have to also follow the schema for send feedback, which allows us to send \"request\", \"response\", \"truth\" and \"reward\".\n",
    "\n",
    "In the feedback scoring section of the Seldon documentation we cover in detail all the different approaches to feedback. \n",
    "\n",
    "Here we provide a simple example where feedbacks cores is dynamically calculated in the python model itself.\n",
    "\n",
    "We will then be able to visualise the feedback that was sent to the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:80/seldon/seldon/metrics-model/api/v1.0/feedback\"\n",
    "\n",
    "for x_i, y_i in zip(X_test, y_test):\n",
    "    data = {\"request\": {\"data\": {\"ndarray\": [x_i.tolist()]}}, \"truth\":{\"data\": {\"ndarray\": [[y_i.tolist()]]}}}\n",
    "    requests.post(f\"{url}\", json=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Metrics\n",
    "\n",
    "Now we can view the initial metrics in our current model by opening the grafana.\n",
    "\n",
    "You can start forwarding the port with the following command:\n",
    "\n",
    "```\n",
    "kubectl port-forward -n seldon-system svc/seldon-core-analytics-grafana 7000:80\n",
    "```\n",
    "\n",
    "Then you can accessing it at [http://localhost:7000](http://localhost:7000). The username is `admin` and password is `password."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when you access the dashboard, you have to import the dashboard, first by going to the following section:\n",
    "   \n",
    "<img src=\"images/grafana-import.jpg\" width=\"600px\">\n",
    "\n",
    "And then in the box you can add the code below for the dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"annotations\": {\"list\": [{\"builtIn\": 1,\"datasource\": \"-- Grafana --\",\"enable\": true,\"hide\": true,\"iconColor\": \"rgba(0, 211, 255, 1)\",\"name\": \"Annotations & Alerts\",\"type\": \"dashboard\"}]},\"editable\": true,\"gnetId\": null,\"graphTooltip\": 0,\"id\": 4,\"links\": [],\"panels\": [{\"aliasColors\": {},\"bars\": false,\"dashLength\": 10,\"dashes\": false,\"datasource\": \"prometheus\",\"description\": \"\",\"fieldConfig\": {\"defaults\": {\"custom\": {},\"mappings\": [],\"thresholds\": {\"mode\": \"absolute\",\"steps\": [{\"color\": \"green\",\"value\": null},{\"color\": \"red\",\"value\": 80}]}},\"overrides\": []},\"fill\": 1,\"fillGradient\": 0,\"gridPos\": {\"h\": 8,\"w\": 12,\"x\": 0,\"y\": 0},\"hiddenSeries\": false,\"id\": 2,\"legend\": {\"avg\": false,\"current\": false,\"max\": false,\"min\": false,\"show\": true,\"total\": false,\"values\": false},\"lines\": true,\"linewidth\": 1,\"nullPointMode\": \"null\",\"options\": {\"dataLinks\": []},\"percentage\": false,\"pluginVersion\": \"7.0.3\",\"pointradius\": 2,\"points\": true,\"renderer\": \"flot\",\"seriesOverrides\": [],\"spaceLength\": 10,\"stack\": false,\"steppedLine\": false,\"targets\": [{\"expr\": \"(sum(true_pos{method=\\\"feedback\\\"} + true_neg{method=\\\"feedback\\\"}) by (seldon_app)) / (sum(true_pos{method=\\\"feedback\\\"} + true_neg{method=\\\"feedback\\\"} + false_pos{method=\\\"feedback\\\"} + false_neg{method=\\\"feedback\\\"}) by (seldon_app))\",\"interval\": \"\",\"legendFormat\": \"{{seldon_app}}\",\"refId\": \"A\"}],\"thresholds\": [],\"timeFrom\": null,\"timeRegions\": [],\"timeShift\": null,\"title\": \"Real Time Model Accuracy\",\"tooltip\": {\"shared\": true,\"sort\": 0,\"value_type\": \"individual\"},\"type\": \"graph\",\"xaxis\": {\"buckets\": null,\"mode\": \"time\",\"name\": null,\"show\": true,\"values\": []},\"yaxes\": [{\"decimals\": null,\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": \"1\",\"min\": \"0\",\"show\": true},{\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": null,\"min\": null,\"show\": true}],\"yaxis\": {\"align\": false,\"alignLevel\": null}},{\"aliasColors\": {},\"bars\": false,\"dashLength\": 10,\"dashes\": false,\"datasource\": \"prometheus\",\"description\": \"\",\"fieldConfig\": {\"defaults\": {\"custom\": {\"align\": null},\"mappings\": [],\"thresholds\": {\"mode\": \"absolute\",\"steps\": [{\"color\": \"green\",\"value\": null},{\"color\": \"red\",\"value\": 80}]}},\"overrides\": []},\"fill\": 1,\"fillGradient\": 0,\"gridPos\": {\"h\": 8,\"w\": 12,\"x\": 12,\"y\": 0},\"hiddenSeries\": false,\"id\": 3,\"legend\": {\"avg\": false,\"current\": false,\"max\": false,\"min\": false,\"show\": true,\"total\": false,\"values\": false},\"lines\": true,\"linewidth\": 1,\"nullPointMode\": \"null\",\"options\": {\"dataLinks\": []},\"percentage\": false,\"pluginVersion\": \"7.0.3\",\"pointradius\": 2,\"points\": true,\"renderer\": \"flot\",\"seriesOverrides\": [],\"spaceLength\": 10,\"stack\": false,\"steppedLine\": false,\"targets\": [{\"expr\": \"(sum(true_pos{method=\\\"feedback\\\"}) by (seldon_app)) / (sum(true_pos{method=\\\"feedback\\\"} + false_pos{method=\\\"feedback\\\"}) by (seldon_app))\",\"interval\": \"\",\"legendFormat\": \"{{seldon_app}}\",\"refId\": \"A\"}],\"thresholds\": [],\"timeFrom\": null,\"timeRegions\": [],\"timeShift\": null,\"title\": \"Real Time Model Precision\",\"tooltip\": {\"shared\": true,\"sort\": 0,\"value_type\": \"individual\"},\"type\": \"graph\",\"xaxis\": {\"buckets\": null,\"mode\": \"time\",\"name\": null,\"show\": true,\"values\": []},\"yaxes\": [{\"decimals\": null,\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": \"1\",\"min\": \"0\",\"show\": true},{\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": null,\"min\": null,\"show\": true}],\"yaxis\": {\"align\": false,\"alignLevel\": null}},{\"aliasColors\": {},\"bars\": false,\"dashLength\": 10,\"dashes\": false,\"datasource\": \"prometheus\",\"description\": \"\",\"fieldConfig\": {\"defaults\": {\"custom\": {},\"mappings\": [],\"thresholds\": {\"mode\": \"absolute\",\"steps\": [{\"color\": \"green\",\"value\": null},{\"color\": \"red\",\"value\": 80}]}},\"overrides\": []},\"fill\": 1,\"fillGradient\": 0,\"gridPos\": {\"h\": 8,\"w\": 12,\"x\": 0,\"y\": 8},\"hiddenSeries\": false,\"id\": 5,\"legend\": {\"avg\": false,\"current\": false,\"max\": false,\"min\": false,\"show\": true,\"total\": false,\"values\": false},\"lines\": true,\"linewidth\": 1,\"nullPointMode\": \"null\",\"options\": {\"dataLinks\": []},\"percentage\": false,\"pluginVersion\": \"7.0.3\",\"pointradius\": 2,\"points\": true,\"renderer\": \"flot\",\"seriesOverrides\": [],\"spaceLength\": 10,\"stack\": false,\"steppedLine\": false,\"targets\": [{\"expr\": \"(sum(true_pos{method=\\\"feedback\\\"}) by (seldon_app)) / (sum(true_pos{method=\\\"feedback\\\"} + false_neg{method=\\\"feedback\\\"}) by (seldon_app))\",\"interval\": \"\",\"legendFormat\": \"{{seldon_app}}\",\"refId\": \"A\"}],\"thresholds\": [],\"timeFrom\": null,\"timeRegions\": [],\"timeShift\": null,\"title\": \"Real Time Model Recall\",\"tooltip\": {\"shared\": true,\"sort\": 0,\"value_type\": \"individual\"},\"type\": \"graph\",\"xaxis\": {\"buckets\": null,\"mode\": \"time\",\"name\": null,\"show\": true,\"values\": []},\"yaxes\": [{\"decimals\": null,\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": \"1\",\"min\": \"0\",\"show\": true},{\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": null,\"min\": null,\"show\": true}],\"yaxis\": {\"align\": false,\"alignLevel\": null}},{\"aliasColors\": {},\"bars\": false,\"dashLength\": 10,\"dashes\": false,\"datasource\": \"prometheus\",\"description\": \"\",\"fieldConfig\": {\"defaults\": {\"custom\": {},\"mappings\": [],\"thresholds\": {\"mode\": \"absolute\",\"steps\": [{\"color\": \"green\",\"value\": null},{\"color\": \"red\",\"value\": 80}]}},\"overrides\": []},\"fill\": 1,\"fillGradient\": 0,\"gridPos\": {\"h\": 8,\"w\": 12,\"x\": 12,\"y\": 8},\"hiddenSeries\": false,\"id\": 4,\"legend\": {\"avg\": false,\"current\": false,\"max\": false,\"min\": false,\"show\": true,\"total\": false,\"values\": false},\"lines\": true,\"linewidth\": 1,\"nullPointMode\": \"null\",\"options\": {\"dataLinks\": []},\"percentage\": false,\"pluginVersion\": \"7.0.3\",\"pointradius\": 2,\"points\": true,\"renderer\": \"flot\",\"seriesOverrides\": [],\"spaceLength\": 10,\"stack\": false,\"steppedLine\": false,\"targets\": [{\"expr\": \"(sum(true_neg{method=\\\"feedback\\\"}) by (seldon_app)) / (sum(true_neg{method=\\\"feedback\\\"} + false_pos{method=\\\"feedback\\\"}) by (seldon_app))\",\"interval\": \"\",\"legendFormat\": \"{{seldon_app}}\",\"refId\": \"A\"}],\"thresholds\": [],\"timeFrom\": null,\"timeRegions\": [],\"timeShift\": null,\"title\": \"Real Time Model Specificity\",\"tooltip\": {\"shared\": true,\"sort\": 0,\"value_type\": \"individual\"},\"type\": \"graph\",\"xaxis\": {\"buckets\": null,\"mode\": \"time\",\"name\": null,\"show\": true,\"values\": []},\"yaxes\": [{\"decimals\": null,\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": \"1\",\"min\": \"0\",\"show\": true},{\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": null,\"min\": null,\"show\": true}],\"yaxis\": {\"align\": false,\"alignLevel\": null}}],\"refresh\": \"5s\",\"schemaVersion\": 25,\"style\": \"dark\",\"tags\": [],\"templating\": {\"list\": []},\"time\": {\"from\": \"now-5m\",\"to\": \"now\"},\"timepicker\": {\"refresh_intervals\": [\"10s\",\"30s\",\"1m\",\"5m\",\"15m\",\"30m\",\"1h\",\"2h\",\"1d\"],\"time_options\": [\"5m\",\"15m\",\"1h\",\"6h\",\"12h\",\"24h\",\"2d\",\"7d\",\"30d\"]},\"timezone\": \"browser\",\"title\": \"statistical-metrics\",\"uid\": \"zmkrlZ7Gk\",\"version\": 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you import the dashboard you should be able to see the model as follows:\n",
    "    \n",
    "![single-model](images/single-model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Time Model Performance\n",
    "\n",
    "Now we can actually run two models at the same time and compare the performance of both.\n",
    "\n",
    "We will be able to assess in real time which model is performing better.\n",
    "\n",
    "We first deploy both of our models as a shadow deployment (so the requests get sent to both models):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"metrics-model\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete sdep -n seldon metrics-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/ab-test created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl apply -n seldon -f - <<END\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: ab-test\n",
    "spec:\n",
    "  name: ab-test\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - image: metrics_model:0.1\n",
    "          imagePullPolicy: IfNotPresent\n",
    "          name: percept-model\n",
    "    graph:\n",
    "      children: []\n",
    "      endpoint:\n",
    "        type: REST\n",
    "      parameters:\n",
    "      - name: model_name\n",
    "        type: STRING\n",
    "        value: binary-percept.joblib\n",
    "      name: percept-model\n",
    "      type: MODEL\n",
    "    name: default\n",
    "    replicas: 1\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - image: metrics_model:0.1\n",
    "          imagePullPolicy: IfNotPresent\n",
    "          name: lr-model\n",
    "    graph:\n",
    "      children: []\n",
    "      endpoint:\n",
    "        type: REST\n",
    "      parameters:\n",
    "      - name: model_name\n",
    "        type: STRING\n",
    "        value: binary-lr.joblib\n",
    "      name: lr-model\n",
    "      type: MODEL\n",
    "    name: shadow\n",
    "    replicas: 1\n",
    "    shadow: true\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test with a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response: {'data': {'names': [], 'ndarray': [1]}, 'meta': {'metrics': [{'key': 'true_pos', 'type': 'GAUGE', 'value': 0}, {'key': 'true_neg', 'type': 'GAUGE', 'value': 0}, {'key': 'false_pos', 'type': 'GAUGE', 'value': 0}, {'key': 'false_neg', 'type': 'GAUGE', 'value': 0}]}}\n",
      "\n",
      "Predicted Class: [1]\n",
      "Expected class: 1\n"
     ]
    }
   ],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "\n",
    "sc = SeldonClient(namespace=\"seldon\", gateway_endpoint=\"localhost:80\", deployment_name=\"ab-test\", payload_type=\"ndarray\")\n",
    "\n",
    "y_res = sc.predict(data=X[[101]])\n",
    "\n",
    "print(f\"Raw Response: {y_res.response}\\n\")\n",
    "print(f\"Predicted Class: {y_res.response['data']['ndarray']}\")\n",
    "print(f\"Expected class: {y_test[101]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send feedback to both models\n",
    "\n",
    "Now that we have a shadow deployment with both models we just need to send the request to the main deployment, and the traffic will be split dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "url = \"http://localhost:80/seldon/seldon/ab-test/api/v1.0/feedback\"\n",
    "\n",
    "for x_i, y_i in zip(X_test, y_test):\n",
    "    data = {\"request\": {\"data\": {\"ndarray\": [x_i.tolist()]}}, \"truth\":{\"data\": {\"ndarray\": [y_i.tolist()]}}}\n",
    "    requests.post(f\"{url}\", json=data)\n",
    "    time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real time dashboard\n",
    "\n",
    "Now we can see the real time dashboard for our two models.\n",
    "\n",
    "![model-perf-comp](images/model-perf-comp.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
