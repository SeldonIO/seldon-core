{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier\n",
    "\n",
    "Implementation of an image classifier model, based in [PyTorch's MNIST example](https://github.com/pytorch/examples/blob/master/mnist/main.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "First we will train a machine learning model, which will help us classify news across multiple categories.\n",
    "This model will use a custom reusable server, responsible for loading a PyTorch model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies \n",
    "\n",
    "We will need the following dependencies in order to run the Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/requirements.txt\n",
    "torch==1.3.1\n",
    "torchvision==0.4.2\n",
    "matplotlib==3.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now install the dependencies using the make command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip install -r src/requirements.txt\n",
      "Requirement already satisfied: torch==1.3.1 in /home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages (from -r src/requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: torchvision==0.4.2 in /home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages (from -r src/requirements.txt (line 2)) (0.4.2)\n",
      "Requirement already satisfied: matplotlib==3.1.2 in /home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages (from -r src/requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: numpy in /home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages (from torch==1.3.1->-r src/requirements.txt (line 1)) (1.17.4)\n",
      "Requirement already satisfied: six in /home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages (from torchvision==0.4.2->-r src/requirements.txt (line 2)) (1.13.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages (from torchvision==0.4.2->-r src/requirements.txt (line 2)) (6.2.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages (from matplotlib==3.1.2->-r src/requirements.txt (line 3)) (2.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages (from matplotlib==3.1.2->-r src/requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages (from matplotlib==3.1.2->-r src/requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages (from matplotlib==3.1.2->-r src/requirements.txt (line 3)) (2.8.1)\n",
      "Requirement already satisfied: setuptools in /home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib==3.1.2->-r src/requirements.txt (line 3)) (42.0.1)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "make install_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the ML data\n",
    "\n",
    "Now that we have all the dependencies we can proceed to download the data.\n",
    "\n",
    "We will download the news stories dataset, and we'll be attempting to classify across the four classes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import fetch_training, fetch_test\n",
    "\n",
    "training_dataset = fetch_training()\n",
    "test_dataset = fetch_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look into the data to see a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faf16f31e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x_example, y_example = training_dataset[0]\n",
    "plt.imshow(x_example.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model\n",
    "\n",
    "Now that we've downloaded the data, we can train the ML model using a simple pipeline with basic text pre-processors and a Multiclass naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.308114\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 1.369711\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.638653\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.428343\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.357857\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.446279\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.319209\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.221589\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.280998\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.170742\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.218999\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.206189\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.111903\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.242586\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.206079\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.210710\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.171747\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.247889\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.060543\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.144133\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.128856\n",
      "Train Epoch: 1 [53760/60000 (89%)]\tLoss: 0.078763\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.130446\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.101130\n",
      "\n",
      "Test set: Average loss: 0.0656, Accuracy: 9772/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.041494\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.094879\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.068686\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.120580\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.082097\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.054558\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.065923\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.243822\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.099501\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.107730\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.052492\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.074916\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.087789\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.107939\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.062355\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.100331\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.126194\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.091540\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.102458\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.063010\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.063841\n",
      "Train Epoch: 2 [53760/60000 (89%)]\tLoss: 0.054854\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.157604\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.104388\n",
      "\n",
      "Test set: Average loss: 0.0470, Accuracy: 9846/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from src.data import fetch_test, fetch_training\n",
    "from src.train import train_epoch, test_epoch\n",
    "from src.model import Classifier\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 2\n",
    "lr = 1.0\n",
    "gamma = 0.7\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "model = Classifier()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_epoch(model, train_loader, optimizer, epoch)\n",
    "    test_epoch(model, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test single prediction\n",
    "\n",
    "Now that we've trained our model we can use it to predict from un-seen data.\n",
    "\n",
    "We can see below that the model is able to predict the first datapoint in the dataset correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTED: 5\n",
      "ACTUAL: 5\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(x_example.unsqueeze(0))\n",
    "print(f\"PREDICTED: {y_pred.argmax()}\")\n",
    "print(f\"ACTUAL: {y_example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print accuracy\n",
    "\n",
    "We can print the accuracy of the model by running the test data and counting the number of correct classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0470, Accuracy: 9846/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_epoch(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "Now we want to be able to deploy the model we just trained. This will just be as simple as updated the model binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model\n",
    "\n",
    "First we have to save the trained model in the `src/` folder.\n",
    "This is the artifact we will upload to our model registry and which the wrapper will load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_path = os.path.join(\"src\", \"model.pt\")\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update your unit test\n",
    "\n",
    "We'll write a very simple unit test that make sure that the model loads and runs as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./src/test_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/test_model.py\n",
    "from src.model import Classifier\n",
    "\n",
    "def test_model():\n",
    "    data = [\"text 1\", \"text 2\"]\n",
    "\n",
    "    model = Classifier()\n",
    "    model_path = \"model.pt\"\n",
    "    model_state_dict = torch.load(model_path)\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    y_pred = model(x_example.unsqueeze(0))\n",
    "\n",
    "    assert all(y_pred == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Classifier.forward of Classifier(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd src && \\\n",
      "\tpytest -s --verbose -W ignore --log-level=INFO 2>&1\n",
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.6.9, pytest-5.1.1, py-1.8.0, pluggy-0.13.1 -- /home/agm/.virtualenvs/sig-mlops/bin/python3.6\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/agm/Seldon/sig-mlops-jenkins-classic/models/image_classifier/src\n",
      "collecting ... collected 1 item\n",
      "\n",
      "test_model.py::test_model FAILED\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "__________________________________ test_model __________________________________\n",
      "\n",
      "    def test_model():\n",
      "        data = [\"text 1\", \"text 2\"]\n",
      "    \n",
      "        model = Classifier()\n",
      ">       model.load_state_dict(\"model.pt\")\n",
      "\n",
      "test_model.py:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = Classifier(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), ...): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "state_dict = 'model.pt', strict = True\n",
      "\n",
      "    def load_state_dict(self, state_dict, strict=True):\n",
      "        r\"\"\"Copies parameters and buffers from :attr:`state_dict` into\n",
      "        this module and its descendants. If :attr:`strict` is ``True``, then\n",
      "        the keys of :attr:`state_dict` must exactly match the keys returned\n",
      "        by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      "    \n",
      "        Arguments:\n",
      "            state_dict (dict): a dict containing parameters and\n",
      "                persistent buffers.\n",
      "            strict (bool, optional): whether to strictly enforce that the keys\n",
      "                in :attr:`state_dict` match the keys returned by this module's\n",
      "                :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      "    \n",
      "        Returns:\n",
      "            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      "                * **missing_keys** is a list of str containing the missing keys\n",
      "                * **unexpected_keys** is a list of str containing the unexpected keys\n",
      "        \"\"\"\n",
      "        missing_keys = []\n",
      "        unexpected_keys = []\n",
      "        error_msgs = []\n",
      "    \n",
      "        # copy state_dict so _load_from_state_dict can modify it\n",
      "        metadata = getattr(state_dict, '_metadata', None)\n",
      ">       state_dict = state_dict.copy()\n",
      "E       AttributeError: 'str' object has no attribute 'copy'\n",
      "\n",
      "/home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages/torch/nn/modules/module.py:812: AttributeError\n",
      "============================== 1 failed in 0.75s ===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "make: *** [Makefile:10: test] Error 1\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'make test\\n'' returned non-zero exit status 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d00272f30bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'make test\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/sig-mlops/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2350\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2352\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2353\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sig-mlops/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/agm/.virtualenvs/sig-mlops/lib/python3.6/site-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sig-mlops/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sig-mlops/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'make test\\n'' returned non-zero exit status 2."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "make test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Integration Tests\n",
    "\n",
    "We can also now update the integration tests. This is another very simple step, where we'll want to test this model specifically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mseldon_core.seldon_client\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SeldonClient\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mseldon_core.utils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m seldon_message_to_json\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m run\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\n",
      "\n",
      "API_AMBASSADOR = \u001b[33m\"\u001b[39;49;00m\u001b[33mlocalhost:8003\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtest_sklearn_server\u001b[39;49;00m():\n",
      "    data = [\u001b[33m\"\u001b[39;49;00m\u001b[33mFrom: brian@ucsd.edu (Brian Kantor)\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mSubject: Re: HELP for Kidney Stones ..............\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mOrganization: The Avant-Garde of the Now, Ltd.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mLines: 12\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mNNTP-Posting-Host: ucsd.edu\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mAs I recall from my bout with kidney stones, there isn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mt any\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mmedication that can do anything about them except relieve the pain.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mEither they pass, or they have to be broken up with sound, or they have\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mto be extracted surgically.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mWhen I was in, the X-ray tech happened to mention that she\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33md had kidney\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mstones and children, and the childbirth hurt less.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mDemerol worked, although I nearly got arrested on my way home when I barfed\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mall over the police car parked just outside the ER.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m- Brian\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mFrom: rind@enterprise.bih.harvard.edu (David Rind)\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mSubject: Re: Candida(yeast) Bloom, Fact or Fiction\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mOrganization: Beth Israel Hospital, Harvard Medical School, Boston Mass., USA\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mLines: 37\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mNNTP-Posting-Host: enterprise.bih.harvard.edu\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mIn article <1993Apr26.103242.1@vms.ocom.okstate.edu>\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m banschbach@vms.ocom.okstate.edu writes:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m>are in a different class.  The big question seems to be is it reasonable to \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m>use them in patients with GI distress or sinus problems that *could* be due \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m>to candida blooms following the use of broad-spectrum antibiotics?\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mI guess I\u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33mm still not clear on what the term \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mcandida bloom\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m means,\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mbut certainly it is well known that thrush (superficial candidal\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33minfections on mucous membranes) can occur after antibiotic use.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mThis has nothing to do with systemic yeast syndrome, the \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mquack\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mdiagnosis that has been being discussed.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m>found in the sinus mucus membranes than is candida.  Women have been known \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m>for a very long time to suffer from candida blooms in the vagina and a \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m>women is lucky to find a physician who is willing to treat the cause and \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m>not give give her advise to use the OTC anti-fungal creams.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mLucky how?  Since a recent article (randomized controlled trial) of\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33moral yogurt on reducing vaginal candidiasis, I\u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33mve mentioned to a \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mnumber of patients with frequent vaginal yeast infections that they\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mcould try eating 6 ounces of yogurt daily.  It turns out most would\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mrather just use anti-fungal creams when they get yeast infections.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m>yogurt dangerous).  If this were a standard part of medical practice, as \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m>Gordon R. says it is, then the incidence of GI distress and vaginal yeast \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m>infections should decline.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mAgain, this just isn\u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33mt what the systemic yeast syndrome is about, and\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mhas nothing to do with the quack therapies that were being discussed.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mThere is some evidence that attempts to reinoculate the GI tract with\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mbacteria after antibiotic therapy don\u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33mt seem to be very helpful in\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mreducing diarrhea, but I don\u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33mt think anyone would view this as a\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mquack therapy.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m-- \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mDavid Rind\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mrind@enterprise.bih.harvard.edu\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    labels = [\u001b[34m2.0\u001b[39;49;00m, \u001b[34m2.0\u001b[39;49;00m]\n",
      "    \n",
      "    sc = SeldonClient(\n",
      "        gateway=\u001b[33m\"\u001b[39;49;00m\u001b[33mambassador\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        gateway_endpoint=API_AMBASSADOR,\n",
      "        deployment_name=\u001b[33m\"\u001b[39;49;00m\u001b[33mseldon-model-server\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        payload_type=\u001b[33m\"\u001b[39;49;00m\u001b[33mndarray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        namespace=\u001b[33m\"\u001b[39;49;00m\u001b[33mseldon\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        transport=\u001b[33m\"\u001b[39;49;00m\u001b[33mrest\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    sm_result = sc.predict(data=np.array(data))\n",
      "    logging.info(sm_result)\n",
      "    result = seldon_message_to_json(sm_result.response)\n",
      "    logging.info(result)\n",
      "    values = result.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, {}).get(\u001b[33m\"\u001b[39;49;00m\u001b[33mndarray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, {})\n",
      "    \u001b[34massert\u001b[39;49;00m (values == labels)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize integration/test_e2e_seldon_model_server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now push your changes to trigger the pipeline\n",
    "Because Jenkins Classic has created a CI GitOps pipeline for our repo we just need to push our changes to run all the tests\n",
    "\n",
    "We can do this by running our good old git commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git add .\n",
    "git push origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that the pipeline has been triggered by viewing our activities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Create Effective Pipeline                          11h28m57s       7s Succeeded \n",
      "    Create Tekton Crds                                 11h28m50s      11s Succeeded \n",
      "  test and deploy sklearn server                       11h28m38s    1m54s Succeeded \n",
      "    Credential Initializer 59hx6                       11h28m38s       0s Succeeded \n",
      "    Working Dir Initializer Fslpm                      11h28m38s       1s Succeeded \n",
      "    Place Tools                                        11h28m37s       1s Succeeded \n",
      "    Git Source Seldonio Sig Mlops Seldon Jenki Ftjtn   11h28m36s       6s Succeeded https://github.com/SeldonIO/sig-mlops-seldon-jenkins-x.git\n",
      "    Git Merge                                          11h28m30s       1s Succeeded \n",
      "    Run Tests                                          11h28m29s      13s Succeeded \n",
      "    Build And Push Images                              11h28m16s    1m32s Succeeded \n"
     ]
    }
   ],
   "source": [
    "!jx get activity -f sig-mlops-seldon-jenkins-x | tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we can actually see the logs of our running job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Failed to parse docker reference ELDON_BASE_WRAPPER\n",
      "ERROR: An error occurred: unable to get metadata for ELDON_BASE_WRAPPER:latest\n",
      "ERROR: Suggested solution: check image name\n",
      "ERROR: If the problem persists consult the docs at https://github.com/openshift/source-to-image/tree/master/docs. Eventually reach us on freenode #openshift or file an issue at https://github.com/openshift/source-to-image/issues providing us with a log from your build using log output level 3.\n",
      "Makefile:8: recipe for target 'build' failed\n",
      "make: *** [build] Error 1\n",
      "Stopping Docker: dockerProgram process in pidfile '/var/run/docker-ssd.pid', 1 process(es), refused to die.\n",
      "\u001b[31m\n",
      "Pipeline failed on stage 'test-and-deploy-sklearn-server' : container 'step-build-and-push-images'. The execution of the pipeline has stopped.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrote: /tmp/086bfe4e-d4ac-46e6-baa1-71d4ef7abca4095596018\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "YOUR_GIT_USERNAME=SeldonIO\n",
    "jx get build logs \"$YOUR_GIT_USERNAME/sig-mlops-seldon-jenkins-x/master #7 release\" | tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing your Jenkins X Application\n",
    "\n",
    "Now that we've deployed our MLOps repo, Jenkins X now has created an application from our charts.\n",
    "\n",
    "This application gets automatically syncd into the Jenkins X staging environment, which you can see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get pods -n jx-staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your application in the staging environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ndarray {\n",
       "  values {\n",
       "    number_value: 2.0\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "import numpy as np\n",
    "\n",
    "url = !kubectl get svc ambassador -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'\n",
    "\n",
    "sc = SeldonClient(\n",
    "    gateway=\"ambassador\", \n",
    "    gateway_endpoint=\"localhost:80\",\n",
    "    deployment_name=\"mlops-server\",\n",
    "    payload_type=\"ndarray\",\n",
    "    namespace=\"jx-staging\",\n",
    "    transport=\"rest\")\n",
    "\n",
    "response = sc.predict(data=np.array([twenty_test.data[0]]))\n",
    "\n",
    "response.response.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"meta\": {\n",
      "    \"puid\": \"so6n21pkf70fm66eka28lc63cr\",\n",
      "    \"tags\": {\n",
      "    },\n",
      "    \"routing\": {\n",
      "    },\n",
      "    \"requestPath\": {\n",
      "      \"news-classifier-server-processor\": \"axsauze/sklearn-server:0.1\"\n",
      "    },\n",
      "    \"metrics\": []\n",
      "  },\n",
      "  \"data\": {\n",
      "    \"names\": [],\n",
      "    \"ndarray\": [2.0]\n",
      "  }\n",
      "}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   350  100   278  100    72   7942   2057 --:--:-- --:--:-- --:--:-- 10294\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST -H 'Content-Type: application/json' \\\n",
    "     -d \"{'data': {'names': ['text'], 'ndarray': ['Hello world this is a test']}}\" \\\n",
    "    http://localhost/seldon/jx-staging/news-classifier-server/api/v0.1/predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sig-mlops",
   "language": "python",
   "name": "sig-mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
