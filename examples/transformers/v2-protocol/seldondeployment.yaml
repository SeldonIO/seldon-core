apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
  name: gpt2
spec:
  protocol: kfserving
  predictors:
    - name: default
      graph:
        name: tokeniser
        children:
          - name: gpt2
            implementation: TRITON_SERVER
            modelUri: gs://seldon-models/triton/onnx_gpt2
      componentSpecs:
        - spec:
            containers:
              - name: tokeniser
                image: gpt2-tokeniser:0.1.0
                env:
                  # Use always a writable HuggingFace cache location regardless
                  # of the user
                  - name: TRANSFORMERS_CACHE
                    value: /opt/mlserver/.cache
