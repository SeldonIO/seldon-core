Am working through canarying and the istio configuration for explainers.

I'm working with a SeldonDeployment with one predictor and one explainer. The dummy one I'm using is:

apiVersion: machinelearning.seldon.io/v1alpha2
kind: SeldonDeployment
metadata:
  name: sklearn
spec:
  name: iris
  predictors:
    - graph:
        children: []
        implementation: SKLEARN_SERVER
        modelUri: "gs://kfserving-samples/models/sklearn/iris"
        name: classifier
      name: default
      replicas: 1
      explainer:
        type: TABULAR
        modelUri: "gs://kfserving-samples/models/sklearn/iris"

For this I have three Services, one for the container/model, one for the Predictor and one for the Explainer:

iris-default-classifier-seldonio-sklearnserver-rest-0-1   ClusterIP           9000/TCP            55m
sklearn-default-explainer                                 ClusterIP           9000/TCP            54m
sklearn-iris-default                                      ClusterIP           8000/TCP,5001/TCP   54m

The Predictor and Explainer services are both ambassador-annotated as they are intended to be externally-accessible.

Now imagine if this were a canary.

Then we would have two Predictors and two Explainers. So we'd get 6 Services.

So what is this at istio level?

If we forget the explainer and just concentrate on Predictors currently we create one VirtualService for the whole SeldonDeployment (either http or grpc) and add traffic weight entries (destination rules) per Predictor.

This suggests we should add one VirtualSerivce per Explainer. There should be no traffic-weighting with explainers.

So if there were a canary situation with explainers we would have three external entrypoints. One for the SeldonDeployment, weighted across the Predictors, and one per Explainer.

The entrypoint for the SeldonDeployment is "/seldon/<namespace>/<mlDep.Name>/"

For the Explainers I propose to use "/seldon/<namespace>/<mlDep.Name>/<predictor.Name>/explainer"

