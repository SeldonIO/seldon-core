<div align="center">

 <a href="https://www.seldon.io/solutions/core/">
  <img alt="Core 2 Logo" src="/.images/core-2-logo.png" alt="Core 2 Logo" style="max-width: 100%; height: auto; width: 400px;">
 </a>
</div>

# Deploy Modular, Data-centric AI applications at scale

##  💡 About
Seldon Core 2 is an MLOps and LLMOps framework for deploying, managing and scaling AI systems in Kubernetes - from singular models, to modular and data-centric applications. With Core 2 you can deploy in a standardized way across a wide range of model types, on-prem or in any cloud, and production-ready out of the box. 

</br>
 <div align="center">
   <a href="https://www.youtube.com/watch?v=ar5lSG_idh4">
     <img src="/.images/Core-intro-thumbnail.png" alt="Introductory Youtube Video" style="max-width: 100%; width: 500px; height: auto;">
   </a>
 </div>
</br>

To contact Seldon regarding commercial use [Contact Seldon](https://www.seldon.io/)

## 📚 Documentation  

The Seldon Core 2 Docs can be found [here](https://docs.seldon.ai/seldon-core-2). For most specific sections, see here:

<p align="center">
  <a href="https://docs.seldon.ai/seldon-core-2/installation/installation">🔧 Installation</a>  &nbsp • &nbsp
  <a href="https://docs.seldon.ai/seldon-core-2/user-guide/servers"> ⛽ Servers</a>  &nbsp • &nbsp
  <a href="https://docs.seldon.ai/seldon-core-2/user-guide/models">🤖 Models</a>  &nbsp •  &nbsp
  <a href="https://docs.seldon.ai/seldon-core-2/user-guide/pipelines"> 🔗 Pipelines</a>  &nbsp • &nbsp
  <a href="https://docs.seldon.ai/seldon-core-2/user-guide/experiment">🧑‍🔬 Experiments</a>  &nbsp • &nbsp
  <a href="https://docs.seldon.ai/seldon-core-2/user-guide/performance-tuning">📊 Performance Tuning</a>  
</p>

## 🧩 Features

 * **Pipelines**: Deploy composable AI applications, leveraging Kafka for realtime data streaming between components
 * **Autoscaling** for models and application components based on native or custom logic
 * **Multi-Model Serving**: Save infrastructure costs by consolidating multiple models on shared inference servers
 * **Overcommit**: Deploy more models than available memory allows, saving infrastructure costs for unused models
 * **Experiments**: Route data between candidate models or pipelines, with support for A/B tests and shadow deployments
 * **Custom Components**: Implement custom logic, drift & outlier detection, LLMs and more through plug-and-play integrate with the rest of Seldon's ecosytem of ML/AI products!
 
## 🔬 Research

These features are influenced by our position paper on the next generation of ML model serving frameworks: 

👉 [Desiderata for next generation of ML model serving](http://arxiv.org/abs/2210.14665)

## 📜 License

Seldon is distributed under the terms of the The Business Source License. A complete version of the license is available in the [LICENSE file](LICENSE) in this repository. Any contribution made to this project will be licensed under the Business Source License.



