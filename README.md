# Core 2: Deploy Modular, Data-centric AI applications at scale

## üìñ About
Seldon Core 2 is an MLOps and LLMOps framework for deploying, managing and scaling AI systems in Kubernetes - from singular models, to modular, data-centric applications. With Core 2 you can deploy across a wide range of model types, on-prem or in any cloud, in a standardized way that is production-ready out of the box. 

[![Introductory Youtube Video](./docs-gb/images/Core-intro-thumbnail.png)](https://www.youtube.com/watch?v=ar5lSG_idh4)

## Features

 * **Pipelines**: Deploy composable AI pipelines, leveraging Kafka for realtime data streaming between components
 * **Autoscaling** for models and application components based on native or custom logic
 * **Multi-Model Serving**: Save infrastructure costs by consolidating multiple models on shared inference servers
 * **Overcommit**: Deploy more models than available memory allows, saving infrastructure costs for unused models
 * **Experiments**: Route data between candidate models or pipeline, with support for A/B tests and shadow deployments
 * **Custom Components**: Implement custom logic, drift & outlier detection, LLMs and more through plug-and-play integrate with the rest of Seldon's ecosytem of ML/AI products!
 
## Publication

These features are influenced by our position paper on the next generation of ML model serving frameworks:

*Title*: [Desiderata for next generation of ML model serving](http://arxiv.org/abs/2210.14665)

*Workshop*: Challenges in deploying and monitoring ML systems workshop - NeurIPS 2022


## ‚ö°Ô∏è Quickstart


## Documentation

[Seldon Core 2 docs](https://docs.seldon.ai/seldon-core-2)

## üìú License
