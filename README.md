<div align="center">

 <a href="https://www.seldon.io/solutions/core/">
  <img alt="Core 2 Logo" src="/.images/core-2-logo.png" alt="Core 2 Logo" style="max-width: 100%; height: auto; width: 400px;">
 </a>
</div>

# Deploy Modular, Data-centric AI applications at scale

##  ğŸ’¡ About
Seldon Core 2 is an MLOps and LLMOps framework for deploying, managing and scaling AI systems in Kubernetes - from singular models, to modular and data-centric applications. With Core 2 you can deploy in a standardized way across a wide range of model types, on-prem or in any cloud, and production-ready out of the box. 

</br>
 <div align="center">
   <a href="https://www.youtube.com/watch?v=ar5lSG_idh4">
     <img src="/.images/Core-intro-thumbnail.png" alt="Introductory Youtube Video" style="max-width: 100%; width: 500px; height: auto;">
   </a>
 </div>
</br>

To contact Seldon regarding commercial use [Contact Seldon](https://www.seldon.io/)

## ğŸ“š Documentation  

The Seldon Core 2 Docs can be found [here](https://docs.seldon.ai/seldon-core-2). For most specific sections, see here:

<p align="center">
  <a href="https://docs.seldon.ai/seldon-core-2/installation/installation">ğŸ”§ Installation</a>  &nbsp â€¢ &nbsp
  <a href="https://docs.seldon.ai/seldon-core-2/user-guide/servers"> â›½ Servers</a>  &nbsp â€¢ &nbsp
  <a href="https://docs.seldon.ai/seldon-core-2/user-guide/models">ğŸ¤– Models</a>  &nbsp â€¢  &nbsp
  <a href="https://docs.seldon.ai/seldon-core-2/user-guide/pipelines"> ğŸ”— Pipelines</a>  &nbsp â€¢ &nbsp
  <a href="https://docs.seldon.ai/seldon-core-2/user-guide/experiment">ğŸ§‘â€ğŸ”¬ Experiments</a>  &nbsp â€¢ &nbsp
  <a href="https://docs.seldon.ai/seldon-core-2/user-guide/performance-tuning">ğŸ“Š Performance Tuning</a>  
</p>

## ğŸ§© Features

 * **Pipelines**: Deploy composable AI applications, leveraging Kafka for realtime data streaming between components
 * **Autoscaling** for models and application components based on native or custom logic
 * **Multi-Model Serving**: Save infrastructure costs by consolidating multiple models on shared inference servers
 * **Overcommit**: Deploy more models than available memory allows, saving infrastructure costs for unused models
 * **Experiments**: Route data between candidate models or pipelines, with support for A/B tests and shadow deployments
 * **Custom Components**: Implement custom logic, drift & outlier detection, LLMs and more through plug-and-play integrate with the rest of Seldon's ecosytem of ML/AI products!
 
## ğŸ”¬ Research

These features are influenced by our position paper on the next generation of ML model serving frameworks: 

ğŸ‘‰ [Desiderata for next generation of ML model serving](http://arxiv.org/abs/2210.14665)

## ğŸ“œ License

Seldon is distributed under the terms of the The Business Source License. A complete version of the license is available in the [LICENSE file](LICENSE) in this repository. Any contribution made to this project will be licensed under the Business Source License.



