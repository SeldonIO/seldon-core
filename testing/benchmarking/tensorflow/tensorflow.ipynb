{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Load and Benchmark Tests\n",
    "\n",
    "Using a pretrained model for [Tensorflow flowers dataset](https://www.tensorflow.org/datasets/catalog/tf_flowers)\n",
    "\n",
    " * Tests the extra latency added by the svcOrch for a medium size image (224x224) classification model.\n",
    " * Load test the model at fixed rate\n",
    " * Benchmark the model to find maximum throughput and saturation handling\n",
    " \n",
    " ## Setup\n",
    " \n",
    "  * Create a 1 node GCP cluster with n1-standard-8 node\n",
    "  * Install Seldon Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/seldon created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"gke_seldon-demos_europe-west4-a_cluster-2\" modified.\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Flowers Model - Latency Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_name):\n",
    "    with open(model_name, 'r') as stream:\n",
    "        resource = yaml.safe_load(stream)\n",
    "        metaName = resource[\"metadata\"][\"name\"]\n",
    "        %env metaName=$metaName\n",
    "        !kubectl apply -f $model_name\n",
    "        !kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=$metaName \\\n",
    "                                 -o jsonpath='{.items[0].metadata.name}')\n",
    "        for i in range(60):\n",
    "            state=!kubectl get sdep $metaName -o jsonpath='{.status.state}'\n",
    "            state=state[0]\n",
    "            print(state)\n",
    "            if state==\"Available\":\n",
    "                break\n",
    "            time.sleep(1)\n",
    "def run_test(vegeta_cfg,vegeta_job,wait_time):\n",
    "    with open(vegeta_job, 'r') as stream:\n",
    "        resource = yaml.safe_load(stream)\n",
    "        metaName = resource[\"metadata\"][\"name\"]\n",
    "        %env metaName=$metaName\n",
    "        !kubectl apply -f $vegeta_cfg\n",
    "        !kubectl create -f $vegeta_job\n",
    "        !kubectl wait --for=condition=complete --timeout=$wait_time job/tf-load-test\n",
    "        raw=!kubectl logs $(kubectl get pods -l job-name=$metaName -o  jsonpath='{.items[0].metadata.name}')\n",
    "        results = json.loads(raw[0])\n",
    "        !kubectl delete -f $vegeta_cfg\n",
    "        !kubectl delete -f $vegeta_job\n",
    "        return results\n",
    "\n",
    "def print_results(results):\n",
    "    print(\"Latencies:\")\n",
    "    print(\"\\tmean:\",results[\"latencies\"][\"mean\"]/1e6,\"ms\")\n",
    "    print(\"\\t50th:\",results[\"latencies\"][\"50th\"]/1e6,\"ms\")\n",
    "    print(\"\\t90th:\",results[\"latencies\"][\"90th\"]/1e6,\"ms\")\n",
    "    print(\"\\t95th:\",results[\"latencies\"][\"95th\"]/1e6,\"ms\")\n",
    "    print(\"\\t99th:\",results[\"latencies\"][\"99th\"]/1e6,\"ms\")\n",
    "    print(\"\")\n",
    "    print(\"Throughput:\",str(results[\"throughput\"])+\"/s\")\n",
    "    print(\"Errors:\",len(results[\"errors\"])>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tf_flowers.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile tf_flowers.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: tf-flowers\n",
    "spec:\n",
    "  protocol: tensorflow\n",
    "  transport: rest\n",
    "  predictors:\n",
    "  - graph:\n",
    "      implementation: TENSORFLOW_SERVER\n",
    "      modelUri: gs://kfserving-samples/models/tensorflow/flowers\n",
    "      name:  flowers\n",
    "      parameters:\n",
    "        - name: model_name\n",
    "          type: STRING\n",
    "          value: flowers\n",
    "    componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - name: flowers\n",
    "          resources:\n",
    "            requests:\n",
    "              cpu: '2'\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: metaName=tf-flowers\n",
      "seldondeployment.machinelearning.seldon.io/tf-flowers created\n",
      "Waiting for deployment \"tf-flowers-default-0-flowers\" rollout to finish: 0 of 1 updated replicas are available...\n",
      "deployment \"tf-flowers-default-0-flowers\" successfully rolled out\n",
      "Available\n"
     ]
    }
   ],
   "source": [
    "run_model(\"tf_flowers.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: metaName=tf-load-test\n",
      "configmap/tf-vegeta-cfg unchanged\n",
      "job.batch/tf-load-test created\n",
      "job.batch/tf-load-test condition met\n",
      "configmap \"tf-vegeta-cfg\" deleted\n",
      "job.batch \"tf-load-test\" deleted\n",
      "{\n",
      "    \"latencies\": {\n",
      "        \"total\": 1200035534611,\n",
      "        \"mean\": 77803133,\n",
      "        \"50th\": 76854636,\n",
      "        \"90th\": 82629749,\n",
      "        \"95th\": 85047245,\n",
      "        \"99th\": 89765289,\n",
      "        \"max\": 127443810,\n",
      "        \"min\": 71799948\n",
      "    },\n",
      "    \"bytes_in\": {\n",
      "        \"total\": 3347008,\n",
      "        \"mean\": 217\n",
      "    },\n",
      "    \"bytes_out\": {\n",
      "        \"total\": 249483200,\n",
      "        \"mean\": 16175\n",
      "    },\n",
      "    \"earliest\": \"2020-07-04T18:03:08.918608479Z\",\n",
      "    \"latest\": \"2020-07-04T18:23:08.921688249Z\",\n",
      "    \"end\": \"2020-07-04T18:23:08.998265316Z\",\n",
      "    \"duration\": 1200003079770,\n",
      "    \"wait\": 76577067,\n",
      "    \"requests\": 15424,\n",
      "    \"rate\": 12.853300345659328,\n",
      "    \"throughput\": 12.852480176734598,\n",
      "    \"success\": 1,\n",
      "    \"status_codes\": {\n",
      "        \"200\": 15424\n",
      "    },\n",
      "    \"errors\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results = run_test(\"tf_vegeta_cfg.yaml\",\"vegeta_1worker.yaml\",\"21m\")\n",
    "print(json.dumps(results, indent=4))\n",
    "mean_with_executor=results[\"latencies\"][\"mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Flowers Model - No executor - Latency Test\n",
    "This test will show that the executor adds around 1-2ms on each request when compared to the last test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tf_flowers.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile tf_flowers.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: tf-flowers\n",
    "spec:\n",
    "  protocol: tensorflow\n",
    "  transport: rest\n",
    "  predictors:\n",
    "  - graph:\n",
    "      implementation: TENSORFLOW_SERVER\n",
    "      modelUri: gs://kfserving-samples/models/tensorflow/flowers\n",
    "      name:  flowers\n",
    "      parameters:\n",
    "        - name: model_name\n",
    "          type: STRING\n",
    "          value: flowers\n",
    "    annotations:\n",
    "        seldon.io/no-engine: \"true\"\n",
    "    componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - name: flowers\n",
    "          resources:\n",
    "            requests:\n",
    "              cpu: '2'\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: metaName=tf-flowers\n",
      "seldondeployment.machinelearning.seldon.io/tf-flowers configured\n",
      "Waiting for deployment \"tf-flowers-default-0-flowers\" rollout to finish: 1 old replicas are pending termination...\n",
      "Waiting for deployment \"tf-flowers-default-0-flowers\" rollout to finish: 1 old replicas are pending termination...\n",
      "deployment \"tf-flowers-default-0-flowers\" successfully rolled out\n",
      "Failed\n",
      "Available\n"
     ]
    }
   ],
   "source": [
    "run_model(\"tf_flowers.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: metaName=tf-load-test\n",
      "configmap/tf-vegeta-cfg created\n",
      "job.batch/tf-load-test created\n",
      "job.batch/tf-load-test condition met\n",
      "configmap \"tf-vegeta-cfg\" deleted\n",
      "job.batch \"tf-load-test\" deleted\n",
      "{\n",
      "    \"latencies\": {\n",
      "        \"total\": 1200069382510,\n",
      "        \"mean\": 76059664,\n",
      "        \"50th\": 75062613,\n",
      "        \"90th\": 80622085,\n",
      "        \"95th\": 83526579,\n",
      "        \"99th\": 88975382,\n",
      "        \"max\": 101852309,\n",
      "        \"min\": 70775664\n",
      "    },\n",
      "    \"bytes_in\": {\n",
      "        \"total\": 3423826,\n",
      "        \"mean\": 217\n",
      "    },\n",
      "    \"bytes_out\": {\n",
      "        \"total\": 255209150,\n",
      "        \"mean\": 16175\n",
      "    },\n",
      "    \"earliest\": \"2020-07-04T18:57:37.737338947Z\",\n",
      "    \"latest\": \"2020-07-04T19:17:37.779148449Z\",\n",
      "    \"end\": \"2020-07-04T19:17:37.854295243Z\",\n",
      "    \"duration\": 1200041809502,\n",
      "    \"wait\": 75146794,\n",
      "    \"requests\": 15778,\n",
      "    \"rate\": 13.147875244903044,\n",
      "    \"throughput\": 13.147051974581446,\n",
      "    \"success\": 1,\n",
      "    \"status_codes\": {\n",
      "        \"200\": 15778\n",
      "    },\n",
      "    \"errors\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results = run_test(\"tf_standalone_vegeta_cfg.yaml\",\"vegeta_1worker.yaml\",\"21m\")\n",
    "print(json.dumps(results, indent=4))\n",
    "mean_no_executor=results[\"latencies\"][\"mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are errors above you will need to rerun as this may skew result becuase of network error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff in ms 1.743469\n"
     ]
    }
   ],
   "source": [
    "diff = (mean_with_executor - mean_no_executor) / 1e6\n",
    "print(\"Diff in ms\",diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark with Saturation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tf_flowers.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile tf_flowers.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: tf-flowers\n",
    "spec:\n",
    "  protocol: tensorflow\n",
    "  transport: rest\n",
    "  predictors:\n",
    "  - graph:\n",
    "      implementation: TENSORFLOW_SERVER\n",
    "      modelUri: gs://kfserving-samples/models/tensorflow/flowers\n",
    "      name:  flowers\n",
    "      parameters:\n",
    "        - name: model_name\n",
    "          type: STRING\n",
    "          value: flowers\n",
    "    componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - name: flowers\n",
    "          resources:\n",
    "            requests:\n",
    "              cpu: '2'\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: metaName=tf-flowers\n",
      "seldondeployment.machinelearning.seldon.io/tf-flowers configured\n",
      "Waiting for deployment \"tf-flowers-default-0-flowers\" rollout to finish: 1 old replicas are pending termination...\n",
      "Waiting for deployment \"tf-flowers-default-0-flowers\" rollout to finish: 1 old replicas are pending termination...\n",
      "deployment \"tf-flowers-default-0-flowers\" successfully rolled out\n",
      "Failed\n",
      "Available\n"
     ]
    }
   ],
   "source": [
    "run_model(\"tf_flowers.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: metaName=tf-load-test\n",
      "configmap/tf-vegeta-cfg created\n",
      "job.batch/tf-load-test created\n",
      "job.batch/tf-load-test condition met\n",
      "configmap \"tf-vegeta-cfg\" deleted\n",
      "job.batch \"tf-load-test\" deleted\n",
      "{\n",
      "    \"latencies\": {\n",
      "        \"total\": 6230883133856,\n",
      "        \"mean\": 4591660378,\n",
      "        \"50th\": 4229617284,\n",
      "        \"90th\": 6169903843,\n",
      "        \"95th\": 7032964423,\n",
      "        \"99th\": 7872317613,\n",
      "        \"max\": 8901616694,\n",
      "        \"min\": 886076277\n",
      "    },\n",
      "    \"bytes_in\": {\n",
      "        \"total\": 294469,\n",
      "        \"mean\": 217\n",
      "    },\n",
      "    \"bytes_out\": {\n",
      "        \"total\": 21949475,\n",
      "        \"mean\": 16175\n",
      "    },\n",
      "    \"earliest\": \"2020-07-04T19:31:56.520502929Z\",\n",
      "    \"latest\": \"2020-07-04T19:32:56.548603582Z\",\n",
      "    \"end\": \"2020-07-04T19:33:00.898401339Z\",\n",
      "    \"duration\": 60028100653,\n",
      "    \"wait\": 4349797757,\n",
      "    \"requests\": 1357,\n",
      "    \"rate\": 22.60607924019301,\n",
      "    \"throughput\": 21.078662608054525,\n",
      "    \"success\": 1,\n",
      "    \"status_codes\": {\n",
      "        \"200\": 1357\n",
      "    },\n",
      "    \"errors\": []\n",
      "}\n",
      "Max Throughtput= 21\n"
     ]
    }
   ],
   "source": [
    "results = run_test(\"tf_vegeta_cfg.yaml\",\"vegeta_max.yaml\",\"11m\")\n",
    "print(json.dumps(results, indent=4))\n",
    "saturation_throughput=int(results[\"throughput\"])\n",
    "print(\"Max Throughtput=\",saturation_throughput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tests with HPA\n",
    "\n",
    "Run with an HPA at twice max saturation rate to check:\n",
    "  * Latencies affected by scaling\n",
    "  * Check for errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tf_flowers.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile tf_flowers.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: tf-flowers\n",
    "spec:\n",
    "  protocol: tensorflow\n",
    "  transport: rest\n",
    "  predictors:\n",
    "  - graph:\n",
    "      implementation: TENSORFLOW_SERVER\n",
    "      modelUri: gs://kfserving-samples/models/tensorflow/flowers\n",
    "      name:  flowers\n",
    "      parameters:\n",
    "        - name: model_name\n",
    "          type: STRING\n",
    "          value: flowers\n",
    "    componentSpecs:\n",
    "    - hpaSpec:\n",
    "        minReplicas: 1\n",
    "        maxReplicas: 5\n",
    "        metrics:\n",
    "        - resource:\n",
    "            name: cpu\n",
    "            targetAverageUtilization: 70\n",
    "          type: Resource\n",
    "      spec:\n",
    "        containers:\n",
    "        - name: flowers\n",
    "          resources:\n",
    "            requests:\n",
    "              cpu: '1'\n",
    "          livenessProbe:\n",
    "            failureThreshold: 3\n",
    "            initialDelaySeconds: 60\n",
    "            periodSeconds: 5\n",
    "            successThreshold: 1\n",
    "            tcpSocket:\n",
    "              port: http\n",
    "            timeoutSeconds: 5\n",
    "          readinessProbe:\n",
    "            failureThreshold: 3\n",
    "            initialDelaySeconds: 20\n",
    "            periodSeconds: 5\n",
    "            successThreshold: 1\n",
    "            tcpSocket:\n",
    "              port: http\n",
    "            timeoutSeconds: 5\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: metaName=tf-flowers\n",
      "seldondeployment.machinelearning.seldon.io/tf-flowers configured\n",
      "Waiting for deployment \"tf-flowers-default-0-flowers\" rollout to finish: 1 old replicas are pending termination...\n",
      "Waiting for deployment \"tf-flowers-default-0-flowers\" rollout to finish: 1 old replicas are pending termination...\n",
      "deployment \"tf-flowers-default-0-flowers\" successfully rolled out\n",
      "Available\n"
     ]
    }
   ],
   "source": [
    "run_model(\"tf_flowers.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DURATION=10m\n",
      "env: RATE=42/1s\n",
      "apiVersion: batch/v1\n",
      "kind: Job\n",
      "metadata:\n",
      "  name: tf-load-test\n",
      "spec:\n",
      "  backoffLimit: 6\n",
      "  parallelism: 1\n",
      "  template:\n",
      "    metadata:\n",
      "      annotations:\n",
      "        sidecar.istio.io/inject: \"false\"\n",
      "    spec:\n",
      "      containers:\n",
      "        - args:\n",
      "            - vegeta -cpus=4 attack -keepalive=false -duration=10m -rate=42/1s -targets=/var/vegeta/cfg\n",
      "              | vegeta report -type=json\n",
      "          command:\n",
      "            - sh\n",
      "            - -c\n",
      "          image: peterevans/vegeta:latest\n",
      "          imagePullPolicy: Always\n",
      "          name: vegeta\n",
      "          volumeMounts:\n",
      "            - mountPath: /var/vegeta\n",
      "              name: tf-vegeta-cfg\n",
      "      restartPolicy: Never\n",
      "      volumes:\n",
      "        - configMap:\n",
      "            defaultMode: 420\n",
      "            name: tf-vegeta-cfg\n",
      "          name: tf-vegeta-cfg\n"
     ]
    }
   ],
   "source": [
    "rate=saturation_throughput*2\n",
    "duration=\"10m\"\n",
    "%env DURATION=$duration\n",
    "%env RATE=$rate/1s\n",
    "!cat vegeta_cfg.tmpl.yaml | envsubst > vegeta.tmp.yaml\n",
    "!cat vegeta.tmp.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: metaName=tf-load-test\n",
      "configmap/tf-vegeta-cfg created\n",
      "job.batch/tf-load-test created\n",
      "job.batch/tf-load-test condition met\n",
      "configmap \"tf-vegeta-cfg\" deleted\n",
      "job.batch \"tf-load-test\" deleted\n",
      "{\n",
      "    \"latencies\": {\n",
      "        \"total\": 149270246390025,\n",
      "        \"mean\": 5923422475,\n",
      "        \"50th\": 300207052,\n",
      "        \"90th\": 30001304102,\n",
      "        \"95th\": 30032935844,\n",
      "        \"99th\": 30541862186,\n",
      "        \"max\": 32350943067,\n",
      "        \"min\": 72003155\n",
      "    },\n",
      "    \"bytes_in\": {\n",
      "        \"total\": 4678954,\n",
      "        \"mean\": 185.67277777777778\n",
      "    },\n",
      "    \"bytes_out\": {\n",
      "        \"total\": 348991800,\n",
      "        \"mean\": 13848.880952380952\n",
      "    },\n",
      "    \"earliest\": \"2020-07-04T19:38:42.009484454Z\",\n",
      "    \"latest\": \"2020-07-04T19:48:41.989427412Z\",\n",
      "    \"end\": \"2020-07-04T19:48:42.179397209Z\",\n",
      "    \"duration\": 599979942958,\n",
      "    \"wait\": 189969797,\n",
      "    \"requests\": 25200,\n",
      "    \"rate\": 42.00140403987481,\n",
      "    \"throughput\": 35.9264927177414,\n",
      "    \"success\": 0.8556349206349206,\n",
      "    \"status_codes\": {\n",
      "        \"0\": 3624,\n",
      "        \"200\": 21562,\n",
      "        \"500\": 14\n",
      "    },\n",
      "    \"errors\": [\n",
      "        \"Post \\\"http://tf-flowers-default.seldon.svc.cluster.local:8000/v1/models/flowers/:predict\\\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\",\n",
      "        \"500 Internal Server Error\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results = run_test(\"tf_vegeta_cfg.yaml\",\"vegeta.tmp.yaml\",\"11m\")\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latencies:\n",
      "\tmean: 5923.422475 ms\n",
      "\t50th: 300.207052 ms\n",
      "\t90th: 30001.304102 ms\n",
      "\t95th: 30032.935844 ms\n",
      "\t99th: 30541.862186 ms\n",
      "\n",
      "Throughput: 35.9264927177414/s\n",
      "Errors: True\n"
     ]
    }
   ],
   "source": [
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
