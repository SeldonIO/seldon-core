{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "forced-trading",
   "metadata": {},
   "source": [
    "# Multimodel serving with over-commit example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745880c",
   "metadata": {},
   "source": [
    "Note: this notebook requires access to internal services, so either `make start-all-host` or expose the relevant ports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ebabe7",
   "metadata": {},
   "source": [
    "## `iris` model on `MLServer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52febfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env INFER_ENDPOINT=0.0.0.0:9000\n",
    "%env SCHEDULER_ENDPOINT=0.0.0.0:9004\n",
    "%env MLSERVER_DEBUG=0.0.0.0:7777\n",
    "%env TRITON_DEBUG=0.0.0.0:7778"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf5eb28",
   "metadata": {},
   "source": [
    "By default if running locally there is 1 replica of `mlserver` with memory slots up to 1000000 MB (10GB) and 20% overcommit budget. We will load 11 `iris` models each requiring 1MB worth of memory slots as an example. These numbers allow for 10 models to be active at the same time and 1 model to be evicted to disk.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in {1..11}; \n",
    "do\n",
    "\n",
    "echo \"loading model iris$i\"\n",
    "\n",
    "data='{ \n",
    "        \"model\":{ \n",
    "            \"meta\": {\"name\":\"iris'\"$i\"'\"}, \n",
    "            \"modelSpec\" : { \n",
    "                \"uri\":\"gs://seldon-models/mlserver/iris\", \n",
    "                \"requirements\":[\"sklearn\"],  \n",
    "                \"memoryBytes\":1000000}, \n",
    "            \"deploymentSpec\": {\"replicas\":1}\n",
    "            }\n",
    "      }'\n",
    "\n",
    "grpcurl -d \"$data\" \\\n",
    "-plaintext \\\n",
    "-import-path ../../apis \\\n",
    "-proto ../../apis/mlops/scheduler/scheduler.proto \"$SCHEDULER_ENDPOINT\" seldon.mlops.scheduler.Scheduler/LoadModel\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa0e33",
   "metadata": {},
   "source": [
    "Get the list of models on this mlserver replica and whether they are loaded in main memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-theta",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "grpcurl -d '{}' \\\n",
    "         -plaintext \\\n",
    "         -import-path ../../apis/ \\\n",
    "         -proto ../../apis/mlops/agent_debug/agent_debug.proto  ${MLSERVER_DEBUG} seldon.mlops.agent_debug.AgentDebugService/ReplicaStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-geography",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in {1..11}; \n",
    "do\n",
    "\n",
    "url=http://${INFER_ENDPOINT}/v2/models/iris${i}/infer \n",
    "curl -i -s \"${url}\" -H \"Content-Type: application/json\" \\\n",
    "        -d '{\"inputs\": [{\"name\": \"predict\", \"shape\": [1, 4], \"datatype\": \"FP32\", \"data\": [[1, 2, 3, 4]]}]}'\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e62d9",
   "metadata": {},
   "source": [
    "Doing inference for all models succeeds as swapping in and out models is handled automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6359c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in {1..10}; \n",
    "do \n",
    "\n",
    "for j in {1..11};\n",
    "do\n",
    "curl http://\"$INFER_ENDPOINT\"/v2/models/iris$j/infer -H \"Content-Type: application/json\"  \\\n",
    "        -d '{\"inputs\": [{\"name\": \"predict\", \"shape\": [1, 4], \"datatype\": \"FP32\", \"data\": [[1, 2, 3, 4]]}]}' &\n",
    "done\n",
    "\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b53afb",
   "metadata": {},
   "source": [
    "Unload models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for i in {1..11};\n",
    "do\n",
    "\n",
    "grpcurl -d '{\"model\": {\"name\" : \"iris'\"$i\"'\"}}' \\\n",
    "         -plaintext \\\n",
    "         -import-path ../../apis/ \\\n",
    "         -proto ../../apis/mlops/scheduler/scheduler.proto \"$SCHEDULER_ENDPOINT\" seldon.mlops.scheduler.Scheduler/UnloadModel\n",
    "\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417559e0",
   "metadata": {},
   "source": [
    "## `tfsimple` model on `triton`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in {1..11}; \n",
    "do\n",
    "\n",
    "echo \"loading model tfsimple$i\"\n",
    "\n",
    "data='{ \n",
    "        \"model\":{ \n",
    "            \"meta\": {\"name\":\"tfsimple'\"$i\"'\"}, \n",
    "            \"modelSpec\" : { \n",
    "                \"uri\":\"gs://seldon-models/triton/simple\", \n",
    "                \"requirements\":[\"tensorflow\"],  \n",
    "                \"memoryBytes\":1000000}, \n",
    "            \"deploymentSpec\": {\"replicas\":1}\n",
    "            }\n",
    "      }'\n",
    "\n",
    "grpcurl -d \"$data\" \\\n",
    "-plaintext \\\n",
    "-import-path ../../apis \\\n",
    "-proto ../../apis/mlops/scheduler/scheduler.proto \"$SCHEDULER_ENDPOINT\" seldon.mlops.scheduler.Scheduler/LoadModel\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in {1..11}; \n",
    "do\n",
    "\n",
    "url=http://${INFER_ENDPOINT}/v2/models/tfsimple${i}/infer \n",
    "curl -i -s \"${url}\" -H \"Content-Type: application/json\" \\\n",
    "        -d '{\"inputs\":[{\"name\":\"INPUT0\",\"data\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],\"datatype\":\"INT32\",\"shape\":[1,16]},{\"name\":\"INPUT1\",\"data\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],\"datatype\":\"INT32\",\"shape\":[1,16]}]}'\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3682fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "grpcurl -d '{}' \\\n",
    "         -plaintext \\\n",
    "         -import-path ../../apis/ \\\n",
    "         -proto ../../apis/mlops/agent_debug/agent_debug.proto  ${TRITON_DEBUG} seldon.mlops.agent_debug.AgentDebugService/ReplicaStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for i in {1..11};\n",
    "do\n",
    "\n",
    "grpcurl -d '{\"model\": {\"name\" : \"tfsimple'\"$i\"'\"}}' \\\n",
    "         -plaintext \\\n",
    "         -import-path ../../apis/ \\\n",
    "         -proto ../../apis/mlops/scheduler/scheduler.proto \"$SCHEDULER_ENDPOINT\" seldon.mlops.scheduler.Scheduler/UnloadModel\n",
    "\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35cb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('seldon-core-v2-python-3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc8b7b3d3b143757bd161269cf4ea949ead8c2ebc12155bae9e3cf57923f4a90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
