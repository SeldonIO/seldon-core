{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "forced-trading",
   "metadata": {},
   "source": [
    "# Multimodel serving with over-commit example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745880c",
   "metadata": {},
   "source": [
    "Note: this notebook requires access to internal services, so either `make start-all-host` or expose the relevant ports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ebabe7",
   "metadata": {},
   "source": [
    "## `iris` model on `MLServer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52febfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env INFER_ENDPOINT=0.0.0.0:9000\n",
    "%env SCHEDULER_ENDPOINT=0.0.0.0:9004\n",
    "%env MLSERVER_DEBUG=0.0.0.0:7777\n",
    "%env TRITON_DEBUG=0.0.0.0:7778"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf5eb28",
   "metadata": {},
   "source": [
    "By default if running locally there is 1 replica of `mlserver` with memory slots up to 10MB and 20% overcommit budget. We will load 11 `iris` models each requiring 1MB worth of memory slots as an example. These numbers allow for 10 models to be active at the same time and 1 model to be evicted to disk.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in {1..11}; \n",
    "do\n",
    "\n",
    "echo \"loading model iris$i\"\n",
    "\n",
    "data='{ \n",
    "        \"model\":{ \n",
    "            \"meta\": {\"name\":\"iris'\"$i\"'\"}, \n",
    "            \"modelSpec\" : { \n",
    "                \"uri\":\"gs://seldon-models/mlserver/iris\", \n",
    "                \"requirements\":[\"sklearn\"],  \n",
    "                \"memoryBytes\":1000000}, \n",
    "            \"deploymentSpec\": {\"replicas\":1}\n",
    "            }\n",
    "      }'\n",
    "\n",
    "grpcurl -d \"$data\" \\\n",
    "-plaintext \\\n",
    "-import-path ../../apis \\\n",
    "-proto ../../apis/mlops/scheduler/scheduler.proto \"$SCHEDULER_ENDPOINT\" seldon.mlops.scheduler.Scheduler/LoadModel\n",
    "\n",
    "sleep 0.01\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa0e33",
   "metadata": {},
   "source": [
    "Get the list of models on this mlserver replica and whether they are loaded in main memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-theta",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "grpcurl -d '{}' \\\n",
    "         -plaintext \\\n",
    "         -import-path ../../apis/ \\\n",
    "         -proto ../../apis/mlops/agent_debug/agent_debug.proto  ${MLSERVER_DEBUG} seldon.mlops.agent_debug.AgentDebugService/ReplicaStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-geography",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in {1..11}; \n",
    "do\n",
    "\n",
    "url=http://${INFER_ENDPOINT}/v2/models/iris${i}/infer \n",
    "ret=`curl -s -o /dev/null -w \"%{http_code}\" \"${url}\" -H \"Content-Type: application/json\" \\\n",
    "        -d '{\"inputs\": [{\"name\": \"predict\", \"shape\": [1, 4], \"datatype\": \"FP32\", \"data\": [[1, 2, 3, 4]]}]}'`\n",
    "if [ $ret -ne 200 ]; then\n",
    "    echo \"Failed with code ${ret}\"\n",
    "    exit\n",
    "fi\n",
    "\n",
    "done\n",
    "echo \"All succeeded\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e62d9",
   "metadata": {},
   "source": [
    "Doing inference for all models succeeds as swapping in and out models is handled automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6359c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in {1..10}; \n",
    "do \n",
    "\n",
    "for j in {1..11};\n",
    "do\n",
    "curl http://\"$INFER_ENDPOINT\"/v2/models/iris$j/infer -H \"Content-Type: application/json\"  \\\n",
    "        -d '{\"inputs\": [{\"name\": \"predict\", \"shape\": [1, 4], \"datatype\": \"FP32\", \"data\": [[1, 2, 3, 4]]}]}' &\n",
    "done\n",
    "\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b53afb",
   "metadata": {},
   "source": [
    "Unload models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for i in {1..11};\n",
    "do\n",
    "\n",
    "grpcurl -d '{\"model\": {\"name\" : \"iris'\"$i\"'\"}}' \\\n",
    "         -plaintext \\\n",
    "         -import-path ../../apis/ \\\n",
    "         -proto ../../apis/mlops/scheduler/scheduler.proto \"$SCHEDULER_ENDPOINT\" seldon.mlops.scheduler.Scheduler/UnloadModel\n",
    "\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417559e0",
   "metadata": {},
   "source": [
    "## `tfsimple` model on `triton`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1302a2c5",
   "metadata": {},
   "source": [
    "With `tfsimple` on `triton` we will reduce the memory slot required to 100KB, which will allow us to load at least 100 models on the server in memory. The remaining models (10) will have to be evicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in {1..110}; \n",
    "do\n",
    "\n",
    "echo \"loading model tfsimple$i\"\n",
    "\n",
    "data='{ \n",
    "        \"model\":{ \n",
    "            \"meta\": {\"name\":\"tfsimple'\"$i\"'\"}, \n",
    "            \"modelSpec\" : { \n",
    "                \"uri\":\"gs://seldon-models/triton/simple\", \n",
    "                \"requirements\":[\"tensorflow\"],  \n",
    "                \"memoryBytes\":100000}, \n",
    "            \"deploymentSpec\": {\"replicas\":1}\n",
    "            }\n",
    "      }'\n",
    "\n",
    "grpcurl -d \"$data\" \\\n",
    "-plaintext \\\n",
    "-import-path ../../apis \\\n",
    "-proto ../../apis/mlops/scheduler/scheduler.proto \"$SCHEDULER_ENDPOINT\" seldon.mlops.scheduler.Scheduler/LoadModel\n",
    "\n",
    "sleep 0.01\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in {1..110}; \n",
    "do\n",
    "\n",
    "url=http://${INFER_ENDPOINT}/v2/models/tfsimple${i}/infer \n",
    "ret=`curl -s -o /dev/null -w \"%{http_code}\" curl -s -o /dev/null -w \"%{http_code}\" \"${url}\" -H \"Content-Type: application/json\" \\\n",
    "        -d '{\"inputs\":[{\"name\":\"INPUT0\",\"data\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],\"datatype\":\"INT32\",\"shape\":[1,16]},{\"name\":\"INPUT1\",\"data\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],\"datatype\":\"INT32\",\"shape\":[1,16]}]}'`\n",
    "if [ $ret -ne 200 ]; then\n",
    "    echo \"Failed with code ${ret}\"\n",
    "    exit\n",
    "fi\n",
    "done\n",
    "echo \"All succeeded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3682fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "grpcurl -d '{}' \\\n",
    "         -plaintext \\\n",
    "         -import-path ../../apis/ \\\n",
    "         -proto ../../apis/mlops/agent_debug/agent_debug.proto  ${TRITON_DEBUG} seldon.mlops.agent_debug.AgentDebugService/ReplicaStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for i in {1..110};\n",
    "do\n",
    "\n",
    "grpcurl -d '{\"model\": {\"name\" : \"tfsimple'\"$i\"'\"}}' \\\n",
    "         -plaintext \\\n",
    "         -import-path ../../apis/ \\\n",
    "         -proto ../../apis/mlops/scheduler/scheduler.proto \"$SCHEDULER_ENDPOINT\" seldon.mlops.scheduler.Scheduler/UnloadModel\n",
    "\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35cb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('seldon-core-v2-python-3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc8b7b3d3b143757bd161269cf4ea949ead8c2ebc12155bae9e3cf57923f4a90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
