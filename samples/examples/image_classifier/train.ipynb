{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95804711",
   "metadata": {},
   "source": [
    "## Train Outlier Detector\n",
    "\n",
    "Based on [Alibi Detect Example](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/od_vae_cifar10.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97fa4aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 18:02:43.572083: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-02 18:02:43.572120: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Layer, Reshape, InputLayer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from alibi_detect.models.tensorflow import elbo\n",
    "from alibi_detect.od import OutlierVAE\n",
    "from alibi_detect.utils.fetching import fetch_detector\n",
    "from alibi_detect.utils.perturbation import apply_mask\n",
    "from alibi_detect.saving import save_detector, load_detector\n",
    "from alibi_detect.utils.visualize import plot_instance_score, plot_feature_outlier_image\n",
    "\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f421df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "train, test = tf.keras.datasets.cifar10.load_data()\n",
    "X_train, y_train = train\n",
    "X_test, y_test = test\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80363be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [=] - 408s 521ms/step - loss_ma: 12246.5974\n",
      "782/782 [=] - 441s 563ms/step - loss_ma: -336.8379\n",
      "782/782 [=] - 514s 656ms/step - loss_ma: -2060.8556\n",
      "782/782 [=] - 385s 491ms/step - loss_ma: -2942.0786\n",
      "782/782 [=] - 334s 426ms/step - loss_ma: -3482.4651\n",
      "782/782 [=] - 331s 422ms/step - loss_ma: -3826.7684\n",
      "782/782 [=] - 328s 419ms/step - loss_ma: -4113.3548\n",
      "782/782 [=] - 324s 414ms/step - loss_ma: -4344.3997\n",
      "782/782 [=] - 356s 455ms/step - loss_ma: -4517.2223\n",
      "782/782 [=] - 340s 434ms/step - loss_ma: -4636.2948\n",
      "782/782 [=] - 338s 432ms/step - loss_ma: -4749.2001\n",
      "782/782 [=] - 332s 423ms/step - loss_ma: -4853.0608\n",
      "782/782 [=] - 333s 425ms/step - loss_ma: -4944.8810\n",
      "782/782 [=] - 326s 416ms/step - loss_ma: -5008.7755\n",
      "782/782 [=] - 326s 416ms/step - loss_ma: -5083.0938\n",
      "782/782 [=] - 315s 402ms/step - loss_ma: -5140.1222\n",
      "782/782 [=] - 311s 397ms/step - loss_ma: -5201.4831\n",
      "782/782 [=] - 316s 403ms/step - loss_ma: -5250.6943\n",
      "782/782 [=] - 318s 406ms/step - loss_ma: -5283.1387\n",
      "782/782 [=] - 316s 404ms/step - loss_ma: -5321.9071\n",
      "782/782 [=] - 320s 409ms/step - loss_ma: -5368.1527\n",
      "782/782 [=] - 321s 409ms/step - loss_ma: -5388.1669\n",
      "782/782 [=] - 317s 405ms/step - loss_ma: -5425.3241\n",
      "782/782 [=] - 319s 408ms/step - loss_ma: -5449.0800\n",
      "782/782 [=] - 320s 409ms/step - loss_ma: -5481.8549\n",
      "782/782 [=] - 319s 407ms/step - loss_ma: -5511.5501\n",
      "782/782 [=] - 318s 406ms/step - loss_ma: -5527.1451\n",
      "782/782 [=] - 319s 408ms/step - loss_ma: -5554.7566\n",
      "782/782 [=] - 373s 476ms/step - loss_ma: -5573.3425\n",
      "782/782 [=] - 376s 480ms/step - loss_ma: -5599.4756\n",
      "782/782 [=] - 375s 479ms/step - loss_ma: -5612.1058\n",
      "782/782 [=] - 375s 478ms/step - loss_ma: -5622.7508\n",
      "782/782 [=] - 373s 476ms/step - loss_ma: -5642.8896\n",
      "782/782 [=] - 374s 477ms/step - loss_ma: -5661.9375\n",
      "782/782 [=] - 373s 476ms/step - loss_ma: -5674.5788\n",
      "782/782 [=] - 374s 477ms/step - loss_ma: -5683.5199\n",
      "782/782 [=] - 373s 476ms/step - loss_ma: -5697.1596\n",
      "782/782 [=] - 375s 479ms/step - loss_ma: -5711.3716\n",
      "782/782 [=] - 376s 480ms/step - loss_ma: -5721.1513\n",
      "782/782 [=] - 377s 481ms/step - loss_ma: -5733.8188\n",
      "782/782 [=] - 376s 480ms/step - loss_ma: -5741.6455\n",
      "782/782 [=] - 376s 480ms/step - loss_ma: -5743.0460\n",
      "782/782 [=] - 376s 480ms/step - loss_ma: -5756.9715\n",
      "782/782 [=] - 376s 480ms/step - loss_ma: -5761.5570\n",
      "782/782 [=] - 376s 480ms/step - loss_ma: -5776.9497\n",
      "782/782 [=] - 376s 479ms/step - loss_ma: -5783.7933\n",
      "782/782 [=] - 374s 478ms/step - loss_ma: -5791.9981\n",
      "782/782 [=] - 377s 481ms/step - loss_ma: -5801.7900\n",
      "782/782 [=] - 377s 481ms/step - loss_ma: -5803.0183\n",
      "782/782 [=] - 376s 480ms/step - loss_ma: -5816.9740\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 1024\n",
    "\n",
    "encoder_net = tf.keras.Sequential(\n",
    "    [\n",
    "        InputLayer(input_shape=(32, 32, 3)),\n",
    "        Conv2D(64, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "        Conv2D(128, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "        Conv2D(512, 4, strides=2, padding='same', activation=tf.nn.relu)\n",
    "    ])\n",
    "\n",
    "decoder_net = tf.keras.Sequential(\n",
    "    [\n",
    "        InputLayer(input_shape=(latent_dim,)),\n",
    "        Dense(4*4*128),\n",
    "        Reshape(target_shape=(4, 4, 128)),\n",
    "        Conv2DTranspose(256, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "        Conv2DTranspose(64, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "        Conv2DTranspose(3, 4, strides=2, padding='same', activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "# initialize outlier detector\n",
    "od = OutlierVAE(threshold=.015,  # threshold for outlier score\n",
    "                score_type='mse',  # use MSE of reconstruction error for outlier detection\n",
    "                encoder_net=encoder_net,  # can also pass VAE model instead\n",
    "                decoder_net=decoder_net,  # of separate encoder and decoder\n",
    "                latent_dim=latent_dim,\n",
    "                samples=2)\n",
    "# train\n",
    "od.fit(X_train,\n",
    "        loss_fn=elbo,\n",
    "        cov_elbo=dict(sim=.05),\n",
    "        epochs=50,\n",
    "        verbose=True)\n",
    "\n",
    "# save the trained outlier detector\n",
    "save_detector(od, \"./outlier-detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a38614a",
   "metadata": {},
   "source": [
    "Create a MLServer model settings file: `model-settings.json`:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"cifar10-outlier-detect\",\n",
    "  \"implementation\": \"mlserver_alibi_detect.AlibiDetectRuntime\",\n",
    "  \"parameters\": {\n",
    "    \"uri\": \"./\",\n",
    "    \"version\": \"v0.1.0\"\n",
    "  }\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "Save to local or remote storage the directory. Here we saved to Google Storage:\n",
    "\n",
    "```bash\n",
    "gsutil ls -R gs://seldon-models/mlserver/alibi-detect/cifar10-outlier \n",
    "\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-outlier/:\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-outlier/\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-outlier/OutlierVAE.dill\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-outlier/meta.dill\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-outlier/model-settings.json\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-outlier/model/:\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-outlier/model/checkpoint\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-outlier/model/decoder_net.h5\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-outlier/model/encoder_net.h5\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-outlier/model/vae.ckpt.data-00000-of-00001\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-outlier/model/vae.ckpt.index\n",
    "\n",
    "```\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785949c4",
   "metadata": {},
   "source": [
    "## Train Drift Detector\n",
    "\n",
    "Based on [Alibi Detect Example](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_ks_cifar10.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81395f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from alibi_detect.cd import KSDrift\n",
    "from alibi_detect.models.tensorflow import scale_by_instance\n",
    "from alibi_detect.utils.fetching import fetch_tf_model, fetch_detector\n",
    "from alibi_detect.saving import save_detector, load_detector\n",
    "from alibi_detect.datasets import fetch_cifar10c, corruption_types_cifar10c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5338d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "y_train = y_train.astype('int64').reshape(-1,)\n",
    "y_test = y_test.astype('int64').reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2acb47cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 32, 32, 3) (5000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n_test = X_test.shape[0]\n",
    "idx = np.random.choice(n_test, size=n_test // 2, replace=False)\n",
    "idx_h0 = np.delete(np.arange(n_test), idx, axis=0)\n",
    "X_ref,y_ref = X_test[idx], y_test[idx]\n",
    "X_h0, y_h0 = X_test[idx_h0], y_test[idx_h0]\n",
    "print(X_ref.shape, X_h0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28d5e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Directory drift-detector/preprocess_fn/model does not exist and is now created.\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, InputLayer, Reshape\n",
    "from alibi_detect.cd.tensorflow import preprocess_drift\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# define encoder\n",
    "encoding_dim = 32\n",
    "encoder_net = tf.keras.Sequential(\n",
    "  [\n",
    "      InputLayer(input_shape=(32, 32, 3)),\n",
    "      Conv2D(64, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2D(128, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2D(512, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Flatten(),\n",
    "      Dense(encoding_dim,)\n",
    "  ]\n",
    ")\n",
    "\n",
    "# define preprocessing function\n",
    "preprocess_fn = partial(preprocess_drift, model=encoder_net, batch_size=512)\n",
    "\n",
    "# initialise drift detector\n",
    "p_val = .05\n",
    "cd = KSDrift(X_ref, p_val=p_val, preprocess_fn=preprocess_fn)\n",
    "\n",
    "# we can also save/load an initialised detector\n",
    "filepath = 'my_path'  # change to directory where detector is saved\n",
    "save_detector(cd, \"./drift-detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb4314a",
   "metadata": {},
   "source": [
    "Create a MLServer model settings file: `model-settings.json`:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"cifar10-drift\",\n",
    "  \"implementation\": \"mlserver_alibi_detect.AlibiDetectRuntime\",\n",
    "  \"parameters\": {\n",
    "    \"uri\": \"./\",\n",
    "    \"version\": \"v0.1.0\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Save to local or remote storage the directory. Here we saved to Google Storage:\n",
    "\n",
    "```bash\n",
    "gsutil ls -R gs://seldon-models/mlserver/alibi-detect/cifar10-drift \n",
    "\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-drift/:\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-drift/\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-drift/KSDrift.dill\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-drift/meta.dill\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-drift/model-settings.json\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-drift/model/:\n",
    "gs://seldon-models/mlserver/alibi-detect/cifar10-drift/model/encoder.h5\n",
    "\n",
    "```\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
