{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Machine Learning Models using kubectl\n",
    "This demo shows how you can interact directly with kubernetes using kubectl to create and manage runtime machine learning models. It uses Minikube as the target Kubernetes cluster.\n",
    "<img src=\"images/deploy-graph.png\" alt=\"predictor with canary\" title=\"ml graph\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequistes\n",
    "You will need\n",
    " - [Git clone of Seldon Core](https://github.com/SeldonIO/seldon-core)\n",
    " - [Minikube](https://github.com/kubernetes/minikube) version v0.24.0 or greater\n",
    " - [python grpc tools](https://grpc.io/docs/quickstart/python.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start minikube and ensure custom resource validation is activated and ther is 5G of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!minikube start --memory=5000 --feature-gates=CustomResourceValidation=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Helm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$HELM_HOME has been configured at /home/clive/.helm.\n",
      "Warning: Tiller is already installed in the cluster.\n",
      "(Use --client-only to suppress this message, or --upgrade to upgrade Tiller to the current version.)\n",
      "Happy Helming!\n"
     ]
    }
   ],
   "source": [
    "!helm init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label the node to allow load testing to run on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node \"fresh\" not labeled\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl label nodes `kubectl get nodes -o jsonpath='{.items[0].metadata.name}'` role=locust --overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up REST and gRPC methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install gRPC modules for the prediction protos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cp ../proto/prediction.proto ./proto\n",
    "!python -m grpc.tools.protoc -I./proto --python_out=./proto --grpc_python_out=./proto ./proto/prediction.proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustration of both REST and gRPC requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from proto import prediction_pb2\n",
    "from proto import prediction_pb2_grpc\n",
    "import grpc\n",
    "import commands\n",
    "\n",
    "MINIKUBE_IP=commands.getoutput('minikube ip')\n",
    "\n",
    "def get_token():\n",
    "    payload = {'grant_type': 'client_credentials'}\n",
    "    response = requests.post(\n",
    "                \"http://\"+MINIKUBE_IP+\":30032/oauth/token\",\n",
    "                auth=HTTPBasicAuth('oauth-key', 'oauth-secret'),\n",
    "                data=payload)\n",
    "    token =  response.json()[\"access_token\"]\n",
    "    return token\n",
    "\n",
    "def rest_request():\n",
    "    token = get_token()\n",
    "    headers = {'Authorization': 'Bearer '+token}\n",
    "    payload = {\"data\":{\"names\":[\"a\",\"b\"],\"tensor\":{\"shape\":[2,2],\"values\":[0,0,1,1]}}}\n",
    "    response = requests.post(\n",
    "                \"http://\"+MINIKUBE_IP+\":30032/api/v0.1/predictions\",\n",
    "                headers=headers,\n",
    "                json=payload)\n",
    "    print response.text\n",
    "    \n",
    "def grpc_request():\n",
    "    token = get_token()\n",
    "    datadef = prediction_pb2.DefaultData(\n",
    "            names = [\"a\",\"b\"],\n",
    "            tensor = prediction_pb2.Tensor(\n",
    "                shape = [3,2],\n",
    "                values = [1.0,1.0,2.0,3.0,4.0,5.0]\n",
    "                )\n",
    "            )\n",
    "    request = prediction_pb2.SeldonMessage(data = datadef)\n",
    "    channel = grpc.insecure_channel(MINIKUBE_IP+\":30033\")\n",
    "    stub = prediction_pb2_grpc.SeldonStub(channel)\n",
    "    metadata = [('oauth_token', token)]\n",
    "    response = stub.Predict(request=request,metadata=metadata)\n",
    "    print response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start seldon-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME:   seldon-core\n",
      "LAST DEPLOYED: Wed Jan 24 16:31:43 2018\n",
      "NAMESPACE: default\n",
      "STATUS: DEPLOYED\n",
      "\n",
      "RESOURCES:\n",
      "==> v1/Job\n",
      "NAME                            DESIRED  SUCCESSFUL  AGE\n",
      "grafana-prom-import-dashboards  1        0           2s\n",
      "\n",
      "==> v1beta1/Deployment\n",
      "NAME                     DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE\n",
      "alertmanager-deployment  1        1        1           0          2s\n",
      "seldon-apiserver         1        1        1           0          2s\n",
      "seldon-cluster-manager   1        1        1           0          2s\n",
      "grafana-prom-deployment  1        1        1           0          2s\n",
      "kafka                    1        1        1           0          2s\n",
      "prometheus-deployment    1        1        1           0          2s\n",
      "redis                    1        1        1           0          2s\n",
      "\n",
      "==> v1/Service\n",
      "NAME                      TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)                        AGE\n",
      "alertmanager              ClusterIP  10.109.60.246   <none>       80/TCP                         2s\n",
      "seldon-apiserver          NodePort   10.108.75.248   <none>       8080:30032/TCP,5000:30033/TCP  2s\n",
      "grafana-prom              NodePort   10.106.21.7     <none>       80:30034/TCP                   2s\n",
      "kafka                     NodePort   10.103.159.220  <none>       9092:30010/TCP                 2s\n",
      "prometheus-node-exporter  ClusterIP  None            <none>       9100/TCP                       2s\n",
      "prometheus-seldon         ClusterIP  10.102.249.205  <none>       80/TCP                         2s\n",
      "redis                     ClusterIP  10.103.92.39    <none>       6379/TCP                       1s\n",
      "zookeeper-1               ClusterIP  10.96.109.253   <none>       2181/TCP,2888/TCP,3888/TCP     1s\n",
      "zookeeper-2               ClusterIP  10.100.165.161  <none>       2181/TCP,2888/TCP,3888/TCP     1s\n",
      "zookeeper-3               ClusterIP  10.100.226.57   <none>       2181/TCP,2888/TCP,3888/TCP     1s\n",
      "\n",
      "==> v1/Pod\n",
      "NAME         READY  STATUS   RESTARTS  AGE\n",
      "zookeeper-1  0/1    Pending  0         1s\n",
      "zookeeper-2  0/1    Pending  0         1s\n",
      "zookeeper-3  0/1    Pending  0         1s\n",
      "\n",
      "==> v1/Pod(related)\n",
      "grafana-prom-import-dashboards-8x74c      0/1  ContainerCreating  0  2s\n",
      "alertmanager-deployment-6f5c9c5f58-98jf8  0/1  ContainerCreating  0  2s\n",
      "seldon-apiserver-85b66fd56f-pz5vx         0/1  ContainerCreating  0  2s\n",
      "seldon-cluster-manager-7cb44ddc7-skbcc    0/1  ContainerCreating  0  2s\n",
      "grafana-prom-deployment-bf46c5988-cmwtl   0/1  ContainerCreating  0  2s\n",
      "kafka-68cc697c5-g464q                     0/1  Pending            0  2s\n",
      "prometheus-node-exporter-2qj8m            0/1  Pending            0  2s\n",
      "prometheus-deployment-6b7f9fcbc6-bttk9    0/1  Pending            0  2s\n",
      "redis-5767447797-j42t7                    0/1  Pending            0  1s\n",
      "\n",
      "==> v1/ConfigMap\n",
      "NAME                       DATA  AGE\n",
      "alertmanager-server-conf   1     2s\n",
      "grafana-import-dashboards  5     2s\n",
      "prometheus-rules           4     2s\n",
      "prometheus-server-conf     1     2s\n",
      "\n",
      "==> v1beta1/CustomResourceDefinition\n",
      "NAME                                         AGE\n",
      "seldondeployments.machinelearning.seldon.io  2s\n",
      "\n",
      "==> v1beta1/DaemonSet\n",
      "NAME                      DESIRED  CURRENT  READY  UP-TO-DATE  AVAILABLE  NODE SELECTOR  AGE\n",
      "prometheus-node-exporter  1        1        0      1           0          <none>         2s\n",
      "\n",
      "==> v1/Secret\n",
      "NAME                 TYPE    DATA  AGE\n",
      "grafana-prom-secret  Opaque  1     2s\n",
      "\n",
      "\n",
      "NOTES:\n",
      "NOTES: TODO\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!helm install ../helm-charts/seldon-core --name seldon-core \\\n",
    "    --set grafana_prom_admin_password=password \\\n",
    "    --set persistence.enabled=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all services are running before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                       READY     STATUS              RESTARTS   AGE\r\n",
      "alertmanager-deployment-6f5c9c5f58-hzfvs   0/1       ContainerCreating   0          3s\r\n",
      "grafana-prom-deployment-bf46c5988-89744    0/1       ContainerCreating   0          3s\r\n",
      "grafana-prom-import-dashboards-c7gbj       0/1       ContainerCreating   0          3s\r\n",
      "kafka-68cc697c5-hhdvs                      0/1       ContainerCreating   0          3s\r\n",
      "prometheus-deployment-6b7f9fcbc6-f56n9     0/1       ContainerCreating   0          3s\r\n",
      "prometheus-node-exporter-ddlkl             0/1       ContainerCreating   0          3s\r\n",
      "redis-5767447797-h456r                     0/1       ContainerCreating   0          3s\r\n",
      "seldon-apiserver-775c6f4cdf-8hzps          1/1       Running             0          3s\r\n",
      "seldon-cluster-manager-69fcb5f4-2vt2p      1/1       Running             0          3s\r\n",
      "zookeeper-1                                0/1       ContainerCreating   0          2s\r\n",
      "zookeeper-2                                0/1       ContainerCreating   0          2s\r\n",
      "zookeeper-3                                0/1       ContainerCreating   0          2s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating with Kubernetes API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using OpenAPI Schema certain basic validation can be done before the custom resource is accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SeldonDeployment \"seldon-deployment-example\" is invalid: []: Invalid value: map[string]interface {}{\"apiVersion\":\"machinelearning.seldon.io/v1alpha1\", \"kind\":\"SeldonDeployment\", \"metadata\":map[string]interface {}{\"clusterName\":\"\", \"namespace\":\"default\", \"deletionTimestamp\":interface {}(nil), \"creationTimestamp\":\"2018-01-09T16:42:10Z\", \"uid\":\"09e309f1-f55c-11e7-94f2-0800274e805e\", \"selfLink\":\"\", \"initializers\":interface {}(nil), \"labels\":map[string]interface {}{\"app\":\"seldon\"}, \"name\":\"seldon-deployment-example\", \"deletionGracePeriodSeconds\":(*int64)(nil)}, \"spec\":map[string]interface {}{\"annotations\":map[string]interface {}{\"deployment_version\":\"v1\", \"project_name\":\"FX Market Prediction\"}, \"name\":\"test-deployment\", \"oauth_key\":1234, \"oauth_secret\":\"oauth-secret\", \"predictors\":[]interface {}{map[string]interface {}{\"name\":\"fx-market-predictor\", \"replicas\":1, \"annotations\":map[string]interface {}{\"predictor_version\":\"v1\"}, \"componentSpec\":map[string]interface {}{\"spec\":map[string]interface {}{\"containers\":[]interface {}{map[string]interface {}{\"image\":\"seldonio/mean_classifier:0.6\", \"imagePullPolicy\":22, \"name\":\"mean-classifier\", \"resources\":map[string]interface {}{\"requests\":map[string]interface {}{\"memory\":\"1Mi\"}}}}, \"terminationGracePeriodSeconds\":20}}, \"graph\":map[string]interface {}{\"children\":[]interface {}{}, \"endpoint\":map[string]interface {}{\"type\":\"REST\"}, \"name\":\"mean-classifier\", \"type\":\"MODEL\"}}}}}: validation failure list:\r\n",
      "spec.oauth_key in body must be of type string: \"integer\"\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f resources/model_invalid1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the more complex cases, e.g. checking if the graph predictive unit names for models each have an associated container in the pod spec, we need to check inside the custom resource operator and add a FAILED status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!kubectl create -f resources/model_invalid2.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!kubectl get seldondeployments seldon-deployment-example -o jsonpath='{.status}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/model_invalid2.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Operation\n",
    "A simple example is shown below we use a single prepacked model for illustration. The spec contains a set of predictors each of which contains a ***componentSpec*** which is a Kubernetes [PodTemplateSpec](https://kubernetes.io/docs/api-reference/v1.9/#podtemplatespec-v1-core) alongside a ***graph*** which describes how components fit together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"apiVersion\": \"machinelearning.seldon.io/v1alpha1\",\r\n",
      "    \"kind\": \"SeldonDeployment\",\r\n",
      "    \"metadata\": {\r\n",
      "        \"labels\": {\r\n",
      "            \"app\": \"seldon\"\r\n",
      "        },\r\n",
      "        \"name\": \"seldon-deployment-example\"\r\n",
      "    },\r\n",
      "    \"spec\": {\r\n",
      "        \"annotations\": {\r\n",
      "            \"project_name\": \"FX Market Prediction\",\r\n",
      "            \"deployment_version\": \"v1\"\r\n",
      "        },\r\n",
      "        \"name\": \"test-deployment\",\r\n",
      "        \"oauth_key\": \"oauth-key\",\r\n",
      "        \"oauth_secret\": \"oauth-secret\",\r\n",
      "        \"predictors\": [\r\n",
      "            {\r\n",
      "                \"componentSpec\": {\r\n",
      "                    \"spec\": {\r\n",
      "                        \"containers\": [\r\n",
      "                            {\r\n",
      "                                \"image\": \"seldonio/mean_classifier:0.6\",\r\n",
      "                                \"imagePullPolicy\": \"IfNotPresent\",\r\n",
      "                                \"name\": \"mean-classifier\",\r\n",
      "                                \"resources\": {\r\n",
      "                                    \"requests\": {\r\n",
      "                                        \"memory\": \"1Mi\"\r\n",
      "                                    }\r\n",
      "                                }\r\n",
      "                            }\r\n",
      "                        ],\r\n",
      "                        \"terminationGracePeriodSeconds\": 20\r\n",
      "                    }\r\n",
      "                },\r\n",
      "                \"graph\": {\r\n",
      "                    \"children\": [],\r\n",
      "                    \"name\": \"mean-classifier\",\r\n",
      "                    \"endpoint\": {\r\n",
      "\t\t\t\"type\" : \"GRPC\"\r\n",
      "\t\t    },\r\n",
      "                    \"type\": \"MODEL\"\r\n",
      "                },\r\n",
      "                \"name\": \"fx-market-predictor\",\r\n",
      "                \"replicas\": 1,\r\n",
      "\t\t\"annotations\": {\r\n",
      "\t\t    \"predictor_version\" : \"v1\"\r\n",
      "\t\t}\r\n",
      "            }\r\n",
      "        ]\r\n",
      "    }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat resources/model.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Seldon Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the runtime graph to kubernetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment \"seldon-deployment-example\" created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f resources/model.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                        AGE\r\n",
      "seldon-deployment-example   1m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get seldondeployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         seldon-deployment-example\r\n",
      "Namespace:    default\r\n",
      "Labels:       app=seldon\r\n",
      "Annotations:  kubectl.kubernetes.io/last-applied-configuration={\"apiVersion\":\"machinelearning.seldon.io/v1alpha1\",\"kind\":\"SeldonDeployment\",\"metadata\":{\"name\":\"seldon-deployment-example\",\"namespace\":\"default\",\"self...\r\n",
      "API Version:  machinelearning.seldon.io/v1alpha1\r\n",
      "Kind:         SeldonDeployment\r\n",
      "Metadata:\r\n",
      "  Cluster Name:        \r\n",
      "  Creation Timestamp:  2018-01-10T10:18:22Z\r\n",
      "  Generation:          0\r\n",
      "  Initializers:        <nil>\r\n",
      "  Resource Version:    10347\r\n",
      "  Self Link:           /apis/machinelearning.seldon.io/v1alpha1/namespaces/default/seldondeployments/seldon-deployment-example\r\n",
      "  UID:                 9670910d-f5ef-11e7-a1a3-0800274e805e\r\n",
      "Spec:\r\n",
      "  Annotations:\r\n",
      "    Deployment _ Version:  v1\r\n",
      "    Project _ Name:        FX Market Prediction\r\n",
      "  Name:                    test-deployment\r\n",
      "  Oauth _ Key:             oauth-key\r\n",
      "  Oauth _ Secret:          oauth-secret\r\n",
      "  Predictors:\r\n",
      "    Annotations:\r\n",
      "      Predictor _ Version:  v1\r\n",
      "    Component Spec:\r\n",
      "      Metadata:\r\n",
      "        Labels:\r\n",
      "          Seldon - App:  test-deployment\r\n",
      "      Spec:\r\n",
      "        Containers:\r\n",
      "          Env:\r\n",
      "            Name:             PREDICTIVE_UNIT_SERVICE_PORT\r\n",
      "            Value:            9000\r\n",
      "            Name:             PREDICTIVE_UNIT_PARAMETERS\r\n",
      "            Value:            []\r\n",
      "          Image:              seldonio/meanclassifier:0.1_grpc\r\n",
      "          Image Pull Policy:  IfNotPresent\r\n",
      "          Lifecycle:\r\n",
      "            Pre Stop:\r\n",
      "              Exec:\r\n",
      "                Command:\r\n",
      "                  /bin/sh\r\n",
      "                  -c\r\n",
      "                  /bin/sleep 5\r\n",
      "          Liveness Probe:\r\n",
      "            Handler:\r\n",
      "              Tcp Socket:\r\n",
      "                Port:               grpc\r\n",
      "            Initial Delay Seconds:  10\r\n",
      "            Period Seconds:         5\r\n",
      "          Name:                     mean-classifier\r\n",
      "          Ports:\r\n",
      "            Container Port:  9000\r\n",
      "            Name:            grpc\r\n",
      "          Readiness Probe:\r\n",
      "            Handler:\r\n",
      "              Tcp Socket:\r\n",
      "                Port:               grpc\r\n",
      "            Initial Delay Seconds:  10\r\n",
      "            Period Seconds:         5\r\n",
      "          Resources:\r\n",
      "            Requests:\r\n",
      "              Memory:                      1Mi\r\n",
      "        Termination Grace Period Seconds:  20\r\n",
      "    Graph:\r\n",
      "      Endpoint:\r\n",
      "        Service _ Host:  0.0.0.0\r\n",
      "        Service _ Port:  9000\r\n",
      "        Type:            GRPC\r\n",
      "      Name:              mean-classifier\r\n",
      "      Type:              MODEL\r\n",
      "    Name:                fx-market-predictor\r\n",
      "    Replicas:            1\r\n",
      "Events:                  <none>\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe seldondeployments seldon-deployment-example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the status of the SeldonDeployment. **When ready the replicasAvailable should be 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map[predictorStatus:[map[name:test-deployment-fx-market-predictor replicas:1 replicasAvailable:1]]]"
     ]
    }
   ],
   "source": [
    "!kubectl get seldondeployments seldon-deployment-example -o jsonpath='{.status}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REST Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"meta\": {\n",
      "    \"puid\": \"9ciu7ike3lsus1omus1u4ef82p\",\n",
      "    \"tags\": {\n",
      "    },\n",
      "    \"routing\": {\n",
      "    }\n",
      "  },\n",
      "  \"data\": {\n",
      "    \"names\": [\"proba\"],\n",
      "    \"tensor\": {\n",
      "      \"shape\": [2, 1],\n",
      "      \"values\": [0.05133579311531625, 0.12823373759251927]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rest_request()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gRPC Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta {\n",
      "  puid: \"i5pjfu2kerin2of27ecu1m6q5\"\n",
      "}\n",
      "data {\n",
      "  names: \"proba\"\n",
      "  tensor {\n",
      "    shape: 3\n",
      "    shape: 1\n",
      "    values: 0.128233737593\n",
      "    values: 0.397314662022\n",
      "    values: 0.829676081356\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpc_request()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update deployment with canary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will change the deployment to add a \"canary\" deployment. This illustrates:\n",
    " - Updating a deployment with no downtime\n",
    " - Adding an extra predictor to run alongside th exsting predictor.\n",
    " \n",
    " You could manage different traffic levels by controlling the number of replicas of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat resources/model_with_canary.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/model_with_canary.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the status of the deployments. Note: **Might need to run several times until replicasAvailable is 1 for both predictors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!kubectl get seldondeployments seldon-deployment-example -o jsonpath='{.status}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REST Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rest_request()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gRPC request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grpc_request()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a load test which will post REST requests at 10 requests per second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "!helm install seldon-core-loadtesting --name loadtest  \\\n",
    "    --set oauth.key=oauth-key \\\n",
    "    --set oauth.secret=oauth-secret \\\n",
    "    --repo https://storage.googleapis.com/seldon-charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view an analytics dashboard inside the cluster at http://192.168.99.100:30034/dashboard/db/prediction-analytics?refresh=5s&orgId=1. Your IP address may be different. get it via minikube ip. Login with:\n",
    " - Username : admin\n",
    " - password : password (as set when starting seldon-core above)\n",
    " \n",
    " The dashboard should look like below:\n",
    " \n",
    " \n",
    " <img src=\"images/dashboard.png\" alt=\"predictor with canary\" title=\"ml graph\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tear down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!helm delete loadtest --purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment \"seldon-deployment-example\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f resources/model_with_canary.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release \"seldon-core\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!helm delete seldon-core --purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
