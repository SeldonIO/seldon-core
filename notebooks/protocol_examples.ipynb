{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Examples with Different Protocols\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    " * A kubernetes cluster with kubectl configured\n",
    " * curl\n",
    " * grpcurl\n",
    " * pygmentize\n",
    " \n",
    "## Examples\n",
    "\n",
    "  * [Seldon Protocol](#Seldon-Protocol-Model)\n",
    "  * [Tensorflow Protocol](#Tensorflow-Protocol-Model)\n",
    "  * [KFServing V2 Protocol](#KFServing-V2-Protocol-Model)\n",
    " \n",
    "\n",
    "## Setup Seldon Core\n",
    "\n",
    "Use the setup notebook to [Setup Cluster](https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html) to setup Seldon Core with an ingress - either Ambassador or Istio.\n",
    "\n",
    "Then port-forward to that ingress on localhost:8003 in a separate terminal either with:\n",
    "\n",
    " * Ambassador: `kubectl port-forward $(kubectl get pods -n seldon -l app.kubernetes.io/name=ambassador -o jsonpath='{.items[0].metadata.name}') -n seldon 8003:8080`\n",
    " * Istio: `kubectl port-forward $(kubectl get pods -l istio=ingressgateway -n istio-system -o jsonpath='{.items[0].metadata.name}') -n istio-system 8003:8080`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): namespaces \"seldon\" already exists\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"kind-ansible\" modified.\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0-dev'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VERSION=!cat ../version.txt\n",
    "VERSION=VERSION[0]\n",
    "VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seldon Protocol Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will deploy a REST model that uses the SELDON Protocol namely by specifying the attribute `protocol: seldon`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate resources/model_seldon.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: example-seldon\n",
    "spec:\n",
    "  protocol: seldon\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - image: seldonio/mock_classifier:{VERSION}\n",
    "          name: classifier\n",
    "    graph:\n",
    "      name: classifier\n",
    "      type: MODEL\n",
    "    name: model\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/example-seldon created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f resources/model_seldon.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/example-seldon condition met\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl wait --for condition=ready --timeout=300s sdep --all -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'names': ['proba'], 'ndarray': [[0.43782349911420193]]}, 'meta': {'requestPath': {'classifier': 'seldonio/mock_classifier:1.11.0-dev'}}}\n"
     ]
    }
   ],
   "source": [
    "X=!curl -s -d '{\"data\": {\"ndarray\":[[1.0, 2.0, 5.0]]}}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/example-seldon/api/v1.0/predictions \\\n",
    "   -H \"Content-Type: application/json\"\n",
    "d=json.loads(X[0])\n",
    "print(d)\n",
    "assert(d[\"data\"][\"ndarray\"][0][0] > 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meta': {'requestPath': {'classifier': 'seldonio/mock_classifier:1.11.0-dev'}}, 'data': {'names': ['proba'], 'ndarray': [[0.43782349911420193]]}}\n"
     ]
    }
   ],
   "source": [
    "X=!cd ../executor/proto && grpcurl -d '{\"data\":{\"ndarray\":[[1.0,2.0,5.0]]}}' \\\n",
    "         -rpc-header seldon:example-seldon -rpc-header namespace:seldon \\\n",
    "         -plaintext \\\n",
    "         -proto ./prediction.proto  0.0.0.0:8003 seldon.protos.Seldon/Predict\n",
    "d=json.loads(\"\".join(X))\n",
    "print(d)\n",
    "assert(d[\"data\"][\"ndarray\"][0][0] > 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"example-seldon\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f resources/model_seldon.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Protocol Model\n",
    "We will deploy a model that uses the TENSORLFOW Protocol namely by specifying the attribute `protocol: tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting resources/model_tfserving.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile resources/model_tfserving.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: example-tfserving\n",
    "spec:\n",
    "  protocol: tensorflow\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - args: \n",
    "          - --port=8500\n",
    "          - --rest_api_port=8501\n",
    "          - --model_name=halfplustwo\n",
    "          - --model_base_path=gs://seldon-models/tfserving/half_plus_two\n",
    "          image: tensorflow/serving\n",
    "          name: halfplustwo\n",
    "          ports:\n",
    "          - containerPort: 8501\n",
    "            name: http\n",
    "            protocol: TCP\n",
    "          - containerPort: 8500\n",
    "            name: grpc\n",
    "            protocol: TCP\n",
    "    graph:\n",
    "      name: halfplustwo\n",
    "      type: MODEL\n",
    "      endpoint:\n",
    "        httpPort: 8501\n",
    "        grpcPort: 8500\n",
    "    name: model\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/example-tfserving created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f resources/model_tfserving.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/example-tfserving condition met\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl wait --for condition=ready --timeout=300s sdep --all -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [2.5, 3.0, 4.5]}\n"
     ]
    }
   ],
   "source": [
    "X=!curl -s -d '{\"instances\": [1.0, 2.0, 5.0]}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/example-tfserving/v1/models/halfplustwo/:predict \\\n",
    "   -H \"Content-Type: application/json\"\n",
    "d=json.loads(\"\".join(X))\n",
    "print(d)\n",
    "assert(d[\"predictions\"][0] == 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputs': {'x': {'dtype': 'DT_FLOAT', 'tensorShape': {'dim': [{'size': '3'}]}, 'floatVal': [2.5, 3, 3.5]}}, 'modelSpec': {'name': 'halfplustwo', 'version': '123', 'signatureName': 'serving_default'}}\n"
     ]
    }
   ],
   "source": [
    "X=!cd ../executor/proto && grpcurl \\\n",
    "   -d '{\"model_spec\":{\"name\":\"halfplustwo\"},\"inputs\":{\"x\":{\"dtype\": 1, \"tensor_shape\": {\"dim\":[{\"size\": 3}]}, \"floatVal\" : [1.0, 2.0, 3.0]}}}' \\\n",
    "   -rpc-header seldon:example-tfserving -rpc-header namespace:seldon \\\n",
    "   -plaintext -proto ./prediction_service.proto \\\n",
    "   0.0.0.0:8003 tensorflow.serving.PredictionService/Predict\n",
    "d=json.loads(\"\".join(X))\n",
    "print(d)\n",
    "assert(d[\"outputs\"][\"x\"][\"floatVal\"][0] == 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"example-tfserving\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f resources/model_tfserving.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFServing V2 Protocol Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will deploy a REST model that uses the KFServing V2 Protocol namely by specifying the attribute `protocol: kfserving`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting resources/model_v2.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile resources/model_v2.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: triton\n",
    "spec:\n",
    "  protocol: kfserving\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: TRITON_SERVER\n",
    "      modelUri: gs://seldon-models/trtis/simple-model\n",
    "      name: simple\n",
    "    name: simple\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/triton created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f resources/model_v2.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/triton condition met\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl wait --for condition=ready --timeout=300s sdep --all -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'simple', 'model_version': '1', 'outputs': [{'name': 'OUTPUT0', 'datatype': 'INT32', 'shape': [1, 16], 'data': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32]}, {'name': 'OUTPUT1', 'datatype': 'INT32', 'shape': [1, 16], 'data': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}]}\n"
     ]
    }
   ],
   "source": [
    "X=!curl -s -d '{\"inputs\":[{\"name\":\"INPUT0\",\"data\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],\"datatype\":\"INT32\",\"shape\":[1,16]},{\"name\":\"INPUT1\",\"data\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],\"datatype\":\"INT32\",\"shape\":[1,16]}]}'  \\\n",
    "        -X POST http://0.0.0.0:8003/seldon/seldon/triton/v2/models/simple/infer \\\n",
    "        -H \"Content-Type: application/json\"\n",
    "d=json.loads(X[0])\n",
    "print(d)\n",
    "assert(d[\"outputs\"][0][\"data\"][0]==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{  \"modelName\": \"simple\",  \"modelVersion\": \"1\",  \"outputs\": [    {      \"name\": \"OUTPUT0\",      \"datatype\": \"INT32\",      \"shape\": [        \"1\",        \"16\"      ]    },    {      \"name\": \"OUTPUT1\",      \"datatype\": \"INT32\",      \"shape\": [        \"1\",        \"16\"      ]    }  ],  \"rawOutputContents\": [    \"AgAAAAQAAAAGAAAACAAAAAoAAAAMAAAADgAAABAAAAASAAAAFAAAABYAAAAYAAAAGgAAABwAAAAeAAAAIAAAAA==\",    \"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==\"  ]}\n"
     ]
    }
   ],
   "source": [
    "X=!cd ../executor/api/grpc/kfserving/inference && \\\n",
    "        grpcurl -d '{\"model_name\":\"simple\",\"inputs\":[{\"name\":\"INPUT0\",\"contents\":{\"int_contents\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]},\"datatype\":\"INT32\",\"shape\":[1,16]},{\"name\":\"INPUT1\",\"contents\":{\"int_contents\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]},\"datatype\":\"INT32\",\"shape\":[1,16]}]}' \\\n",
    "        -plaintext -proto ./grpc_service.proto \\\n",
    "        -rpc-header seldon:triton -rpc-header namespace:seldon \\\n",
    "        0.0.0.0:8003 inference.GRPCInferenceService/ModelInfer\n",
    "X=\"\".join(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"triton\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f resources/model_v2.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Protocol Multi-Model\n",
    "We will deploy two models that uses the TENSORLFOW Protocol namely by specifying the attribute `protocol: tensorflow`\n",
    "\n",
    " * The demo half_plus_two model\n",
    " * A ResNet32 CIFAR10 image classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting resources/model_tfserving.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile resources/model_tfserving.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: example-tfserving\n",
    "spec:\n",
    "  protocol: tensorflow\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - args: \n",
    "          - --port=8500\n",
    "          - --rest_api_port=8501\n",
    "          - --model_config_file=/mnt/models/models.config\n",
    "          image: tensorflow/serving\n",
    "          name: multi\n",
    "          ports:\n",
    "          - containerPort: 8501\n",
    "            name: http\n",
    "            protocol: TCP\n",
    "          - containerPort: 8500\n",
    "            name: grpc\n",
    "            protocol: TCP\n",
    "    graph:\n",
    "      name: multi\n",
    "      type: MODEL\n",
    "      implementation: TENSORFLOW_SERVER\n",
    "      modelUri: gs://seldon-models/tfserving/multi-model\n",
    "      endpoint:\n",
    "        httpPort: 8501\n",
    "        grpcPort: 8500\n",
    "    name: model\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/example-tfserving created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f resources/model_tfserving.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/example-tfserving condition met\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl wait --for condition=ready --timeout=300s sdep --all -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [2.5, 3.0, 4.5]}\n"
     ]
    }
   ],
   "source": [
    "X=!curl -s -d '{\"instances\": [1.0, 2.0, 5.0]}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/example-tfserving/v1/models/half_plus_two/:predict \\\n",
    "   -H \"Content-Type: application/json\"\n",
    "d=json.loads(\"\".join(X))\n",
    "print(d)\n",
    "assert(d[\"predictions\"][0] == 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputs': {'x': {'dtype': 'DT_FLOAT', 'tensorShape': {'dim': [{'size': '3'}]}, 'floatVal': [2.5, 3, 3.5]}}, 'modelSpec': {'name': 'half_plus_two', 'version': '123', 'signatureName': 'serving_default'}}\n"
     ]
    }
   ],
   "source": [
    "X=!cd ../executor/proto && grpcurl \\\n",
    "   -d '{\"model_spec\":{\"name\":\"half_plus_two\"},\"inputs\":{\"x\":{\"dtype\": 1, \"tensor_shape\": {\"dim\":[{\"size\": 3}]}, \"floatVal\" : [1.0, 2.0, 3.0]}}}' \\\n",
    "   -rpc-header seldon:example-tfserving -rpc-header namespace:seldon \\\n",
    "   -plaintext -proto ./prediction_service.proto \\\n",
    "   0.0.0.0:8003 tensorflow.serving.PredictionService/Predict\n",
    "d=json.loads(\"\".join(X))\n",
    "print(d)\n",
    "assert(d[\"outputs\"][\"x\"][\"floatVal\"][0] == 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 09:46:30.236315: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-25 09:46:30.236350: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "train, test = tf.keras.datasets.cifar10.load_data()\n",
    "X_test, y_test = test\n",
    "X_test = X_test.astype('float32') / 255\n",
    "print(X_test.shape, y_test.shape)\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: ship\n",
      "prediction: ship\n"
     ]
    }
   ],
   "source": [
    "from subprocess import run, Popen, PIPE\n",
    "import json\n",
    "import numpy as np\n",
    "idx=1\n",
    "test_example=X_test[idx:idx+1].tolist()\n",
    "payload='{\"instances\":'+f\"{test_example}\"+'}'\n",
    "cmd=f\"\"\"curl -s -d '{payload}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/example-tfserving/v1/models/cifar10/:predict \\\n",
    "   -H \"Content-Type: application/json\" \\\n",
    "\"\"\"\n",
    "ret = Popen(cmd, shell=True,stdout=PIPE)\n",
    "raw = ret.stdout.read().decode(\"utf-8\")\n",
    "res=json.loads(raw)\n",
    "arr=np.array(res[\"predictions\"][0])\n",
    "X = X_test[idx].reshape(1, 32, 32, 3)\n",
    "plt.imshow(X.reshape(32, 32, 3))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(\"class:\",class_names[y_test[idx][0]])\n",
    "print(\"prediction:\",class_names[arr.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"example-tfserving\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f resources/model_tfserving.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
