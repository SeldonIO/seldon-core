{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Model Explanations with Seldon\n",
    "Seldon core supports various out-of-the-box explainers that leverage the [Alibi ML Expalinability](https://github.com/SeldonIO/alibi) open source library.\n",
    "\n",
    "In this notebook we show how you can use the pre-packaged explainer functionality that simplifies the creation of advanced AI model explainers.\n",
    "\n",
    "Seldon provides the following out-of-the-box pre-packaged explainers:\n",
    "* Anchor Tabular Explainer \n",
    "    * AI Explainer that uses the [anchor technique](https://docs.seldon.io/projects/alibi/en/latest/methods/Anchors.html) for tabular data\n",
    "    * It basically answers the question of what are the most \"powerul\" or \"important\" features in a tabular prediction\n",
    "* Anchor Image Explainer\n",
    "    * AI Explainer that uses the [anchor technique](https://docs.seldon.io/projects/alibi/en/latest/methods/Anchors.html) for image data\n",
    "    * It basically answers the question of what are the most \"powerul\" or \"important\" pixels in an image prediction\n",
    "* Anchor Text Explainer\n",
    "    * AI Explainer that uses the [anchor technique](https://docs.seldon.io/projects/alibi/en/latest/methods/Anchors.html) for text data\n",
    "    * It basically answers the question of what are the most \"powerul\" or \"important\" tokens in a text prediction\n",
    "* Counterfactual Explainer\n",
    "    * AI Explainer that uses the [counterfactual technique](https://docs.seldon.io/projects/alibi/en/latest/methods/CF.html) for any type of data\n",
    "    * It basically provides insight of what are the minimum changes you can do to an input to change the prediction to a different class\n",
    "* Contrastive Explainer\n",
    "    * AI explainer that uses the [Contrastive Explanations](https://docs.seldon.io/projects/alibi/en/latest/methods/CEM.html) technique for any type of data\n",
    "    * It basically provides insights of what are the minimum changes you can do to an input to change the prediction to change the prediction or the minimum components of the input to make it the same prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this notebook\n",
    "\n",
    "For the [ImageNet Model](http://localhost:8888/notebooks/explainer_examples.ipynb#Imagenet-Model) you will need:\n",
    "\n",
    " - [alibi package](https://pypi.org/project/alibi/) (```pip install alibi```)\n",
    " \n",
    " This should install the required package dependencies, if not please also install:\n",
    " - [Pillow package](https://pypi.org/project/Pillow/) (```pip install Pillow```)\n",
    " - [matplotlib package](https://pypi.org/project/matplotlib/) (```pip install matplotlib```)\n",
    " - [tensorflow package](https://pypi.org/project/tensorflow/) (```pip install tensorflow```)\n",
    "\n",
    "You will also need to start Jupyter with settings to allow for large payloads, for example:\n",
    "\n",
    "```\n",
    "jupyter notebook --NotebookApp.iopub_data_rate_limit=1000000000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Seldon Core\n",
    "\n",
    "Follow the instructions to [Setup Cluster](seldon_core_setup.ipynb#Setup-Cluster) with [Ambassador Ingress](seldon_core_setup.ipynb#Ambassador) and [Install Seldon Core](seldon_core_setup.ipynb#Install-Seldon-Core).\n",
    "\n",
    " Then port-forward to that ingress on localhost:8003 in a separate terminal either with:\n",
    "\n",
    " * Ambassador: `kubectl port-forward $(kubectl get pods -n seldon -l app.kubernetes.io/name=ambassador -o jsonpath='{.items[0].metadata.name}') -n seldon 8003:8080`\n",
    " * Istio: `kubectl port-forward $(kubectl get pods -l istio=ingressgateway -n istio-system -o jsonpath='{.items[0].metadata.name}') -n istio-system 8003:80`\n",
    "\n",
    "### Create Namespace for experimentation\n",
    "\n",
    "We will first set up the namespace of Seldon where we will be deploying all our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl create namespace seldon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we will set the current workspace to use the seldon namespace so all our commands are run there by default (instead of running everything in the default namespace.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pygmentize resources/income_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/income_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=income -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/income-default-explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "import numpy as np\n",
    "sc = SeldonClient(deployment_name=\"income\",namespace=\"seldon\", gateway=\"ambassador\", gateway_endpoint=\"localhost:8003\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python client library to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array([[39, 7, 1, 1, 1, 1, 4, 1, 2174, 0, 40, 9]])\n",
    "r = sc.predict(data=data)\n",
    "print(r.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use curl to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -d '{\"data\": {\"ndarray\":[[39, 7, 1, 1, 1, 1, 4, 1, 2174, 0, 40, 9]]}}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/income/api/v1.0/predictions \\\n",
    "   -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python client library to get an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array([[39, 7, 1, 1, 1, 1, 4, 1, 2174, 0, 40, 9]])\n",
    "explanation = sc.explain(deployment_name=\"income\", predictor=\"default\", data=data)\n",
    "print(explanation.response[\"names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using curl to get an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST -H 'Content-Type: application/json' \\\n",
    "    -d '{\"data\": {\"names\": [\"text\"], \"ndarray\": [[52,  4,  0,  2,  8,  4,  2,  0,  0,  0, 60, 9]]}}' \\\n",
    "    http://localhost:8003/seldon/seldon/income-explainer/default/api/v1.0/explain | jq \".names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/income_explainer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Sentiment Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pygmentize resources/moviesentiment_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/moviesentiment_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=movie -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/movie-default-explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "import numpy as np\n",
    "sc = SeldonClient(deployment_name=\"movie\", namespace=\"seldon\", gateway_endpoint=\"localhost:8003\", payload_type='ndarray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -d '{\"data\": {\"ndarray\":[\"This film has great actors\"]}}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/movie/api/v1.0/predictions \\\n",
    "   -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array(['this film has great actors'])\n",
    "r = sc.predict(data=data)\n",
    "print(r)\n",
    "assert(r.success==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s -d '{\"data\": {\"ndarray\":[\"This movie has great actors\"]}}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/movie-explainer/default/api/v1.0/explain \\\n",
    "   -H \"Content-Type: application/json\" | jq \".names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array(['this film has great actors'])\n",
    "explanation = sc.explain(predictor=\"default\", data=data)\n",
    "print(explanation.response[\"names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/moviesentiment_explainer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pygmentize resources/imagenet_explainer_grpc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/imagenet_explainer_grpc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=image -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/image-default-explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, decode_predictions\n",
    "import alibi\n",
    "from alibi.datasets import fetch_imagenet\n",
    "import numpy as np\n",
    "\n",
    "def get_image_data():\n",
    "    data = []\n",
    "    image_shape = (299, 299, 3)\n",
    "    target_size = image_shape[:2]\n",
    "    image = Image.open(\"cat-raw.jpg\").convert('RGB')\n",
    "    image = np.expand_dims(image.resize(target_size), axis=0)\n",
    "    data.append(image)\n",
    "    data = np.concatenate(data, axis=0)\n",
    "    return data\n",
    "\n",
    "data = get_image_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "import numpy as np\n",
    "sc = SeldonClient(\n",
    "    deployment_name=\"image\",\n",
    "    namespace=\"seldon\",\n",
    "    grpc_max_send_message_length= 27 * 1024 * 1024,\n",
    "    grpc_max_receive_message_length= 27 * 1024 * 1024, \n",
    "    gateway=\"ambassador\",\n",
    "    transport=\"grpc\",\n",
    "    gateway_endpoint=\"localhost:8003\",\n",
    "    client_return_type='proto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "data = get_image_data()\n",
    "req = data[0:1]\n",
    "r = sc.predict(data=req, payload_type='tftensor')\n",
    "\n",
    "preds = tf.make_ndarray(r.response.data.tftensor)\n",
    "\n",
    "label = decode_predictions(preds, top=1)\n",
    "plt.title(label[0])\n",
    "plt.imshow(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "req = np.expand_dims(data[0], axis=0)\n",
    "r = sc.explain(data=req, predictor=\"default\", transport=\"rest\", payload_type='ndarray', client_return_type=\"dict\")\n",
    "exp_arr = np.array(r.response['anchor'])\n",
    "\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(data[0])\n",
    "axarr[1].imshow(r.response['anchor'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/imagenet_explainer_grpc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
