{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Model Explanations with Seldon\n",
    "\n",
    "Seldon core supports various out-of-the-box explainers that leverage the [Alibi ML Expalinability](https://github.com/SeldonIO/alibi) open source library.\n",
    "\n",
    "In this notebook we show how you can use the pre-packaged explainer functionality that simplifies the creation of advanced AI model explainers.\n",
    "\n",
    "Seldon provides the following out-of-the-box pre-packaged explainers:\n",
    "\n",
    " - Anchor Tabular Explainer \n",
    "    - A black box Explainer that uses the [anchor technique](https://docs.seldon.io/projects/alibi/en/latest/methods/Anchors.html) for tabular data\n",
    "    - It basically answers the question of what are the most \"powerul\" or \"important\" features in a tabular  prediction\n",
    " - Anchor Image Explainer\n",
    "    - A black box Explainer that uses the [anchor technique](https://docs.seldon.io/projects/alibi/en/latest/methods/Anchors.html) for image data\n",
    "    - It basically answers the question of what are the most \"powerul\" or \"important\" pixels in an image prediction\n",
    " - Anchor Text Explainer\n",
    "    - A black box Explainer that uses the [anchor technique](https://docs.seldon.io/projects/alibi/en/latest/methods/Anchors.html) for text data\n",
    "    - It basically answers the question of what are the most \"powerul\" or \"important\" tokens in a text  prediction\n",
    " - Kernel Shap Explainer\n",
    "    - A black box Explainer that uses the [kernel shap technique](https://docs.seldon.io/projects/alibi/en/latest/methods/Anchors.html) for tabular data\n",
    "    - It provides positive and negative feature attributions that contributed to the predictions\n",
    " - Integrated Gradient Explainer\n",
    "    - A white box explainer that uses the [Integrated Gradients technique](https://docs.seldon.io/projects/alibi/en/latest/methods/Anchors.html) for Keras models\n",
    "    - It provides importance values for each feature\n",
    " - Tree Shap Explainer\n",
    "    - A white box explainer that uses the [TreeShap technique](https://docs.seldon.io/projects/alibi/en/latest/methods/Anchors.html) for tree based models\n",
    "    - It provides positive and negative feature attributions that contributed to the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this notebook\n",
    "\n",
    " This should install the required package dependencies, if not please also install:\n",
    "\n",
    " - [matplotlib package](https://pypi.org/project/matplotlib/) (```pip install matplotlib```)\n",
    " - [tensorflow package](https://pypi.org/project/tensorflow/) (```pip install tensorflow```)\n",
    " - For Shap examples: \n",
    "     * [shap package](https://pypi.org/project/shap/) (```pip install shap```)\n",
    "     * [alibi package](https://pypi.org/project/alibi/) (```pip install alibi```)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Seldon Core\n",
    "\n",
    "Follow the instructions to [Setup Cluster](https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html#Setup-Cluster) with [Ambassador Ingress](https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html#Ambassador) and [Install Seldon Core](https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html#Install-Seldon-Core).\n",
    "\n",
    " Then port-forward to that ingress on localhost:8003 in a separate terminal either with:\n",
    "\n",
    " * Ambassador: `kubectl port-forward $(kubectl get pods -n seldon -l app.kubernetes.io/name=ambassador -o jsonpath='{.items[0].metadata.name}') -n seldon 8003:8080`\n",
    " * Istio: `kubectl port-forward $(kubectl get pods -l istio=ingressgateway -n istio-system -o jsonpath='{.items[0].metadata.name}') -n istio-system 8003:8080`\n",
    "\n",
    "### Create Namespace for experimentation\n",
    "\n",
    "We will first set up the namespace of Seldon where we will be deploying all our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl create namespace seldon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we will set the current workspace to use the seldon namespace so all our commands are run there by default (instead of running everything in the default namespace.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income Prediction Model with Anchors Explainer\n",
    "The model and explainer used here can be trained yourself following the full example in the [Alibi Anchor Explanations for Income Notebook](https://docs.seldon.io/projects/alibi/en/latest/examples/anchor_tabular_adult.html) in the Alibi project documentation.\n",
    "\n",
    "This example also shows you can specify the replicas for your explainer.\n",
    "\n",
    "Note we used a python3.7 and version 0.6.0 of Alibi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile resources/income_explainer.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: income\n",
    "spec:\n",
    "  name: income\n",
    "  annotations:\n",
    "    seldon.io/rest-timeout: \"100000\"\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: SKLEARN_SERVER\n",
    "      modelUri: gs://seldon-models/sklearn/income/model-0.23.2\n",
    "      name: classifier\n",
    "    explainer:\n",
    "      type: AnchorTabular\n",
    "      modelUri: gs://seldon-models/sklearn/income/explainer-py37-0.6.0\n",
    "      replicas: 2\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/income_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl wait --for condition=ready --timeout=300s sdep --all -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from seldon_core.seldon_client import SeldonClient\n",
    "\n",
    "sc = SeldonClient(\n",
    "    deployment_name=\"income\",\n",
    "    namespace=\"seldon\",\n",
    "    gateway=\"ambassador\",\n",
    "    gateway_endpoint=\"localhost:8003\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python client library to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array([[39, 7, 1, 1, 1, 1, 4, 1, 2174, 0, 40, 9]])\n",
    "r = sc.predict(data=data)\n",
    "print(r.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use curl to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -d '{\"data\": {\"ndarray\":[[39, 7, 1, 1, 1, 1, 4, 1, 2174, 0, 40, 9]]}}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/income/api/v1.0/predictions \\\n",
    "   -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python client library to get an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array([[39, 7, 1, 1, 1, 1, 4, 1, 2174, 0, 40, 9]])\n",
    "explanation = sc.explain(deployment_name=\"income\", predictor=\"default\", data=data)\n",
    "print(explanation.response[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using curl to get an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s -X POST -H 'Content-Type: application/json' \\\n",
    "    -d '{\"data\": {\"names\": [\"text\"], \"ndarray\": [[52,  4,  0,  2,  8,  4,  2,  0,  0,  0, 60, 9]]}}' \\\n",
    "    http://localhost:8003/seldon/seldon/income-explainer/default/api/v1.0/explain | jq \".data.anchor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/income_explainer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Sentiment Model\n",
    "\n",
    "The model used here can be trained yourself by following the full example [Anchor explanations for movie sentiment](https://docs.seldon.io/projects/alibi/en/latest/examples/anchor_text_movie.html) taken from the Alibi documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile resources/moviesentiment_explainer.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: movie\n",
    "spec:\n",
    "  name: movie\n",
    "  annotations:\n",
    "    seldon.io/rest-timeout: \"100000\"\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: SKLEARN_SERVER\n",
    "      modelUri: \"gs://seldon-models/v1.11.0-dev/sklearn/moviesentiment\"\n",
    "      name: classifier\n",
    "    explainer:\n",
    "      type: AnchorText\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/moviesentiment_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl wait --for condition=ready --timeout=300s sdep --all -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=movie -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/movie-default-explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from seldon_core.seldon_client import SeldonClient\n",
    "\n",
    "sc = SeldonClient(\n",
    "    deployment_name=\"movie\",\n",
    "    namespace=\"seldon\",\n",
    "    gateway_endpoint=\"localhost:8003\",\n",
    "    payload_type=\"ndarray\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -d '{\"data\": {\"ndarray\":[\"This film has great actors\"]}}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/movie/api/v1.0/predictions \\\n",
    "   -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array([\"this film has great actors\"])\n",
    "r = sc.predict(data=data)\n",
    "print(r)\n",
    "assert r.success == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s -d '{\"data\": {\"ndarray\":[\"a visually exquisite but narratively opaque and emotionally vapid experience of style and mystification\"]}}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/movie-explainer/default/api/v1.0/explain \\\n",
    "   -H \"Content-Type: application/json\" | jq \".data.anchor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array(\n",
    "    [\n",
    "        \"a visually exquisite but narratively opaque and emotionally vapid experience of style and mystification\"\n",
    "    ]\n",
    ")\n",
    "explanation = sc.explain(predictor=\"default\", data=data)\n",
    "print(explanation.response[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/moviesentiment_explainer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow CIFAR10 Model\n",
    "\n",
    "A full Kubeflow example with training of the model and explainer can be found in the [Kubeflow Pipelines project examples](https://github.com/kubeflow/pipelines/blob/master/samples/contrib/e2e-outlier-drift-explainer/seldon/README.md#cifar10-image-classification-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile resources/cifar10_explainer.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: cifar10-classifier\n",
    "spec:\n",
    "  protocol: tensorflow\n",
    "  annotations:\n",
    "    seldon.io/rest-timeout: \"100000\"\n",
    "  predictors:\n",
    "  - graph:\n",
    "      implementation: TENSORFLOW_SERVER\n",
    "      modelUri: gs://seldon-models/tfserving/cifar10/resnet32\n",
    "      name: cifar10-classifier\n",
    "      logger:\n",
    "         mode: all\n",
    "    explainer:\n",
    "      type: AnchorImages\n",
    "      modelUri: gs://seldon-models/tfserving/cifar10/explainer-py36-0.5.2\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/cifar10_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl wait --for condition=ready --timeout=300s sdep --all -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "url = \"https://storage.googleapis.com/seldon-models/alibi-detect/classifier/\"\n",
    "path_model = os.path.join(url, \"cifar10\", \"resnet32\", \"model.h5\")\n",
    "save_path = tf.keras.utils.get_file(\"resnet32\", path_model)\n",
    "model = tf.keras.models.load_model(save_path)\n",
    "\n",
    "train, test = tf.keras.datasets.cifar10.load_data()\n",
    "X_train, y_train = train\n",
    "X_test, y_test = test\n",
    "\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "class_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from subprocess import PIPE, Popen, run\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "idx = 12\n",
    "test_example = X_test[idx : idx + 1].tolist()\n",
    "payload = '{\"instances\":' + f\"{test_example}\" + \" }\"\n",
    "cmd = f\"\"\"curl -s -d '{payload}' \\\n",
    "   http://localhost:8003/seldon/seldon/cifar10-classifier/v1/models/cifar10-classifier/:predict \\\n",
    "   -H \"Content-Type: application/json\"\n",
    "\"\"\"\n",
    "ret = Popen(cmd, shell=True, stdout=PIPE)\n",
    "raw = ret.stdout.read().decode(\"utf-8\")\n",
    "print(raw)\n",
    "res = json.loads(raw)\n",
    "arr = np.array(res[\"predictions\"])\n",
    "X = X_test[idx].reshape(1, 32, 32, 3)\n",
    "plt.imshow(X.reshape(32, 32, 3))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(\"class:\", class_names[y_test[idx][0]])\n",
    "print(\"prediction:\", class_names[arr[0].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = X_test[idx : idx + 1].tolist()\n",
    "payload = '{\"instances\":' + f\"{test_example}\" + \" }\"\n",
    "cmd = f\"\"\"curl -s -d '{payload}' \\\n",
    "   http://localhost:8003/seldon/seldon/cifar10-classifier-explainer/default/v1/models/cifar10-classifier:explain \\\n",
    "   -H \"Content-Type: application/json\"\n",
    "\"\"\"\n",
    "ret = Popen(cmd, shell=True, stdout=PIPE)\n",
    "raw = ret.stdout.read().decode(\"utf-8\")\n",
    "explanation = json.loads(raw)\n",
    "arr = np.array(explanation[\"data\"][\"anchor\"])\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or using non-standard seldon extension\n",
    "\n",
    "test_example = X_test[idx : idx + 1].tolist()\n",
    "payload = '{\"instances\":' + f\"{test_example}\" + \" }\"\n",
    "cmd = f\"\"\"curl -s -d '{payload}' \\\n",
    "   http://localhost:8003/seldon/seldon/cifar10-classifier-explainer/default/v1/models/:explain \\\n",
    "   -H \"Content-Type: application/json\"\n",
    "\"\"\"\n",
    "ret = Popen(cmd, shell=True, stdout=PIPE)\n",
    "raw = ret.stdout.read().decode(\"utf-8\")\n",
    "explanation = json.loads(raw)\n",
    "arr = np.array(explanation[\"data\"][\"anchor\"])\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/cifar10_explainer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Prediction Model with Shap Explainer\n",
    "\n",
    "The model and explainer used here can be trained yourself following the full example in the [Kernel SHAP explanation for multinomial logistic regression models](https://docs.seldon.io/projects/alibi/en/latest/examples/kernel_shap_wine_lr.html) in the Alibi project documentation.\n",
    "\n",
    "Note we used a python3.6 and version 0.5.2 of Alibi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = load_wine()\n",
    "data = wine.data\n",
    "target = wine.target\n",
    "target_names = wine.target_names\n",
    "feature_names = wine.feature_names\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data,\n",
    "    target,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "print(\"Training records: {}\".format(X_train.shape[0]))\n",
    "print(\"Testing records: {}\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile resources/wine_explainer.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: wine\n",
    "spec:\n",
    "  annotations:\n",
    "    seldon.io/rest-timeout: \"100000\"\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: SKLEARN_SERVER\n",
    "      modelUri: gs://seldon-models/sklearn/wine/model-py36-0.23.2\n",
    "      name: classifier\n",
    "      parameters:\n",
    "        - name: method\n",
    "          type: STRING\n",
    "          value: decision_function       \n",
    "    explainer:\n",
    "      type: KernelShap\n",
    "      modelUri: gs://seldon-models/sklearn/wine/kernel_shap_py36_alibi_0.5.5\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/wine_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl wait --for condition=ready --timeout=300s sdep --all -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from seldon_core.seldon_client import SeldonClient\n",
    "\n",
    "sc = SeldonClient(\n",
    "    deployment_name=\"wine\",\n",
    "    namespace=\"seldon\",\n",
    "    gateway=\"ambassador\",\n",
    "    gateway_endpoint=\"localhost:8003\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python client library to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array(\n",
    "    [\n",
    "        [\n",
    "            -0.24226334,\n",
    "            0.26757916,\n",
    "            0.42085937,\n",
    "            0.7127641,\n",
    "            0.84067236,\n",
    "            -1.27747161,\n",
    "            -0.60582812,\n",
    "            -0.9706341,\n",
    "            -0.5873972,\n",
    "            2.42611713,\n",
    "            -2.06608025,\n",
    "            -1.55017035,\n",
    "            -0.86659858,\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "r = sc.predict(data=data)\n",
    "print(r.response)\n",
    "class_idx = np.argmax(np.array(r.response[\"data\"][\"tensor\"][\"values\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use curl to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -d '{\"data\": {\"ndarray\":[[-0.24226334,  0.26757916,  0.42085937,  0.7127641 ,  0.84067236, -1.27747161, -0.60582812, -0.9706341 , -0.5873972 ,  2.42611713, -2.06608025, -1.55017035, -0.86659858]]}}' \\\n",
    "   -X POST http://localhost:8003/seldon/seldon/wine/api/v1.0/predictions \\\n",
    "   -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python client library to get an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = np.array(\n",
    "    [\n",
    "        [\n",
    "            -0.24226334,\n",
    "            0.26757916,\n",
    "            0.42085937,\n",
    "            0.7127641,\n",
    "            0.84067236,\n",
    "            -1.27747161,\n",
    "            -0.60582812,\n",
    "            -0.9706341,\n",
    "            -0.5873972,\n",
    "            2.42611713,\n",
    "            -2.06608025,\n",
    "            -1.55017035,\n",
    "            -0.86659858,\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "explanation = sc.explain(deployment_name=\"wine\", predictor=\"default\", data=data)\n",
    "explanation = explanation.response\n",
    "expStr = json.dumps(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.api.interfaces import Explanation\n",
    "\n",
    "explanation = Explanation.from_json(expStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.shap_values = np.array(explanation.shap_values)\n",
    "explanation.raw[\"instances\"] = np.array(explanation.raw[\"instances\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "shap.force_plot(\n",
    "    explanation.expected_value[class_idx],\n",
    "    explanation.shap_values[class_idx][idx, :],\n",
    "    explanation.raw[\"instances\"][idx][None, :],\n",
    "    explanation.feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using curl to get an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s -X POST -H 'Content-Type: application/json' \\\n",
    "    -d '{\"data\": {\"names\": [\"text\"], \"ndarray\": [[-0.24226334,  0.26757916,  0.42085937,  0.7127641 ,  0.84067236, -1.27747161, -0.60582812, -0.9706341 , -0.5873972 ,  2.42611713, -2.06608025, -1.55017035, -0.86659858]]}}' \\\n",
    "    http://localhost:8003/seldon/seldon/wine-explainer/default/api/v1.0/explain | jq ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/wine_explainer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Model with Integrated Gradients Explainer\n",
    "\n",
    "The model and explainer used here can be trained yourself following the full example in the [Integrated gradients for MNIST](https://docs.seldon.io/projects/alibi/en/latest/examples/integrated_gradients_mnist.html) in the Alibi project documentation.\n",
    "\n",
    "Note we used a python3.6 and version 0.5.2 of Alibi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile resources/mnist_rest_explainer.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: tfserving\n",
    "spec:\n",
    "  name: mnist\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: TENSORFLOW_SERVER\n",
    "      modelUri: gs://seldon-models/tfserving/mnist-model\n",
    "      name: mnist-model\n",
    "      parameters:\n",
    "        - name: signature_name\n",
    "          type: STRING\n",
    "          value: predict_images\n",
    "        - name: model_name\n",
    "          type: STRING\n",
    "          value: mnist-model\n",
    "    explainer:\n",
    "      type: IntegratedGradients\n",
    "      modelUri: gs://seldon-models/keras/mnist\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/mnist_rest_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl wait --for condition=ready --timeout=300s sdep --all -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "X_train, y_train = train\n",
    "X_test, y_test = test\n",
    "test_labels = y_test.copy()\n",
    "train_labels = y_train.copy()\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype(\"float64\") / 255\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype(\"float64\") / 255\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 10\n",
    "X_test_sample = X_test[:nb_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "d = {\n",
    "    \"data\": {\"tensor\": {\"shape\": [10, 784], \"values\": X_test_sample.flatten().tolist()}}\n",
    "}\n",
    "with open(\"input.json\", \"w\") as f:\n",
    "    f.write(json.dumps(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=!curl -s -H 'Content-Type: application/json' \\\n",
    "    -d @./input.json \\\n",
    "    http://localhost:8003/seldon/seldon/tfserving/api/v1.0/predictions \n",
    "res=json.loads(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(res[\"data\"][\"tensor\"][\"values\"]).reshape(\n",
    "    res[\"data\"][\"tensor\"][\"shape\"]\n",
    ")\n",
    "predictions = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "d = {\n",
    "    \"data\": {\n",
    "        \"tensor\": {\n",
    "            \"shape\": X_test_sample.shape,\n",
    "            \"values\": X_test_sample.flatten().tolist(),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "with open(\"input.json\", \"w\") as f:\n",
    "    f.write(json.dumps(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=!curl -s -H 'Content-Type: application/json' \\\n",
    "    -d @./input.json \\\n",
    "    http://localhost:8003/seldon/seldon/tfserving-explainer/default/api/v1.0/explain\n",
    "res=json.loads(res[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = np.array(res[\"data\"][\"attributions\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(10, 7))\n",
    "image_ids = [0, 1, 9]\n",
    "cmap_bound = np.abs(attrs[[0, 1, 9]]).max()\n",
    "\n",
    "for row, image_id in enumerate(image_ids):\n",
    "    # original images\n",
    "    ax[row, 0].imshow(X_test[image_id].squeeze(), cmap=\"gray\")\n",
    "    ax[row, 0].set_title(f\"Prediction: {predictions[image_id]}\")\n",
    "\n",
    "    # attributions\n",
    "    attr = attrs[image_id]\n",
    "    im = ax[row, 1].imshow(\n",
    "        attr.squeeze(), vmin=-cmap_bound, vmax=cmap_bound, cmap=\"PiYG\"\n",
    "    )\n",
    "\n",
    "    # positive attributions\n",
    "    attr_pos = attr.clip(0, 1)\n",
    "    im_pos = ax[row, 2].imshow(\n",
    "        attr_pos.squeeze(), vmin=-cmap_bound, vmax=cmap_bound, cmap=\"PiYG\"\n",
    "    )\n",
    "\n",
    "    # negative attributions\n",
    "    attr_neg = attr.clip(-1, 0)\n",
    "    im_neg = ax[row, 3].imshow(\n",
    "        attr_neg.squeeze(), vmin=-cmap_bound, vmax=cmap_bound, cmap=\"PiYG\"\n",
    "    )\n",
    "\n",
    "ax[0, 1].set_title(\"Attributions\")\n",
    "ax[0, 2].set_title(\"Positive attributions\")\n",
    "ax[0, 3].set_title(\"Negative attributions\")\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.colorbar(im, cax=fig.add_axes([0.95, 0.25, 0.03, 0.5]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/mnist_rest_explainer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model with TreeShap Explainer\n",
    "\n",
    "The model and explainer used here can be trained yourself following the full example in the [Explaining Tree Models with Interventional Feature Perturbation Tree SHAP](https://docs.seldon.io/projects/alibi/en/latest/examples/interventional_tree_shap_adult_xgb.html) in the Alibi project documentation.\n",
    "\n",
    "Note we used a python3.6 and version 0.5.2 of Alibi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile resources/income_explainer.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: income\n",
    "spec:\n",
    "  annotations:\n",
    "    seldon.io/rest-timeout: \"100000\"\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: XGBOOST_SERVER\n",
    "      modelUri: gs://seldon-models/xgboost/adult/model_1.0.2\n",
    "      name: income-model\n",
    "    explainer:\n",
    "      type: TreeShap\n",
    "      modelUri: gs://seldon-models/xgboost/adult/tree_shap_py37_alibi_0.6.0\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/income_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl wait --for condition=ready --timeout=300s sdep --all -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from seldon_core.seldon_client import SeldonClient\n",
    "\n",
    "sc = SeldonClient(\n",
    "    deployment_name=\"income\",\n",
    "    namespace=\"seldon\",\n",
    "    gateway=\"istio\",\n",
    "    gateway_endpoint=\"localhost:8003\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python client library to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array([[52, 4, 0, 2, 8, 4, 2, 0, 0, 0, 60, 9]])\n",
    "r = sc.predict(data=data)\n",
    "print(r.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python client library to get an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.datasets import fetch_adult\n",
    "\n",
    "adult = fetch_adult()\n",
    "data = adult.data\n",
    "feature_names = adult.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "# data = np.array([[52,  4,  0,  2,  8,  4,  2,  0,  0,  0, 60,  9]])\n",
    "start = time.time()\n",
    "res = sc.explain(deployment_name=\"income\", predictor=\"default\", data=data[0:1000])\n",
    "end = time.time()\n",
    "print(\"Elapsed time:\", end - start)\n",
    "explanation = res.response\n",
    "explanationStr = json.dumps(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.api.interfaces import Explanation\n",
    "\n",
    "explanation = Explanation.from_json(explanationStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.shap_values = np.array(explanation.shap_values)\n",
    "explanation.raw[\"instances\"] = np.array(explanation.raw[\"instances\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_data(X, feature_names, category_map):\n",
    "    \"\"\"\n",
    "    Given an encoded data matrix `X` returns a matrix where the\n",
    "    categorical levels have been replaced by human readable categories.\n",
    "    \"\"\"\n",
    "\n",
    "    # expect 2D array\n",
    "    # if len(X.shape) == 1:\n",
    "    #    X = X.reshape(1, -1)\n",
    "\n",
    "    X_new = np.zeros(X.shape, dtype=object)\n",
    "    # Check if a column is categorical and replace it with values from category map\n",
    "    for idx, name in enumerate(feature_names):\n",
    "        categories = category_map.get(str(idx), None)\n",
    "        if categories:\n",
    "            for j, category in enumerate(categories):\n",
    "                encoded_vals = X[:, idx] == j\n",
    "                X_new[encoded_vals, idx] = category\n",
    "        else:\n",
    "            X_new[:, idx] = X[:, idx]\n",
    "\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_features = decode_data(\n",
    "    data, explanation.feature_names, explanation.categorical_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    explanation.expected_value,  # 0 is a class index but we have single-output model\n",
    "    explanation.shap_values[0],\n",
    "    decoded_features,\n",
    "    feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/income_explainer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental: XGBoost Model with GPU TreeShap Explainer\n",
    "\n",
    "The model and explainer used here can be trained yourself following the full example in the [Explaining Tree Models with Interventional Feature Perturbation Tree SHAP](https://docs.seldon.io/projects/alibi/en/latest/examples/interventional_tree_shap_adult_xgb.html) in the Alibi project documentation.\n",
    "\n",
    "Note we used a python 3.8.5 and Alibi master to fit the GPU based TreeShap model.\n",
    "\n",
    " * You will need a cluster with GPUs. This has been tested on GKE with NVIDIA Tesla P100 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile resources/income_gpu_explainer.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: incomegpu\n",
    "spec:\n",
    "  annotations:\n",
    "    seldon.io/rest-timeout: \"100000\"\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: XGBOOST_SERVER\n",
    "      modelUri: gs://seldon-models/xgboost/adult/model_1.0.2\n",
    "      name: income-model\n",
    "    explainer:\n",
    "      type: TreeShap\n",
    "      modelUri: gs://seldon-models/xgboost/adult/tree_shap_gpu\n",
    "      containerSpec:\n",
    "        name: explainer\n",
    "        image: seldonio/alibiexplainer-gpu:1.7.0-dev\n",
    "        resources:\n",
    "          limits:\n",
    "            nvidia.com/gpu: 1\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/income_gpu_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl wait --for condition=ready --timeout=300s sdep --all -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from seldon_core.seldon_client import SeldonClient\n",
    "\n",
    "sc = SeldonClient(\n",
    "    deployment_name=\"incomegpu\",\n",
    "    namespace=\"seldon\",\n",
    "    gateway=\"istio\",\n",
    "    gateway_endpoint=\"localhost:8003\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python client library to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array([[52, 4, 0, 2, 8, 4, 2, 0, 0, 0, 60, 9]])\n",
    "r = sc.predict(data=data)\n",
    "print(r.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python client library to get an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.datasets import fetch_adult\n",
    "\n",
    "adult = fetch_adult()\n",
    "data = adult.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "res = sc.explain(deployment_name=\"incomegpu\", predictor=\"default\", data=data[0:1000])\n",
    "end = time.time()\n",
    "print(\"Elapsed time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For running this test on P100 GPUs on GKE we see at least a 15x speed up over the CPU example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.api.interfaces import Explanation\n",
    "\n",
    "if res.success:\n",
    "    print(\"Successful explanation\")\n",
    "    explanation = res.response\n",
    "    explanationStr = json.dumps(explanation)\n",
    "    explanation = Explanation.from_json(explanationStr)\n",
    "\n",
    "    explanation.shap_values = np.array(explanation.shap_values)\n",
    "    explanation.raw[\"instances\"] = np.array(explanation.raw[\"instances\"])\n",
    "else:\n",
    "    explanation = None\n",
    "    print(\"Explanation not successful: are you running on GPU enabled cluster?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_data(X, feature_names, category_map):\n",
    "    \"\"\"\n",
    "    Given an encoded data matrix `X` returns a matrix where the\n",
    "    categorical levels have been replaced by human readable categories.\n",
    "    \"\"\"\n",
    "\n",
    "    # expect 2D array\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(1, -1)\n",
    "\n",
    "    X_new = np.zeros(X.shape, dtype=object)\n",
    "    # Check if a column is categorical and replace it with values from category map\n",
    "    for idx, name in enumerate(feature_names):\n",
    "        categories = category_map.get(str(idx), None)\n",
    "        if categories:\n",
    "            for j, category in enumerate(categories):\n",
    "                encoded_vals = X[:, idx] == j\n",
    "                X_new[encoded_vals, idx] = category\n",
    "        else:\n",
    "            X_new[:, idx] = X[:, idx]\n",
    "\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explanation is not None:\n",
    "    decoded_features = decode_data(\n",
    "        data, explanation.feature_names, explanation.categorical_names\n",
    "    )\n",
    "    shap.force_plot(\n",
    "        explanation.expected_value[\n",
    "            0\n",
    "        ],  # 0 is a class index but we have single-output model\n",
    "        explanation.shap_values[0],\n",
    "        decoded_features,\n",
    "        explanation.feature_names,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/income_gpu_explainer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triton CIFAR10 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile resources/cifar10_explainer.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: cifar10-classifier\n",
    "spec:\n",
    "  protocol: kfserving\n",
    "  annotations:\n",
    "    seldon.io/rest-timeout: \"100000\"\n",
    "  predictors:\n",
    "  - graph:\n",
    "      implementation: TRITON_SERVER\n",
    "      modelUri: gs://seldon-models/triton/tf_cifar10\n",
    "      name: cifar10\n",
    "      logger:\n",
    "         mode: all\n",
    "    explainer:\n",
    "      type: AnchorImages\n",
    "      modelUri: gs://seldon-models/tfserving/cifar10/explainer-py36-0.5.2\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/cifar10_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl wait --for condition=ready --timeout=300s sdep --all -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "url = \"https://storage.googleapis.com/seldon-models/alibi-detect/classifier/\"\n",
    "path_model = os.path.join(url, \"cifar10\", \"resnet32\", \"model.h5\")\n",
    "save_path = tf.keras.utils.get_file(\"resnet32\", path_model)\n",
    "model = tf.keras.models.load_model(save_path)\n",
    "\n",
    "train, test = tf.keras.datasets.cifar10.load_data()\n",
    "X_train, y_train = train\n",
    "X_test, y_test = test\n",
    "\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "class_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from subprocess import PIPE, Popen, run\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "idx = 12\n",
    "test_example = X_test[idx : idx + 1].tolist()\n",
    "payload = (\n",
    "    '{\"inputs\":[{\"name\":\"input_1\",\"datatype\":\"FP32\",\"shape\":[1, 32, 32, 3],\"data\":'\n",
    "    + f\"{test_example}\"\n",
    "    + \"}]}\"\n",
    ")\n",
    "cmd = f\"\"\"curl -d '{payload}' \\\n",
    "   http://localhost:8003/seldon/seldon/cifar10-classifier/v2/models/cifar10/infer \\\n",
    "   -H \"Content-Type: application/json\"\n",
    "\"\"\"\n",
    "ret = Popen(cmd, shell=True, stdout=PIPE)\n",
    "raw = ret.stdout.read().decode(\"utf-8\")\n",
    "res = json.loads(raw)\n",
    "arr = np.array(res[\"outputs\"][0][\"data\"])\n",
    "X = X_test[idx].reshape(1, 32, 32, 3)\n",
    "plt.imshow(X.reshape(32, 32, 3))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(\"class:\", class_names[y_test[idx][0]])\n",
    "print(\"prediction:\", class_names[arr.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = X_test[idx : idx + 1].tolist()\n",
    "payload = (\n",
    "    '{\"inputs\":[{\"name\":\"input_1\",\"datatype\":\"FP32\",\"shape\":[1, 32, 32, 3],\"data\":'\n",
    "    + f\"{test_example}\"\n",
    "    + \"}]}\"\n",
    ")\n",
    "cmd = f\"\"\"curl -d '{payload}' \\\n",
    "   http://localhost:8003/seldon/seldon/cifar10-classifier-explainer/default/v2/models/cifar10/explain \\\n",
    "   -H \"Content-Type: application/json\"\n",
    "\"\"\"\n",
    "ret = Popen(cmd, shell=True, stdout=PIPE)\n",
    "raw = ret.stdout.read().decode(\"utf-8\")\n",
    "explanation = json.loads(raw)\n",
    "arr = np.array(explanation[\"data\"][\"anchor\"])\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/cifar10_explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
