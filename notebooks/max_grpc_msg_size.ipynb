{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing the Maximum Message Size for gRPC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this notebook\n",
    "\n",
    "You will need to start Jupyter with settings to allow for large payloads, for example:\n",
    "\n",
    "```\n",
    "jupyter notebook --NotebookApp.iopub_data_rate_limit=1000000000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Seldon Core\n",
    "\n",
    "Use the setup notebook to [Setup Cluster](seldon_core_setup.ipynb#Setup-Cluster) with [Ambassador Ingress](seldon_core_setup.ipynb#Ambassador) and [Install Seldon Core](seldon_core_setup.ipynb#Install-Seldon-Core). Instructions [also online](./seldon_core_setup.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl create namespace seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add in our model config file the annotations `\"seldon.io/rest-timeout\":\"100000\"` and `\"seldon.io/grpc-timeout\":\"100000\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile resources/model_long_timeouts.json\n",
    "{\n",
    "    \"apiVersion\": \"machinelearning.seldon.io/v1alpha2\",\n",
    "    \"kind\": \"SeldonDeployment\",\n",
    "    \"metadata\": {\n",
    "        \"labels\": {\n",
    "            \"app\": \"seldon\"\n",
    "        },\n",
    "        \"name\": \"model-long-timeout\"\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"annotations\": {\n",
    "            \"deployment_version\": \"v1\",\n",
    "\t    \"seldon.io/rest-timeout\":\"100000\",\n",
    "\t    \"seldon.io/grpc-timeout\":\"100000\"\n",
    "        },\n",
    "        \"name\": \"long-to\",\n",
    "        \"predictors\": [\n",
    "            {\n",
    "                \"componentSpecs\": [{\n",
    "                    \"spec\": {\n",
    "                        \"containers\": [\n",
    "                            {\n",
    "                                \"image\": \"seldonio/mock_classifier_grpc:1.5\",\n",
    "                                \"imagePullPolicy\": \"IfNotPresent\",\n",
    "                                \"name\": \"classifier\",\n",
    "                                \"resources\": {\n",
    "                                    \"requests\": {\n",
    "                                        \"memory\": \"1Mi\"\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                        \"terminationGracePeriodSeconds\": 20\n",
    "                    }\n",
    "                }],\n",
    "                \"graph\": {\n",
    "                    \"children\": [],\n",
    "                    \"name\": \"classifier\",\n",
    "                    \"endpoint\": {\n",
    "\t\t\t\"type\" : \"GRPC\"\n",
    "\t\t    },\n",
    "                    \"type\": \"MODEL\"\n",
    "                },\n",
    "                \"name\": \"test\",\n",
    "                \"replicas\": 1,\n",
    "\t\t\"annotations\": {\n",
    "\t\t    \"predictor_version\" : \"v1\"\n",
    "\t\t}\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Seldon Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the runtime graph to kubernetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl apply -f resources/model_long_timeouts.json -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=model-long-timeout -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "sc = SeldonClient(deployment_name=\"model-long-timeout\",namespace=\"seldon\", \n",
    "                  grpc_max_send_message_length=50 * 1024 * 1024, grpc_max_receive_message_length=50 * 1024 * 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a small request which should suceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = sc.predict(gateway=\"ambassador\",transport=\"grpc\")\n",
    "assert(r.success==True)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a large request which will fail as the default for the model will be 4G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = sc.predict(gateway=\"ambassador\",transport=\"grpc\",shape=(1000000,1))\n",
    "print(r.success,r.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/model_long_timeouts.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allowing larger gRPC messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we change our SeldonDeployment to include a annotation for max grpx message size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile resources/model_grpc_size.json\n",
    "{\n",
    "    \"apiVersion\": \"machinelearning.seldon.io/v1alpha2\",\n",
    "    \"kind\": \"SeldonDeployment\",\n",
    "    \"metadata\": {\n",
    "        \"labels\": {\n",
    "            \"app\": \"seldon\"\n",
    "        },\n",
    "        \"name\": \"seldon-model\"\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"annotations\": {\n",
    "\t    \"seldon.io/grpc-max-message-size\":\"10000000\",\n",
    "\t    \"seldon.io/rest-timeout\":\"100000\",\n",
    "\t    \"seldon.io/grpc-timeout\":\"100000\"\n",
    "        },\n",
    "        \"name\": \"test-deployment\",\n",
    "        \"predictors\": [\n",
    "            {\n",
    "                \"componentSpecs\": [{\n",
    "                    \"spec\": {\n",
    "                        \"containers\": [\n",
    "                            {\n",
    "                                \"image\": \"seldonio/mock_classifier_grpc:1.5\",\n",
    "                                \"imagePullPolicy\": \"IfNotPresent\",\n",
    "                                \"name\": \"classifier\",\n",
    "                                \"resources\": {\n",
    "                                    \"requests\": {\n",
    "                                        \"memory\": \"1Mi\"\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                        \"terminationGracePeriodSeconds\": 20\n",
    "                    }\n",
    "                }],\n",
    "                \"graph\": {\n",
    "                    \"children\": [],\n",
    "                    \"name\": \"classifier\",\n",
    "                    \"endpoint\": {\n",
    "\t\t\t\"type\" : \"GRPC\"\n",
    "\t\t    },\n",
    "                    \"type\": \"MODEL\"\n",
    "                },\n",
    "                \"name\": \"grpc-size\",\n",
    "                \"replicas\": 1,\n",
    "\t\t\"annotations\": {\n",
    "\t\t    \"predictor_version\" : \"v1\"\n",
    "\t\t}\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl create -f resources/model_grpc_size.json -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=seldon-model -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request via ambassador. This should succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc = SeldonClient(deployment_name=\"seldon-model\",namespace=\"seldon\",\n",
    "                  grpc_max_send_message_length=50 * 1024 * 1024, grpc_max_receive_message_length=50 * 1024 * 1024)\n",
    "r = sc.predict(gateway=\"ambassador\",transport=\"grpc\",shape=(1000000,1))\n",
    "assert(r.success==True)\n",
    "print(r.success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl delete -f resources/model_grpc_size.json -n seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
