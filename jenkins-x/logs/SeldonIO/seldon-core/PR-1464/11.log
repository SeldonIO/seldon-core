
Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mpr-build-comment[0m and container [32mstep-credential-initializer-k2tl2[0m
{"level":"warn","ts":1582556190.9182444,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: \"ref: refs/heads/0.8.0-**-support-backwards-incompats\" is not a valid GitHub commit ID"}
{"level":"info","ts":1582556190.9194922,"logger":"fallback-logger","caller":"creds-init/main.go:40","msg":"Credentials initialized."}

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mpr-build-comment[0m and container [32mstep-working-dir-initializer-rd2bm[0m
{"level":"warn","ts":1582556191.534399,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1582556191.5359833,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c mkdir -p /workspace/source\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mpr-build-comment[0m and container [32mstep-place-tools[0m

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mpr-build-comment[0m and container [32mstep-create-dir-workspace-jmgzh[0m
{"level":"warn","ts":1582556197.5651379,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1582556197.5665443,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c mkdir -p source\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mpr-build-comment[0m and container [32mstep-git-source-seldonio-seldon-core-pr-1464-in-2zxb7[0m
{"level":"warn","ts":1582556197.7633567,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: \"ref: refs/heads/0.8.0-**-support-backwards-incompats\" is not a valid GitHub commit ID"}
{"level":"info","ts":1582556200.42844,"logger":"fallback-logger","caller":"git/git.go:103","msg":"Successfully cloned https://github.com/SeldonIO/seldon-core.git @ master in path /workspace/source"}

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mpr-build-comment[0m and container [32mstep-git-merge[0m
Using SHAs from PULL_REFS=master:a3509cc99e1efffeda510a078b1d8def272db62a,1464:9df5b49d6cbee78da315c36e6f49b6135fab71b5
DEBUG: ran git fetch --unshallow origin 9df5b49d6cbee78da315c36e6f49b6135fab71b5: a3509cc99e1efffeda510a078b1d8def272db62a: in 
DEBUG: ran git checkout master in 
DEBUG: ran git reset --hard a3509cc99e1efffeda510a078b1d8def272db62a in 
DEBUG: ran clean --force -d . in 
DEBUG: ran git merge 9df5b49d6cbee78da315c36e6f49b6135fab71b5 in 
Merged SHA 361748aa049199d596797fd7a44c79f7847f2338 with commit message 'Merge commit '9df5b49d6cbee78da315c36e6f49b6135fab71b5'' into base branch master
Merged SHA 9df5b49d6cbee78da315c36e6f49b6135fab71b5 with commit message 'Increase waiting time' into base branch master
Merged SHA 0b6eecefe9f3645cb6f27ad5e3a6d122e59fcf8a with commit message 'Ensure spans are sorted before assertions' into base branch master
Merged SHA 2429329821b5183a8945bf555c0b7464f3eaf08a with commit message 'Add some comments on how we fetch traces' into base branch master
Merged SHA 0b7b9db881de68617826665a3f5d20350f06f5e5 with commit message 'Fix spanID' into base branch master
Merged SHA 2b3c0f4ff6102dbab5a21a0404c596eafc468d56 with commit message 'Use tenacity instead of retrying (which is no longer maintained)' into base branch master
Merged SHA c75fae7f2172a06b0a68d978e4c210ca90f19949 with commit message 'Add retry if traces are empty' into base branch master
Merged SHA 4f8c0567d1cd139f224a6533d2515f98a21dcc9f with commit message 'Assert traces by operation order (and referencing)' into base branch master
Merged SHA 5d68f211e73f807b09c04bdff166a8053a49c922 with commit message 'Add method to get pod names in a deployment' into base branch master
Merged SHA 9537cedc7604edea1286683fbd95933053c5949c with commit message 'Filter traces by pod name' into base branch master
Merged SHA 946d5400a14e63a68c975cd3364e66b70d6cb262 with commit message 'Get traces through internal REST API' into base branch master
Merged SHA 5d333e7145c9f2302245d3d9119284b68094f947 with commit message 'Fix mapping' into base branch master
Merged SHA 3ace75fed36103ff811acf906683d37bc1f44d30 with commit message 'Fix setup' into base branch master
Merged SHA f4161298eeaef3f2a020d033ec16ac71d7bd8ecc with commit message 'Update install_jaeger for Helm 3.x' into base branch master
Merged SHA 031d654da9aa1ae4b5c038b38794b780a3b1af5a with commit message 'Remove port since Jaeger is exposed through ambassador' into base branch master
Merged SHA 4fb079c52d8201d4e57b3ec3e48392757670faca with commit message 'Tweak config of jaeger' into base branch master
Merged SHA 2589098c156c80ef565c099ce375e9b890b9404a with commit message 'Add Jaeger config' into base branch master
Merged SHA a9030f1542d099bbb106b77440a03640cd6dc22c with commit message 'Move configs to /resources' into base branch master
Merged SHA 06695d81f825cf828d712ccea5fda0f2b0b2edc2 with commit message 'Add target to install Jaeger and open port in Kind cluster' into base branch master

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mpr-build-comment[0m and container [32mstep-step2[0m
+++ dirname ./add-pr-build-comment
++ cd .
++ pwd
+ STARTUP_DIR=/workspace/source/ci
+ REPO_OWNER=SeldonIO
+ REPO_NAME=seldon-core
+ PULL_NUMBER=1464
+ BUILD_NUMBER=11
+ PIPELINE_CONTEXT=integration
++ cat
+++ date
+ COMMENT_MSG='Mon Feb 24 14:56:47 UTC 2020
The logs for [integration] [11] will show after the pipeline context has finished.  
https://github.com/SeldonIO/seldon-core/blob/gh-pages/jenkins-x/logs/SeldonIO/seldon-core/PR-1464/11.log

impatient try  
** get build logs SeldonIO/seldon-core/PR-1464 --build=11'
+ ** step pr comment --owner=SeldonIO --repository=seldon-core --pull-request=1464 '--comment=Mon Feb 24 14:56:47 UTC 2020
The logs for [integration] [11] will show after the pipeline context has finished.  
https://github.com/SeldonIO/seldon-core/blob/gh-pages/jenkins-x/logs/SeldonIO/seldon-core/PR-1464/11.log

impatient try  
** get build logs SeldonIO/seldon-core/PR-1464 --build=11'

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mpr-build-comment[0m and container [32mstep-source-mkdir-seldonio-seldon-core-pr-1464-in-8dfsf[0m
{"level":"warn","ts":1582556213.4711728,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1582556213.4749453,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c mkdir -p /pvc/pr-build-comment/workspace\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mpr-build-comment[0m and container [32mstep-source-copy-seldonio-seldon-core-pr-1464-in-9xd4z[0m
{"level":"warn","ts":1582556213.6901968,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1582556214.07794,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c cp -r source/. /pvc/pr-build-comment/workspace\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mend-to-end[0m and container [32mstep-credential-initializer-kj654[0m
{"level":"warn","ts":1582556218.3758552,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: \"ref: refs/heads/0.8.0-**-support-backwards-incompats\" is not a valid GitHub commit ID"}
{"level":"info","ts":1582556218.3765783,"logger":"fallback-logger","caller":"creds-init/main.go:40","msg":"Credentials initialized."}

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mend-to-end[0m and container [32mstep-working-dir-initializer-hvcqh[0m
{"level":"warn","ts":1582556219.3523166,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1582556219.3539147,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c mkdir -p /workspace/source\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mend-to-end[0m and container [32mstep-place-tools[0m

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mend-to-end[0m and container [32mstep-create-dir-workspace-599vv[0m
{"level":"warn","ts":1582556225.4326253,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1582556225.4341125,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c mkdir -p /workspace/source\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mend-to-end[0m and container [32mstep-source-copy-workspace-6cqlf[0m
{"level":"warn","ts":1582556225.6479163,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1582556227.4561353,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c cp -r /pvc/pr-build-comment/workspace/. /workspace/source\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1464-in-5vmfj-11[0m stage [32mend-to-end[0m and container [32mstep-test-end-to-end[0m
Starting Docker: docker.
[SETUP] Waiting for Docker to be ready, sleeping for 1 seconds ...
kind create cluster --config ../resources/kind_config.yaml
Creating cluster "kind" ...
 â€¢ Ensuring node image (kindest/node:v1.16.3) ðŸ–¼  ...
 âœ“ Ensuring node image (kindest/node:v1.16.3) ðŸ–¼
 â€¢ Preparing nodes ðŸ“¦  ...
 âœ“ Preparing nodes ðŸ“¦
 â€¢ Writing configuration ðŸ“œ  ...
 âœ“ Writing configuration ðŸ“œ
 â€¢ Starting control-plane ðŸ•¹ï¸  ...
 âœ“ Starting control-plane ðŸ•¹ï¸
 â€¢ Installing CNI ðŸ”Œ  ...
 âœ“ Installing CNI ðŸ”Œ
 â€¢ Installing StorageClass ðŸ’¾  ...
 âœ“ Installing StorageClass ðŸ’¾
 â€¢ Joining worker nodes ðŸšœ  ...
 âœ“ Joining worker nodes ðŸšœ
Set kubectl context to "kind-kind"
You can now use your cluster with:

kubectl cluster-info --context kind-kind

Not sure what to do next? ðŸ˜… Check out https://kind.sigs.k8s.io/docs/user/quick-start/
`kind get kubeconfig-path` is deprecated!

KIND will export and merge kubeconfig like kops, minikube, etc.
This command is now unnecessary and will be removed in a future release.

For more info see: https://github.com/kubernetes-sigs/kind/issues/1060
See also the output of `kind create cluster`

Files changed in python folder:
SKIPPING PYTHON IMAGE BUILD...
Files changed in operator folder:
SKIPPING OPERATOR IMAGE BUILD...
Files changed in engine folder:
SKIPPING ENGINE IMAGE BUILD...
Files changed in executor folder:
SKIPPING EXECUTOR IMAGE BUILD...
Build fixed models
cd ../docker/fixed-model && make kind_load_images
make[1]: Entering directory '/workspace/source/testing/docker/fixed-model'
s2i build -E environment_rest_v1 . seldonio/seldon-core-s2i-python3:0.15 seldonio/fixed-model:0.1
---> Installing application source...
Build completed successfully
s2i build -E environment_rest_v2 . seldonio/seldon-core-s2i-python3:0.15 seldonio/fixed-model:0.2
---> Installing application source...
Build completed successfully
kind load -v 3 docker-image seldonio/fixed-model:0.1
Image: "seldonio/fixed-model:0.1" with ID "sha256:5486653f8190a67e6823f3bf6f191db4f6c8f143302f75706ee2187a5399bfaa" not present on node "kind-control-plane"
Image: "seldonio/fixed-model:0.1" with ID "sha256:5486653f8190a67e6823f3bf6f191db4f6c8f143302f75706ee2187a5399bfaa" not present on node "kind-worker"
kind load -v 3 docker-image seldonio/fixed-model:0.2
Image: "seldonio/fixed-model:0.2" with ID "sha256:a37eab406f7bd2efc7ff3084a162fe1d3c1104721eaf39eda52afafb628405a8" not present on node "kind-control-plane"
Image: "seldonio/fixed-model:0.2" with ID "sha256:a37eab406f7bd2efc7ff3084a162fe1d3c1104721eaf39eda52afafb628405a8" not present on node "kind-worker"
make[1]: Leaving directory '/workspace/source/testing/docker/fixed-model'
kubectl create namespace seldon || echo "Namespace seldon already exists"
namespace/seldon created
kubectl create namespace test1 || echo "Namespace test1 already exists"
namespace/test1 created
helm repo add stable https://kubernetes-charts.storage.googleapis.com/
"stable" has been added to your repositories
helm repo add seldonio https://storage.googleapis.com/seldon-charts
"seldonio" has been added to your repositories
helm repo add jaegertracing https://jaegertracing.github.io/helm-charts
"jaegertracing" has been added to your repositories
helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "jaegertracing" chart repository
...Successfully got an update from the "seldonio" chart repository
...Successfully got an update from the "stable" chart repository
Update Complete. âŽˆ Happy Helming!âŽˆ 
helm install ambassador \
	stable/ambassador \
	-f ../resources/ambassador_values.yaml \
	--set crds.keep=false \
	--namespace seldon \
	--set replicaCount=1 \
	--wait
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
NAME: ambassador
LAST DEPLOYED: Mon Feb 24 15:02:03 2020
NAMESPACE: seldon
STATUS: deployed
REVISION: 1
NOTES:
Congratulations! You've successfully installed Ambassador.

For help, visit our Slack at https://d6e.co/slack or view the documentation online at https://www.getambassador.io.

To get the IP address of Ambassador, run the following commands:
  export NODE_PORT=$(kubectl get --namespace seldon -o jsonpath="{.spec.ports[0].nodePort}" services ambassador)
  export NODE_IP=$(kubectl get nodes --namespace seldon -o jsonpath="{.items[0].status.addresses[0].address}")
  echo http://$NODE_IP:$NODE_PORT
kubectl apply -f istio-1.4.2.yaml
clusterrole.rbac.authorization.k8s.io/istio-reader-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/istio-reader-istio-system created
customresourcedefinition.apiextensions.k8s.io/attributemanifests.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/clusterrbacconfigs.rbac.istio.io created
customresourcedefinition.apiextensions.k8s.io/destinationrules.networking.istio.io created
customresourcedefinition.apiextensions.k8s.io/envoyfilters.networking.istio.io created
customresourcedefinition.apiextensions.k8s.io/gateways.networking.istio.io created
customresourcedefinition.apiextensions.k8s.io/httpapispecbindings.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/httpapispecs.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/meshpolicies.authentication.istio.io created
customresourcedefinition.apiextensions.k8s.io/policies.authentication.istio.io created
customresourcedefinition.apiextensions.k8s.io/quotaspecbindings.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/quotaspecs.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/rbacconfigs.rbac.istio.io created
customresourcedefinition.apiextensions.k8s.io/rules.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/serviceentries.networking.istio.io created
customresourcedefinition.apiextensions.k8s.io/servicerolebindings.rbac.istio.io created
customresourcedefinition.apiextensions.k8s.io/serviceroles.rbac.istio.io created
customresourcedefinition.apiextensions.k8s.io/virtualservices.networking.istio.io created
customresourcedefinition.apiextensions.k8s.io/adapters.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/instances.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/templates.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/handlers.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/sidecars.networking.istio.io created
customresourcedefinition.apiextensions.k8s.io/authorizationpolicies.security.istio.io created
namespace/istio-system created
serviceaccount/istio-reader-service-account created
clusterrole.rbac.authorization.k8s.io/istio-citadel-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/istio-citadel-istio-system created
deployment.apps/istio-citadel created
poddisruptionbudget.policy/istio-citadel created
service/istio-citadel created
serviceaccount/istio-citadel-service-account created
deployment.apps/istio-egressgateway created
poddisruptionbudget.policy/istio-egressgateway created
gateway.networking.istio.io/istio-multicluster-egressgateway created
virtualservice.networking.istio.io/istio-multicluster-egressgateway created
envoyfilter.networking.istio.io/istio-multicluster-egressgateway created
destinationrule.networking.istio.io/istio-multicluster-destinationrule created
service/istio-egressgateway created
role.rbac.authorization.k8s.io/istio-egressgateway-sds created
rolebinding.rbac.authorization.k8s.io/istio-egressgateway-sds created
serviceaccount/istio-egressgateway-service-account created
clusterrole.rbac.authorization.k8s.io/istio-galley-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/istio-galley-*****-role-binding-istio-system created
configmap/istio-mesh-galley created
configmap/istio-galley-configuration created
deployment.apps/istio-galley created
poddisruptionbudget.policy/istio-galley created
service/istio-galley created
serviceaccount/istio-galley-service-account created
configmap/istio-grafana-configuration-dashboards-citadel-dashboard created
configmap/istio-grafana-configuration-dashboards-galley-dashboard created
configmap/istio-grafana-configuration-dashboards-istio-mesh-dashboard created
configmap/istio-grafana-configuration-dashboards-istio-performance-dashboard created
configmap/istio-grafana-configuration-dashboards-istio-service-dashboard created
configmap/istio-grafana-configuration-dashboards-istio-workload-dashboard created
configmap/istio-grafana-configuration-dashboards-mixer-dashboard created
configmap/istio-grafana-configuration-dashboards-pilot-dashboard created
configmap/istio-grafana created
deployment.apps/grafana created
policy.authentication.istio.io/grafana-ports-mtls-disabled created
service/grafana created
deployment.apps/istio-ingressgateway created
gateway.networking.istio.io/ingressgateway created
poddisruptionbudget.policy/ingressgateway created
service/istio-ingressgateway created
serviceaccount/istio-ingressgateway-service-account created
sidecar.networking.istio.io/default created
clusterrole.rbac.authorization.k8s.io/istio-sidecar-injector-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/istio-sidecar-injector-*****-role-binding-istio-system created
configmap/injector-mesh created
deployment.apps/istio-sidecar-injector created
mutatingwebhookconfiguration.admissionregistration.k8s.io/istio-sidecar-injector created
poddisruptionbudget.policy/istio-sidecar-injector created
service/istio-sidecar-injector created
serviceaccount/istio-sidecar-injector-service-account created
configmap/istio-sidecar-injector created
clusterrole.rbac.authorization.k8s.io/kiali created
clusterrole.rbac.authorization.k8s.io/kiali-viewer created
clusterrolebinding.rbac.authorization.k8s.io/kiali created
configmap/kiali created
secret/kiali created
deployment.apps/kiali created
service/kiali created
serviceaccount/kiali-service-account created
clusterrole.rbac.authorization.k8s.io/istio-pilot-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/istio-pilot-istio-system created
configmap/pilot-envoy-config created
configmap/istio created
deployment.apps/istio-pilot created
meshpolicy.authentication.istio.io/default created
poddisruptionbudget.policy/istio-pilot created
service/istio-pilot created
serviceaccount/istio-pilot-service-account created
clusterrole.rbac.authorization.k8s.io/istio-policy created
clusterrolebinding.rbac.authorization.k8s.io/istio-policy-*****-role-binding-istio-system created
destinationrule.networking.istio.io/istio-policy created
deployment.apps/istio-policy created
poddisruptionbudget.policy/istio-policy created
service/istio-policy created
serviceaccount/istio-policy-service-account created
clusterrole.rbac.authorization.k8s.io/prometheus-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/prometheus-istio-system created
configmap/prometheus created
deployment.apps/prometheus created
service/prometheus created
serviceaccount/prometheus created
horizontalpodautoscaler.autoscaling/istio-telemetry created
clusterrole.rbac.authorization.k8s.io/istio-mixer-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/istio-mixer-*****-role-binding-istio-system created
attributemanifest.config.istio.io/istioproxy created
attributemanifest.config.istio.io/kubernetes created
handler.config.istio.io/stdio created
instance.config.istio.io/accesslog created
instance.config.istio.io/tcpaccesslog created
rule.config.istio.io/stdio created
rule.config.istio.io/stdiotcp created
instance.config.istio.io/requestcount created
instance.config.istio.io/requestduration created
instance.config.istio.io/requestsize created
instance.config.istio.io/responsesize created
instance.config.istio.io/tcpbytesent created
instance.config.istio.io/tcpbytereceived created
instance.config.istio.io/tcpconnectionsopened created
instance.config.istio.io/tcpconnectionsclosed created
handler.config.istio.io/prometheus created
rule.config.istio.io/promhttp created
rule.config.istio.io/promtcp created
rule.config.istio.io/promtcpconnectionopen created
rule.config.istio.io/promtcpconnectionclosed created
handler.config.istio.io/kubernetesenv created
rule.config.istio.io/kubeattrgenrulerule created
rule.config.istio.io/tcpkubeattrgenrulerule created
instance.config.istio.io/attributes created
destinationrule.networking.istio.io/istio-telemetry created
configmap/telemetry-envoy-config created
deployment.apps/istio-telemetry created
poddisruptionbudget.policy/istio-telemetry created
service/istio-telemetry created
serviceaccount/istio-mixer-service-account created
deployment.apps/istio-tracing created
service/jaeger-query created
service/jaeger-collector created
service/jaeger-agent created
service/zipkin created
service/tracing created
kubectl rollout status deployment.apps/istio-ingressgateway -n istio-system
Waiting for deployment "istio-ingressgateway" rollout to finish: 0 of 1 updated replicas are available...
deployment "istio-ingressgateway" successfully rolled out
kubectl rollout status deployment.apps/istio-pilot -n istio-system
deployment "istio-pilot" successfully rolled out
kubectl rollout status deployment.apps/istio-citadel -n istio-system
deployment "istio-citadel" successfully rolled out
helm install jaeger-operator \
	jaegertracing/jaeger-operator \
	--set rbac.clusterRole=true \
	--namespace seldon \
	--wait
manifest_sorter.go:175: info: skipping unknown hook: "crd-install"
NAME: jaeger-operator
LAST DEPLOYED: Mon Feb 24 15:05:04 2020
NAMESPACE: seldon
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
jaeger-operator is installed.


Check the jaeger-operator logs
  export POD=$(kubectl get pods-l app.kubernetes.io/instance=jaeger-operator -lapp.kubernetes.io/name=jaeger-operator --namespace seldon --output name)
  kubectl logs $POD --namespace=seldon
kubectl apply -f ../resources/jaeger.yaml --namespace seldon
jaeger.jaegertracing.io/jaeger created
mapping.getambassador.io/jaeger created
cd ../../operator && make install-cert-manager
make[1]: Entering directory '/workspace/source/operator'
kubectl create namespace cert-manager || echo "Namespace cert-manager-exists"
namespace/cert-manager created
kubectl label namespace cert-manager cert-manager.io/disable-validation=true || echo "namespace cert-manager-already labelled"
namespace/cert-manager labeled
kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.12.0/cert-manager.yaml
customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/challenges.acme.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/clusterissuers.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/issuers.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/orders.acme.cert-manager.io created
Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply
namespace/cert-manager configured
serviceaccount/cert-manager-cainjector created
serviceaccount/cert-manager created
serviceaccount/cert-manager-webhook created
clusterrole.rbac.authorization.k8s.io/cert-manager-cainjector created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-cainjector created
role.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection created
rolebinding.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-webhook:auth-delegator created
rolebinding.rbac.authorization.k8s.io/cert-manager-webhook:webhook-authentication-reader created
clusterrole.rbac.authorization.k8s.io/cert-manager-webhook:webhook-requester created
role.rbac.authorization.k8s.io/cert-manager:leaderelection created
rolebinding.rbac.authorization.k8s.io/cert-manager:leaderelection created
clusterrole.rbac.authorization.k8s.io/cert-manager-controller-issuers created
clusterrole.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers created
clusterrole.rbac.authorization.k8s.io/cert-manager-controller-certificates created
clusterrole.rbac.authorization.k8s.io/cert-manager-controller-orders created
clusterrole.rbac.authorization.k8s.io/cert-manager-controller-challenges created
clusterrole.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-issuers created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-certificates created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-orders created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-challenges created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim created
clusterrole.rbac.authorization.k8s.io/cert-manager-view created
clusterrole.rbac.authorization.k8s.io/cert-manager-edit created
service/cert-manager created
service/cert-manager-webhook created
deployment.apps/cert-manager-cainjector created
deployment.apps/cert-manager created
deployment.apps/cert-manager-webhook created
mutatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created
validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created
kubectl rollout status deployment.apps/cert-manager -n cert-manager
Waiting for deployment "cert-manager" rollout to finish: 0 of 1 updated replicas are available...
deployment "cert-manager" successfully rolled out
kubectl rollout status deployment.apps/cert-manager-cainjector -n cert-manager
deployment "cert-manager-cainjector" successfully rolled out
kubectl rollout status deployment.apps/cert-manager-webhook -n cert-manager
Waiting for deployment "cert-manager-webhook" rollout to finish: 0 of 1 updated replicas are available...
deployment "cert-manager-webhook" successfully rolled out
make[1]: Leaving directory '/workspace/source/operator'
sleep 5 #https://github.com/jetstack/cert-manager/issues/2273
kubectl create namespace seldon-system || echo "namespace seldon-system exists"
namespace/seldon-system created
helm install seldon \
	../../helm-charts/seldon-core-operator \
	--namespace seldon-system \
	--set istio.enabled=true \
	--set istio.gateway=seldon-gateway \
	--set certManager.enabled=false \
	--set executor.enabled=true \
	--wait
NAME: seldon
LAST DEPLOYED: Mon Feb 24 15:05:59 2020
NAMESPACE: seldon-system
STATUS: deployed
REVISION: 1
TEST SUITE: None
kubectl config set-context $(kubectl config current-context) --namespace=seldon
Context "kind-kind" modified.
make: Entering directory '/workspace/source/python'
pip install -e . -r requirements-dev.txt
Obtaining file:///workspace/source/python
Collecting Flask<2.0.0
  Downloading Flask-1.1.1-py2.py3-none-any.whl (94 kB)
Collecting Flask-cors<4.0.0
  Downloading Flask_Cors-3.0.8-py2.py3-none-any.whl (14 kB)
Collecting redis<4.0.0
  Downloading redis-3.4.1-py2.py3-none-any.whl (71 kB)
Collecting requests<3.0.0
  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)
Collecting numpy<2.0.0
  Downloading numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)
Collecting flatbuffers<2.0.0
  Downloading flatbuffers-1.11-py2.py3-none-any.whl (15 kB)
Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (3.11.3)
Requirement already satisfied: grpcio<2.0.0 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (1.26.0)
Collecting Flask-OpenTracing<1.2.0,>=1.1.0
  Downloading Flask-OpenTracing-1.1.0.tar.gz (8.2 kB)
Collecting opentracing<2.3.0,>=2.2.0
  Downloading opentracing-2.2.0.tar.gz (47 kB)
Collecting jaeger-client<4.2.0,>=4.1.0
  Downloading jaeger-client-4.1.0.tar.gz (80 kB)
Collecting grpcio-opentracing<1.2.0,>=1.1.4
  Downloading grpcio_opentracing-1.1.4-py3-none-any.whl (14 kB)
Collecting pyaml<20.0.0
  Downloading pyaml-19.12.0-py2.py3-none-any.whl (17 kB)
Collecting gunicorn<20.1.0,>=19.9.0
  Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)
Collecting minio<6.0.0,>=4.0.9
  Downloading minio-5.0.7-py2.py3-none-any.whl (71 kB)
Collecting azure-storage-blob<3.0.0,>=2.0.1
  Downloading azure_storage_blob-2.1.0-py2.py3-none-any.whl (88 kB)
Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 17)) (45.1.0)
Collecting google-cloud-storage>=1.16.0
  Downloading google_cloud_storage-1.26.0-py2.py3-none-any.whl (75 kB)
Collecting black==19.10b0
  Downloading black-19.10b0-py36-none-any.whl (97 kB)
Collecting flake8==3.7.9
  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)
Collecting mypy<0.762
  Downloading mypy-0.761-cp36-cp36m-manylinux1_x86_64.whl (24.1 MB)
Collecting Pillow==7.0.0
  Downloading Pillow-7.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)
Collecting pytest==5.3.1
  Downloading pytest-5.3.1-py3-none-any.whl (233 kB)
Collecting pytest-cov==2.8.1
  Downloading pytest_cov-2.8.1-py2.py3-none-any.whl (18 kB)
Collecting tox<4.0.0
  Downloading tox-3.14.5-py2.py3-none-any.whl (81 kB)
Collecting coverage==4.5.4
  Downloading coverage-4.5.4-cp36-cp36m-manylinux1_x86_64.whl (205 kB)
ERROR: Could not find a version that satisfies the requirement pandas==1.0.1 (from -r requirements-dev.txt (line 14)) (from versions: 0.1, 0.2b0, 0.2b1, 0.2, 0.3.0b0, 0.3.0b2, 0.3.0, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.5.0, 0.6.0, 0.6.1, 0.7.0rc1, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.8.0rc1, 0.8.0rc2, 0.8.0, 0.8.1, 0.9.0, 0.9.1, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0rc1, 0.19.0, 0.19.1, 0.19.2, 0.20.0rc1, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.21.0rc1, 0.21.0, 0.21.1, 0.22.0, 0.23.0rc2, 0.23.0, 0.23.1, 0.23.2, 0.23.3, 0.23.4, 0.24.0rc1, 0.24.0, 0.24.1, 0.24.2, 0.25.0rc0, 0.25.0, 0.25.1, 0.25.2, 0.25.3)
ERROR: No matching distribution found for pandas==1.0.1 (from -r requirements-dev.txt (line 14))
make: *** [Makefile:54: install_dev] Error 1
make: Leaving directory '/workspace/source/python'
cp ../../proto/prediction.proto ./proto
cd ../../proto/tensorflow && make create_protos
make[1]: Entering directory '/workspace/source/proto/tensorflow'
./create-protos.sh
Downloading proto files for master
make[1]: Leaving directory '/workspace/source/proto/tensorflow'
cp -vr ../../proto/tensorflow/tensorflow .
'../../proto/tensorflow/tensorflow' -> './tensorflow'
'../../proto/tensorflow/tensorflow/core' -> './tensorflow/core'
'../../proto/tensorflow/tensorflow/core/framework' -> './tensorflow/core/framework'
'../../proto/tensorflow/tensorflow/core/framework/types.proto' -> './tensorflow/core/framework/types.proto'
'../../proto/tensorflow/tensorflow/core/framework/resource_handle.proto' -> './tensorflow/core/framework/resource_handle.proto'
'../../proto/tensorflow/tensorflow/core/framework/tensor_shape.proto' -> './tensorflow/core/framework/tensor_shape.proto'
'../../proto/tensorflow/tensorflow/core/framework/tensor.proto' -> './tensorflow/core/framework/tensor.proto'
python -m grpc.tools.protoc -I. --python_out=. --grpc_python_out=. ./proto/prediction.proto
cd ../../notebooks && make build_protos
make[1]: Entering directory '/workspace/source/notebooks'
cd ../proto/tensorflow && make create_protos
make[2]: Entering directory '/workspace/source/proto/tensorflow'
make[2]: Nothing to be done for 'create_protos'.
make[2]: Leaving directory '/workspace/source/proto/tensorflow'
cp -vr ../proto/tensorflow/tensorflow .
'../proto/tensorflow/tensorflow' -> './tensorflow'
'../proto/tensorflow/tensorflow/core' -> './tensorflow/core'
'../proto/tensorflow/tensorflow/core/framework' -> './tensorflow/core/framework'
'../proto/tensorflow/tensorflow/core/framework/types.proto' -> './tensorflow/core/framework/types.proto'
'../proto/tensorflow/tensorflow/core/framework/resource_handle.proto' -> './tensorflow/core/framework/resource_handle.proto'
'../proto/tensorflow/tensorflow/core/framework/tensor_shape.proto' -> './tensorflow/core/framework/tensor_shape.proto'
'../proto/tensorflow/tensorflow/core/framework/tensor.proto' -> './tensorflow/core/framework/tensor.proto'
cp ../proto/prediction.proto ./proto
python -m grpc.tools.protoc -I. --python_out=. --grpc_python_out=. ./proto/prediction.proto
make[1]: Leaving directory '/workspace/source/notebooks'
cd ../../proto/k8s && make create_protos
make[1]: Entering directory '/workspace/source/proto/k8s'
./create-k8s-protos.sh
Downloading proto files for master
Munging proto file packages
sed -i.bak 's|import "k8s.io/apiextensions-apiserver/|//import "k8s.io/apiextensions-apiserver/|' k8s.io/api/core/v1/generated.proto
rm k8s.io/api/core/v1/generated.proto.bak
make[1]: Leaving directory '/workspace/source/proto/k8s'
pip install -r dev_requirements.txt
Obtaining file:///workspace/source/python (from -r dev_requirements.txt (line 11))
Collecting pytest==5.3.1
  Using cached pytest-5.3.1-py3-none-any.whl (233 kB)
Collecting pytest-xdist==1.30.0
  Downloading pytest_xdist-1.30.0-py2.py3-none-any.whl (35 kB)
Collecting pytest-cov==2.8.1
  Using cached pytest_cov-2.8.1-py2.py3-none-any.whl (18 kB)
Collecting flaky==3.6.1
  Downloading flaky-3.6.1-py2.py3-none-any.whl (22 kB)
Collecting tenacity==6.0.0
  Downloading tenacity-6.0.0-py2.py3-none-any.whl (24 kB)
Collecting coverage==4.5.4
  Using cached coverage-4.5.4-cp36-cp36m-manylinux1_x86_64.whl (205 kB)
Collecting Flask<2.0.0
  Using cached Flask-1.1.1-py2.py3-none-any.whl (94 kB)
Collecting Flask-cors<4.0.0
  Using cached Flask_Cors-3.0.8-py2.py3-none-any.whl (14 kB)
Collecting redis<4.0.0
  Using cached redis-3.4.1-py2.py3-none-any.whl (71 kB)
Collecting requests<3.0.0
  Using cached requests-2.23.0-py2.py3-none-any.whl (58 kB)
Collecting numpy<2.0.0
  Using cached numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)
Collecting flatbuffers<2.0.0
  Using cached flatbuffers-1.11-py2.py3-none-any.whl (15 kB)
Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2->-r dev_requirements.txt (line 11)) (3.11.3)
Requirement already satisfied: grpcio<2.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2->-r dev_requirements.txt (line 11)) (1.26.0)
Collecting Flask-OpenTracing<1.2.0,>=1.1.0
  Using cached Flask-OpenTracing-1.1.0.tar.gz (8.2 kB)
Collecting opentracing<2.3.0,>=2.2.0
  Using cached opentracing-2.2.0.tar.gz (47 kB)
Collecting jaeger-client<4.2.0,>=4.1.0
  Using cached jaeger-client-4.1.0.tar.gz (80 kB)
Collecting grpcio-opentracing<1.2.0,>=1.1.4
  Using cached grpcio_opentracing-1.1.4-py3-none-any.whl (14 kB)
Collecting pyaml<20.0.0
  Using cached pyaml-19.12.0-py2.py3-none-any.whl (17 kB)
Collecting gunicorn<20.1.0,>=19.9.0
  Using cached gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)
Collecting minio<6.0.0,>=4.0.9
  Using cached minio-5.0.7-py2.py3-none-any.whl (71 kB)
Collecting azure-storage-blob<3.0.0,>=2.0.1
  Using cached azure_storage_blob-2.1.0-py2.py3-none-any.whl (88 kB)
Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2->-r dev_requirements.txt (line 11)) (45.1.0)
Collecting packaging
  Downloading packaging-20.1-py2.py3-none-any.whl (36 kB)
Collecting more-itertools>=4.0.0
  Downloading more_itertools-8.2.0-py3-none-any.whl (43 kB)
Collecting importlib-metadata>=0.12; python_version < "3.8"
  Downloading importlib_metadata-1.5.0-py2.py3-none-any.whl (30 kB)
Collecting py>=1.5.0
  Downloading py-1.8.1-py2.py3-none-any.whl (83 kB)
Collecting pluggy<1.0,>=0.12
  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)
Collecting attrs>=17.4.0
  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)
Collecting wcwidth
  Downloading wcwidth-0.1.8-py2.py3-none-any.whl (17 kB)
Collecting execnet>=1.1
  Downloading execnet-1.7.1-py2.py3-none-any.whl (39 kB)
Collecting pytest-forked
  Downloading pytest_forked-1.1.3-py2.py3-none-any.whl (4.5 kB)
Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from pytest-xdist==1.30.0->-r dev_requirements.txt (line 2)) (1.14.0)
Collecting itsdangerous>=0.24
  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)
Collecting Jinja2>=2.10.1
  Downloading Jinja2-2.11.1-py2.py3-none-any.whl (126 kB)
Collecting click>=5.1
  Downloading Click-7.0-py2.py3-none-any.whl (81 kB)
Collecting Werkzeug>=0.15
  Downloading Werkzeug-1.0.0-py2.py3-none-any.whl (298 kB)
Collecting idna<3,>=2.5
  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)
Collecting chardet<4,>=3.0.2
  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1
  Downloading urllib3-1.25.8-py2.py3-none-any.whl (125 kB)
Collecting certifi>=2017.4.17
  Downloading certifi-2019.11.28-py2.py3-none-any.whl (156 kB)
Collecting threadloop<2,>=1
  Downloading threadloop-1.0.2.tar.gz (4.9 kB)
Collecting thrift
  Downloading thrift-0.13.0.tar.gz (59 kB)
Collecting tornado<6,>=4.3
  Downloading tornado-5.1.1.tar.gz (516 kB)
Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/site-packages (from pyaml<20.0.0->seldon-core==1.0.2->-r dev_requirements.txt (line 11)) (5.3)
Collecting pytz
  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)
Collecting configparser
  Downloading configparser-4.0.2-py2.py3-none-any.whl (22 kB)
Collecting python-dateutil
  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)
Collecting azure-common>=1.1.5
  Downloading azure_common-1.1.24-py2.py3-none-any.whl (12 kB)
Collecting azure-storage-common~=2.1
  Downloading azure_storage_common-2.1.0-py2.py3-none-any.whl (47 kB)
Collecting pyparsing>=2.0.2
  Downloading pyparsing-2.4.6-py2.py3-none-any.whl (67 kB)
Collecting zipp>=0.5
  Downloading zipp-3.0.0-py3-none-any.whl (4.8 kB)
Collecting apipkg>=1.4
  Downloading apipkg-1.5-py2.py3-none-any.whl (4.9 kB)
Collecting MarkupSafe>=0.23
  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)
Collecting cryptography
  Downloading cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3 MB)
Collecting cffi!=1.11.3,>=1.8
  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)
Collecting pycparser
  Downloading pycparser-2.19.tar.gz (158 kB)
Building wheels for collected packages: Flask-OpenTracing, opentracing, jaeger-client, threadloop, thrift, tornado, pycparser
  Building wheel for Flask-OpenTracing (setup.py): started
  Building wheel for Flask-OpenTracing (setup.py): finished with status 'done'
  Created wheel for Flask-OpenTracing: filename=Flask_OpenTracing-1.1.0-py3-none-any.whl size=9070 sha256=f9b1abe867bd8997cddd5cb8cc69944b67d2f9c243e38d3a341f3eadae0a1f61
  Stored in directory: /builder/home/.cache/pip/wheels/ad/4b/2d/24ff0da0a0b53c7c77ce59b843bcceaf644c88703241e59615
  Building wheel for opentracing (setup.py): started
  Building wheel for opentracing (setup.py): finished with status 'done'
  Created wheel for opentracing: filename=opentracing-2.2.0-py3-none-any.whl size=49319 sha256=226ff86005690c62c8f700257292782933abccd2a3afb2ad6f95b51479188777
  Stored in directory: /builder/home/.cache/pip/wheels/39/40/44/8bace79f4514e99786236c31f1df8d1b814ff02c1e08b1d697
  Building wheel for jaeger-client (setup.py): started
  Building wheel for jaeger-client (setup.py): finished with status 'done'
  Created wheel for jaeger-client: filename=jaeger_client-4.1.0-py3-none-any.whl size=64309 sha256=dfd6d9b093acd424473da7b60992f25d89b8f4edcf7b57b029120293fc0c3519
  Stored in directory: /builder/home/.cache/pip/wheels/e9/9b/8c/503d0cc13b39a551c054515683ba1d15b40324c863dc442e66
  Building wheel for threadloop (setup.py): started
  Building wheel for threadloop (setup.py): finished with status 'done'
  Created wheel for threadloop: filename=threadloop-1.0.2-py3-none-any.whl size=3423 sha256=a365a008a1eaaaa572fd979b344c12ce17a012091d768f4a29267d1f9a240376
  Stored in directory: /builder/home/.cache/pip/wheels/02/54/65/9f87de48fe8fcaaee30f279973d946ad55f9df56b93b3e78da
  Building wheel for thrift (setup.py): started
  Building wheel for thrift (setup.py): finished with status 'done'
  Created wheel for thrift: filename=thrift-0.13.0-cp36-cp36m-linux_x86_64.whl size=483856 sha256=9d715ca2500fcda02c2f3c06ff003cbc4f95fd831c42bf59d44f447b6046d34b
  Stored in directory: /builder/home/.cache/pip/wheels/e0/38/fc/472fe18756b177b42096961f8bd3ff2dc5c5620ac399fce52d
  Building wheel for tornado (setup.py): started
  Building wheel for tornado (setup.py): finished with status 'done'
  Created wheel for tornado: filename=tornado-5.1.1-cp36-cp36m-linux_x86_64.whl size=462655 sha256=9be569a1775b84d7f8caf7936def556588fdbf09f4c27d6c7867ef78980e6cb7
  Stored in directory: /builder/home/.cache/pip/wheels/64/74/71/e7a0d0eb4fc42cb20a17aec36f8f0b5b8c5e1ec19c701fd34a
  Building wheel for pycparser (setup.py): started
  Building wheel for pycparser (setup.py): finished with status 'done'
  Created wheel for pycparser: filename=pycparser-2.19-py2.py3-none-any.whl size=111031 sha256=76b07d8d6076817fa0cf40af5b30142041aa83d58512c7f5363b611b4d047719
  Stored in directory: /builder/home/.cache/pip/wheels/c6/6b/83/2608afaa57ecfb0a66ac89191a8d9bad71c62ca55ee499c2d0
Successfully built Flask-OpenTracing opentracing jaeger-client threadloop thrift tornado pycparser
Installing collected packages: pyparsing, packaging, more-itertools, zipp, importlib-metadata, py, pluggy, attrs, wcwidth, pytest, apipkg, execnet, pytest-forked, pytest-xdist, coverage, pytest-cov, flaky, tenacity, itsdangerous, MarkupSafe, Jinja2, click, Werkzeug, Flask, Flask-cors, redis, idna, chardet, urllib3, certifi, requests, numpy, flatbuffers, opentracing, Flask-OpenTracing, tornado, threadloop, thrift, jaeger-client, grpcio-opentracing, pyaml, gunicorn, pytz, configparser, python-dateutil, minio, azure-common, pycparser, cffi, cryptography, azure-storage-common, azure-storage-blob, seldon-core
  Running setup.py develop for seldon-core
Successfully installed Flask-1.1.1 Flask-OpenTracing-1.1.0 Flask-cors-3.0.8 Jinja2-2.11.1 MarkupSafe-1.1.1 Werkzeug-1.0.0 apipkg-1.5 attrs-19.3.0 azure-common-1.1.24 azure-storage-blob-2.1.0 azure-storage-common-2.1.0 certifi-2019.11.28 cffi-1.14.0 chardet-3.0.4 click-7.0 configparser-4.0.2 coverage-4.5.4 cryptography-2.8 execnet-1.7.1 flaky-3.6.1 flatbuffers-1.11 grpcio-opentracing-1.1.4 gunicorn-20.0.4 idna-2.9 importlib-metadata-1.5.0 itsdangerous-1.1.0 jaeger-client-4.1.0 minio-5.0.7 more-itertools-8.2.0 numpy-1.18.1 opentracing-2.2.0 packaging-20.1 pluggy-0.13.1 py-1.8.1 pyaml-19.12.0 pycparser-2.19 pyparsing-2.4.6 pytest-5.3.1 pytest-cov-2.8.1 pytest-forked-1.1.3 pytest-xdist-1.30.0 python-dateutil-2.8.1 pytz-2019.3 redis-3.4.1 requests-2.23.0 seldon-core tenacity-6.0.0 threadloop-1.0.2 thrift-0.13.0 tornado-5.1.1 urllib3-1.25.8 wcwidth-0.1.8 zipp-3.0.0
# Run the core tests in parallel
pytest \
	--verbose \
	-s \
	-W ignore \
	-n "4" \
	-m "not sequential" 2>&1
============================= test session starts ==============================
platform linux -- Python 3.6.0, pytest-5.3.1, py-1.8.1, pluggy-0.13.1 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /workspace/source/testing/scripts, inifile: setup.cfg
plugins: xdist-1.30.0, forked-1.1.3, flaky-3.6.1, cov-2.8.1
gw0 I / gw1 I / gw2 I / gw3 I
[gw0] linux Python 3.6.0 cwd: /workspace/source/testing/scripts
[gw1] linux Python 3.6.0 cwd: /workspace/source/testing/scripts
[gw2] linux Python 3.6.0 cwd: /workspace/source/testing/scripts
[gw3] linux Python 3.6.0 cwd: /workspace/source/testing/scripts
[gw1] Python 3.6.0 (default, Feb  4 2020, 10:38:29)  -- [GCC 8.3.0]
[gw2] Python 3.6.0 (default, Feb  4 2020, 10:38:29)  -- [GCC 8.3.0]
[gw0] Python 3.6.0 (default, Feb  4 2020, 10:38:29)  -- [GCC 8.3.0]
[gw3] Python 3.6.0 (default, Feb  4 2020, 10:38:29)  -- [GCC 8.3.0]
gw0 [39] / gw1 [39] / gw2 [39] / gw3 [39]

scheduling tests via LoadScheduling

test_api_version.py::test_api_version[machinelearning.seldon.io/v1] 
test_api_version.py::test_api_version[machinelearning.seldon.io/v1alpha2] 
test_bad_graphs.py::TestBadGraphs::test_duplicate_predictor_name 
test_api_version.py::test_api_version[machinelearning.seldon.io/v1alpha3] Error from server (SeldonDeployment.machinelearing.seldon.io "dupname" is invalid: [spec.predictors[1]: Invalid value: "mymodel": Duplicate predictor name, spec: Invalid value: "dupname": Traffic must sum to 100 for multiple predictors]): error when creating "../resources/bad_duplicate_predictor_name.json": admission webhook "v1alpha2.vseldondeployment.kb.io" denied the request: SeldonDeployment.machinelearing.seldon.io "dupname" is invalid: [spec.predictors[1]: Invalid value: "mymodel": Duplicate predictor name, spec: Invalid value: "dupname": Traffic must sum to 100 for multiple predictors]

[gw3] PASSED test_bad_graphs.py::TestBadGraphs::test_duplicate_predictor_name 
test_helm_charts_clusterwide.py::TestClusterWide::test_mab_model Error: uninstall: Release not loaded: mymodel: release: not found

[gw2] PASSED test_api_version.py::test_api_version[machinelearning.seldon.io/v1alpha3] Error: uninstall: Release not loaded: mymodel: release: not found

[gw1] PASSED test_api_version.py::test_api_version[machinelearning.seldon.io/v1alpha2] Error: uninstall: Release not loaded: mymodel: release: not found

[gw0] PASSED test_api_version.py::test_api_version[machinelearning.seldon.io/v1] Error: uninstall: Release not loaded: mymab: release: not found

[gw3] PASSED test_helm_charts_clusterwide.py::TestClusterWide::test_mab_model 
test_bad_graphs.py::TestBadGraphs::test_model_name_mismatch Error from server (SeldonDeployment.machinelearing.seldon.io "namemismatch" is invalid: spec.predictors[0].graph: Invalid value: "complex-model_bad_name": Can't find container for Predictive Unit): error when creating "../resources/bad_name_mismatch.json": admission webhook "v1alpha2.vseldondeployment.kb.io" denied the request: SeldonDeployment.machinelearing.seldon.io "namemismatch" is invalid: spec.predictors[0].graph: Invalid value: "complex-model_bad_name": Can't find container for Predictive Unit

[gw1] PASSED test_bad_graphs.py::TestBadGraphs::test_model_name_mismatch 
test_local_operators.py::TestLocalOperators::test_namespace_operator 
test_helm_charts_clusterwide.py::TestClusterWide::test_single_model 
test_helm_charts_clusterwide.py::TestClusterWide::test_abtest_model 
test_local_operators.py::TestLocalOperators::test_labelled_operator Error from server (InternalError): error when creating "../resources/model_controller_id.yaml": Internal error occurred: failed calling webhook "v1alpha2.mseldondeployment.kb.io": Post https://seldon-webhook-service.test-labelled-operator.svc:443/mutate-machinelearning-seldon-io-v1alpha2-seldondeployment?timeout=30s: dial tcp 10.110.204.31:443: connect: connection refused

[gw1] PASSED test_local_operators.py::TestLocalOperators::test_namespace_operator Error: uninstall: Release not loaded: mymodel: release: not found

[gw2] PASSED test_helm_charts_clusterwide.py::TestClusterWide::test_single_model Error: uninstall: Release not loaded: myabtest: release: not found

[gw0] PASSED test_helm_charts_clusterwide.py::TestClusterWide::test_abtest_model 
test_prepackaged_servers.py::TestPrepack::test_tfserving 
[gw3] PASSED test_local_operators.py::TestLocalOperators::test_labelled_operator 
test_prepackaged_servers.py::TestPrepack::test_mlflow 
test_rolling_updates.py::TestRollingHttp::test_rolling_update5[istio] 
test_prepackaged_servers.py::TestPrepack::test_sklearn Error from server (NotFound): error when deleting "../resources/graph6.json": seldondeployments.machinelearning.seldon.io "mymodel" not found

[gw0] PASSED test_rolling_updates.py::TestRollingHttp::test_rolling_update5[istio] 
[gw2] PASSED test_prepackaged_servers.py::TestPrepack::test_mlflow 
test_rolling_updates.py::TestRollingHttp::test_rolling_update6[ambas] 
[gw1] PASSED test_prepackaged_servers.py::TestPrepack::test_tfserving 
test_rolling_updates.py::TestRollingHttp::test_rolling_update5[ambas] 
[gw3] PASSED test_prepackaged_servers.py::TestPrepack::test_sklearn 
test_prepackaged_servers.py::TestPrepack::test_xgboost Error from server (NotFound): error when deleting "../resources/graph2svc.json": seldondeployments.machinelearning.seldon.io "mymodel" not found

[gw0] PASSED test_rolling_updates.py::TestRollingHttp::test_rolling_update6[ambas] 
test_rolling_updates.py::TestRollingHttp::test_rolling_update6[istio] Error from server (NotFound): error when deleting "../resources/graph6.json": seldondeployments.machinelearning.seldon.io "mymodel" not found

[gw2] PASSED test_rolling_updates.py::TestRollingHttp::test_rolling_update5[ambas] 
test_rolling_updates.py::TestRollingHttp::test_rolling_update7[ambas] 
[gw1] PASSED test_prepackaged_servers.py::TestPrepack::test_xgboost 
test_rolling_updates.py::TestRollingHttp::test_rolling_update7[istio] 
test_rolling_updates.py::TestRollingHttp::test_rolling_update8[ambas] Error from server (NotFound): error when deleting "../resources/graph2svc.json": seldondeployments.machinelearning.seldon.io "mymodel" not found

[gw3] PASSED test_rolling_updates.py::TestRollingHttp::test_rolling_update6[istio] 
test_rolling_updates.py::TestRollingHttp::test_rolling_update8[istio] Error from server (NotFound): error when deleting "../resources/graph3svc.json": seldondeployments.machinelearning.seldon.io "mymodel" not found

[gw2] PASSED test_rolling_updates.py::TestRollingHttp::test_rolling_update7[istio] 
test_rolling_updates.py::TestRollingHttp::test_rolling_update7[ambas] 
test_rolling_updates.py::TestRollingHttp::test_rolling_update9[istio] Error from server (NotFound): error when deleting "../resources/graph4svc.json": seldondeployments.machinelearning.seldon.io "mymodel" not found

[gw1] PASSED test_rolling_updates.py::TestRollingHttp::test_rolling_update8[ambas] 
test_rolling_updates.py::TestRollingHttp::test_rolling_update10[ambas] Error from server (NotFound): error when deleting "../resources/graph3svc.json": seldondeployments.machinelearning.seldon.io "mymodel" not found

[gw0] PASSED test_rolling_updates.py::TestRollingHttp::test_rolling_update7[ambas] Error from server (NotFound): error when deleting "../resources/graph4svc.json": seldondeployments.machinelearning.seldon.io "mymodel" not found

[gw3] PASSED test_rolling_updates.py::TestRollingHttp::test_rolling_update8[istio] 
test_rolling_updates.py::TestRollingHttp::test_rolling_update9[ambas] Error from server (NotFound): error when deleting "../resources/graph5svc.json": seldondeployments.machinelearning.seldon.io "mymodel" not found

[gw2] PASSED test_rolling_updates.py::TestRollingHttp::test_rolling_update9[istio] 
test_rolling_updates.py::TestRollingHttp::test_rolling_update10[istio] 
test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph2.json-ambas] Error from server (NotFound): error when deleting "../resources/graph6svc.json": seldondeployments.machinelearning.seldon.io "mymodel" not found

[gw1] PASSED test_rolling_updates.py::TestRollingHttp::test_rolling_update10[ambas] 
test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph2.json-istio] Error from server (NotFound): error when deleting "../resources/graph6svc.json": seldondeployments.machinelearning.seldon.io "mymodel" not found

[gw3] PASSED test_rolling_updates.py::TestRollingHttp::test_rolling_update10[istio] 
test_rolling_updates.py::TestRollingHttp::test_rolling_update9[ambas] 
test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph3.json-istio] 
[gw2] PASSED test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph2.json-ambas] 
test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph4.json-ambas] 
[gw1] PASSED test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph2.json-istio] 
[gw0] FAILED test_rolling_updates.py::TestRollingHttp::test_rolling_update9[ambas] 
test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph4.json-istio] 
test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph3.json-ambas] 
[gw3] PASSED test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph3.json-istio] 
test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph5.json-ambas] 
[gw0] PASSED test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph3.json-ambas] 
test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph8.json-istio] 
test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph5.json-ambas] 
[gw3] PASSED test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph5.json-ambas] 
test_rolling_updates.py::test_rolling_update_deployment[graph7.json-graph8.json-ambas] error: timed out waiting for the condition on deployments/mymodel-mymodel-e2eb561

[gw2] PASSED test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph4.json-ambas] error: timed out waiting for the condition on deployments/mymodel-mymodel-e2eb561

[gw1] PASSED test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph4.json-istio] 
test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph5.json-istio] 
test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph8.json-ambas] 
[gw2] PASSED test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph5.json-istio] error: timed out waiting for the condition on deployments/mymodel-mymodel-e2eb561

[gw0] PASSED test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph8.json-istio] 
test_rolling_updates.py::test_rolling_update_deployment[graph7.json-graph8.json-istio] error: timed out waiting for the condition on deployments/mymodel-mymodel-e2eb561

[gw3] PASSED test_rolling_updates.py::test_rolling_update_deployment[graph7.json-graph8.json-ambas] 
test_tracing.py::test_tracing_rest 
[gw3] FAILED test_tracing.py::test_tracing_rest error: timed out waiting for the condition on deployments/mymodel-mymodel-e2eb561

[gw1] PASSED test_rolling_updates.py::test_rolling_update_deployment[graph1.json-graph8.json-ambas] error: timed out waiting for the condition on deployments/mymodel-mymodel-e2eb561

[gw0] PASSED test_rolling_updates.py::test_rolling_update_deployment[graph7.json-graph8.json-istio] 

=================================== FAILURES ===================================
_________________ TestRollingHttp.test_rolling_update9[ambas] __________________
[gw0] linux -- Python 3.6.0 /usr/local/bin/python

self = <test_rolling_updates.TestRollingHttp object at 0x7f248ca14d68>
namespace = 'test-rolling-update9-ambas', api_gateway = 'localhost:8003'

    def test_rolling_update9(self, namespace, api_gateway):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(
                f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}"
            )
        retry_run(f"kubectl apply -f ../resources/graph1svc.json -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace, expected_deployments=2)
        r = initial_rest_request("mymodel", namespace, endpoint=api_gateway)
        assert r.status_code == 200
        assert r.json()["data"]["tensor"]["values"] == [1.0, 2.0, 3.0, 4.0]
        retry_run(f"kubectl apply -f ../resources/graph5svc.json -n {namespace}")
        r = initial_rest_request("mymodel", namespace, endpoint=api_gateway)
        assert r.status_code == 200
        assert r.json()["data"]["tensor"]["values"] == [1.0, 2.0, 3.0, 4.0]
        i = 0
        for i in range(50):
            r = rest_request_ambassador("mymodel", namespace, api_gateway)
>           assert r.status_code == 200
E           assert 504 == 200
E             -504
E             +200

test_rolling_updates.py:185: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  root:seldon_e2e_utils.py:116 Successfully ran command: kubectl create namespace test-rolling-update9-ambas
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:116 Successfully ran command: kubectl apply -f ../resources/graph1svc.json -n test-rolling-update9-ambas
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:133 Status for SeldonDeployment mymodel is ready.
WARNING  root:seldon_e2e_utils.py:60 Successfully waited for SeldonDeployment mymodel
WARNING  root:seldon_e2e_utils.py:71 For SeldonDeployment mymodel found following deployments: ['mymodel-mymodel-e2eb561', 'mymodel-mymodel-svc-orch-8e2a24b']
WARNING  root:seldon_e2e_utils.py:94 Waiting for deployment mymodel-mymodel-e2eb561
WARNING  root:seldon_e2e_utils.py:101 Successfully waited for deployment mymodel-mymodel-e2eb561
WARNING  root:seldon_e2e_utils.py:94 Waiting for deployment mymodel-mymodel-svc-orch-8e2a24b
WARNING  root:seldon_e2e_utils.py:101 Successfully waited for deployment mymodel-mymodel-svc-orch-8e2a24b
WARNING  root:seldon_e2e_utils.py:116 Successfully ran command: kubectl apply -f ../resources/graph5svc.json -n test-rolling-update9-ambas
------------------------------ Captured log setup ------------------------------
WARNING  root:seldon_e2e_utils.py:116 Successfully ran command: kubectl create namespace test-rolling-update9-ambas
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:116 Successfully ran command: kubectl apply -f ../resources/graph1svc.json -n test-rolling-update9-ambas
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:133 Status for SeldonDeployment mymodel is ready.
WARNING  root:seldon_e2e_utils.py:60 Successfully waited for SeldonDeployment mymodel
WARNING  root:seldon_e2e_utils.py:71 For SeldonDeployment mymodel found following deployments: ['mymodel-mymodel-e2eb561', 'mymodel-mymodel-svc-orch-8e2a24b']
WARNING  root:seldon_e2e_utils.py:94 Waiting for deployment mymodel-mymodel-e2eb561
WARNING  root:seldon_e2e_utils.py:101 Successfully waited for deployment mymodel-mymodel-e2eb561
WARNING  root:seldon_e2e_utils.py:94 Waiting for deployment mymodel-mymodel-svc-orch-8e2a24b
WARNING  root:seldon_e2e_utils.py:101 Successfully waited for deployment mymodel-mymodel-svc-orch-8e2a24b
WARNING  root:seldon_e2e_utils.py:176 Bad status:404
WARNING  root:seldon_e2e_utils.py:216 Sleeping 1 sec and trying again
WARNING  root:seldon_e2e_utils.py:116 Successfully ran command: kubectl apply -f ../resources/graph5svc.json -n test-rolling-update9-ambas
______________________________ test_tracing_rest _______________________________
[gw3] linux -- Python 3.6.0 /usr/local/bin/python

namespace = 'test-tracing-rest'

    def test_tracing_rest(namespace):
        # Deploy model and check that is running
        retry_run(f"kubectl apply -f ../resources/graph-tracing.json -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
        initial_rest_request("mymodel", namespace)
    
        # We need the current pod name to find the right traces
        deployment_names = get_deployment_names("mymodel", namespace)
        deployment_name = deployment_names[0]
        pod_names = get_pod_names(deployment_name, namespace)
        pod_name = pod_names[0]
    
        # Get traces and assert their content
        traces = get_traces(pod_name, "executor", "predictions")
        assert len(traces) == 1
    
        trace = traces[0]
        processes = trace["processes"]
>       assert len(processes) == 2
E       assert 1 == 2
E         -1
E         +2

test_tracing.py:50: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  root:seldon_e2e_utils.py:116 Successfully ran command: kubectl create namespace test-tracing-rest
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:116 Successfully ran command: kubectl apply -f ../resources/graph-tracing.json -n test-tracing-rest
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:136 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:133 Status for SeldonDeployment mymodel is ready.
WARNING  root:seldon_e2e_utils.py:60 Successfully waited for SeldonDeployment mymodel
WARNING  root:seldon_e2e_utils.py:71 For SeldonDeployment mymodel found following deployments: ['mymodel-mymodel-e2eb561']
WARNING  root:seldon_e2e_utils.py:94 Waiting for deployment mymodel-mymodel-e2eb561
WARNING  root:seldon_e2e_utils.py:101 Successfully waited for deployment mymodel-mymodel-e2eb561
WARNING  root:seldon_e2e_utils.py:60 Successfully waited for SeldonDeployment mymodel
WARNING  root:seldon_e2e_utils.py:71 For SeldonDeployment mymodel found following deployments: ['mymodel-mymodel-e2eb561']
===Flaky Test Report===

test_rolling_update5[ambas] passed 1 out of the required 1 times. Success!
test_rolling_update7[istio] passed 1 out of the required 1 times. Success!
test_rolling_update9[istio] passed 1 out of the required 1 times. Success!
test_rolling_update_deployment[graph1.json-graph2.json-ambas] passed 1 out of the required 1 times. Success!
test_rolling_update_deployment[graph1.json-graph4.json-ambas] passed 1 out of the required 1 times. Success!
test_rolling_update_deployment[graph1.json-graph5.json-istio] passed 1 out of the required 1 times. Success!
test_rolling_update6[istio] passed 1 out of the required 1 times. Success!
test_rolling_update8[istio] passed 1 out of the required 1 times. Success!
test_rolling_update10[istio] passed 1 out of the required 1 times. Success!
test_rolling_update_deployment[graph1.json-graph3.json-istio] passed 1 out of the required 1 times. Success!
test_rolling_update_deployment[graph1.json-graph5.json-ambas] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:263>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:461>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:453>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:471>]
test_rolling_update_deployment[graph1.json-graph5.json-ambas] passed 1 out of the required 1 times. Success!
test_rolling_update_deployment[graph7.json-graph8.json-ambas] passed 1 out of the required 1 times. Success!
test_rolling_update8[ambas] passed 1 out of the required 1 times. Success!
test_rolling_update10[ambas] passed 1 out of the required 1 times. Success!
test_rolling_update_deployment[graph1.json-graph2.json-istio] passed 1 out of the required 1 times. Success!
test_rolling_update_deployment[graph1.json-graph4.json-istio] passed 1 out of the required 1 times. Success!
test_rolling_update_deployment[graph1.json-graph8.json-ambas] passed 1 out of the required 1 times. Success!
test_rolling_update5[istio] passed 1 out of the required 1 times. Success!
test_rolling_update6[ambas] passed 1 out of the required 1 times. Success!
test_rolling_update7[ambas] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	assert 504 == 200
  -504
  +200
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:123>]
test_rolling_update7[ambas] passed 1 out of the required 1 times. Success!
test_rolling_update9[ambas] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	assert 504 == 200
  -504
  +200
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:185>]
test_rolling_update9[ambas] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	assert 504 == 200
  -504
  +200
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:185>]
test_rolling_update_deployment[graph1.json-graph3.json-ambas] passed 1 out of the required 1 times. Success!
test_rolling_update_deployment[graph1.json-graph8.json-istio] passed 1 out of the required 1 times. Success!
test_rolling_update_deployment[graph7.json-graph8.json-istio] passed 1 out of the required 1 times. Success!

===End Flaky Test Report===
================== 2 failed, 37 passed in 2204.09s (0:36:44) ===================
make: *** [Makefile:105: test] Error 1
kind delete cluster
Deleting cluster "kind" ...
Stopping Docker: dockerProgram process in pidfile '/var/run/docker-ssd.pid', 1 process(es), refused to die.
[31m
Pipeline failed on stage 'end-to-end' : container 'step-test-end-to-end'. The execution of the pipeline has stopped.[0m
