workflow:
  # Name of the overarching argo workflow
  name: seldon-benchmark-process
  # If true the randomly generated string will be apended as the name of the workflow
  useNameAsGenerateName: "false"
  # Namespace where to create the workflow and all resources in benchmark job
  namespace: default
  # The number of benchmarks being carried out at the same time
  parallelism: 1
  # The default delimiter to use for splitting the parameters provided
  paramDelimiter: "|"
seldonDeployment:
  # Name to use for the seldon deployment which by default appends generated workflow ID
  name: seldon-{{workflow.uid}}
  # TODO: Ensure one of image or server is set, and if server is set that modeluri is provided
  # Image parameter to use in addition or alternative to prepackaged server
  image:
  # Prepackaged model server to use [see https://docs.seldon.io/projects/seldon-core/en/latest/servers/overview.html]
  server: CUSTOM_SERVER
  # The name of the model in the graph as well as the name of the model in tf / kf protocol
  modelName: classifier
  # The schema protocol to use which would be dependent on data
  protocol: seldon
  # The URL for the model that is to be used
  modelUri:
  # The API Type (REST vs GRPC)
  apiType: rest
  # The number of seldon deployment replicas to launch
  replicas: 2
  # Waiting time before checks for deployment to ensure kubernetes cluster registers create
  waitTime: 5
  # The number of threads spawned by Python Gunicorn Flask server
  serverThreads: 1
  # The number of workers spawned by Python Gunicorn Flask server
  serverWorkers: 4
  # Whether to enable resources
  enableResources: "false"
  requests:
    # Requests for CPU (only added if enableResources is enabled)
    cpu: 50m
    # Requests for memory (only added if enableResources is enabled)
    memory: 100Mi
  limits:
    # Limits for CPU (only added if enableResources is enabled)
    cpu: 50m
    # Limits for memory (only added if enableResources is enabled)
    memory: 1000Mi
  # Whether to disable service orchestrator to test latency (false by default)
  disableOrchestrator: false
# The benchmark worker is the component that will send the requests from the files
benchmark:
  # Endpoint of for the benchmark client to contact the seldon deployment
  host: istio-ingressgateway.istio-system.svc.cluster.local:80
  # Number of parallel benchmark client workers to process the data
  cpu: 4
  # Maximum number of workers to allocate for a benchmark
  concurrency: 1
  # Duration of benchmark
  duration: 30s
  # Rate (number of requests per second [0 = infinity])
  rate: 0
  # Data that the benchmark worker will use to send
  # TODO: Explore adding multiple data instances with configurable split token (eg |)
  data: '{"data": {"ndarray": [[0,1,2,3]]}}'
  # Image to use for the benchmark REST client
  # TODO: Move image to seldonio
  restImage: peterevans/vegeta:latest-vegeta12.8.4
  # Image to use for the benchmark GRPC client
  grpcImage: seldonio/ghz:v0.55.0
